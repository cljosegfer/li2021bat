torch.cuda.device_count():  1
CUDA_VISIBLE_DEVICES:  0
beat_aligned_transformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(8, 95, kernel_size=(1, 5), stride=(1, 5))
  )
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): BasicLayer(
      dim=96, input_resolution=80, depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=96, input_resolution=80, num_heads=8, window_size=5, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(5, 5), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): Identity()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=96, input_resolution=80, num_heads=8, window_size=5, shift_size=2, mlp_ratio=4.0
          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=96, window_size=(5, 5), num_heads=8
            (qkv): Linear(in_features=96, out_features=288, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=96, out_features=96, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=96, out_features=384, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=384, out_features=96, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): Sequential(
        (0): Conv1d(96, 192, kernel_size=(7,), stride=(1,), padding=(3,))
        (1): ChanNorm()
        (2): MaxPool1d(kernel_size=7, stride=2, padding=3, dilation=1, ceil_mode=False)
      )
    )
    (1): BasicLayer(
      dim=192, input_resolution=40, depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=192, input_resolution=40, num_heads=16, window_size=5, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(5, 5), num_heads=16
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=192, input_resolution=40, num_heads=16, window_size=5, shift_size=2, mlp_ratio=4.0
          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=192, window_size=(5, 5), num_heads=16
            (qkv): Linear(in_features=192, out_features=576, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=192, out_features=192, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=192, out_features=768, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=768, out_features=192, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): Sequential(
        (0): Conv1d(192, 384, kernel_size=(7,), stride=(1,), padding=(3,))
        (1): ChanNorm()
        (2): MaxPool1d(kernel_size=7, stride=2, padding=3, dilation=1, ceil_mode=False)
      )
    )
    (2): BasicLayer(
      dim=384, input_resolution=20, depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=384, input_resolution=20, num_heads=32, window_size=5, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(5, 5), num_heads=32
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=384, input_resolution=20, num_heads=32, window_size=5, shift_size=2, mlp_ratio=4.0
          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=384, window_size=(5, 5), num_heads=32
            (qkv): Linear(in_features=384, out_features=1152, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=384, out_features=384, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=384, out_features=1536, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=1536, out_features=384, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): Sequential(
        (0): Conv1d(384, 768, kernel_size=(7,), stride=(1,), padding=(3,))
        (1): ChanNorm()
        (2): MaxPool1d(kernel_size=7, stride=2, padding=3, dilation=1, ceil_mode=False)
      )
    )
    (3): BasicLayer(
      dim=768, input_resolution=10, depth=6
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=768, input_resolution=10, num_heads=64, window_size=5, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=768, window_size=(5, 5), num_heads=64
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=768, input_resolution=10, num_heads=64, window_size=5, shift_size=2, mlp_ratio=4.0
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=768, window_size=(5, 5), num_heads=64
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (2): SwinTransformerBlock(
          dim=768, input_resolution=10, num_heads=64, window_size=5, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=768, window_size=(5, 5), num_heads=64
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (3): SwinTransformerBlock(
          dim=768, input_resolution=10, num_heads=64, window_size=5, shift_size=2, mlp_ratio=4.0
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=768, window_size=(5, 5), num_heads=64
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (4): SwinTransformerBlock(
          dim=768, input_resolution=10, num_heads=64, window_size=5, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=768, window_size=(5, 5), num_heads=64
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (5): SwinTransformerBlock(
          dim=768, input_resolution=10, num_heads=64, window_size=5, shift_size=2, mlp_ratio=4.0
          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=768, window_size=(5, 5), num_heads=64
            (qkv): Linear(in_features=768, out_features=2304, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=768, out_features=768, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=768, out_features=3072, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=3072, out_features=768, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
      (downsample): Sequential(
        (0): Conv1d(768, 1536, kernel_size=(7,), stride=(1,), padding=(3,))
        (1): ChanNorm()
        (2): MaxPool1d(kernel_size=7, stride=2, padding=3, dilation=1, ceil_mode=False)
      )
    )
    (4): BasicLayer(
      dim=1536, input_resolution=5, depth=2
      (blocks): ModuleList(
        (0): SwinTransformerBlock(
          dim=1536, input_resolution=5, num_heads=128, window_size=5, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1536, window_size=(5, 5), num_heads=128
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
        (1): SwinTransformerBlock(
          dim=1536, input_resolution=5, num_heads=128, window_size=5, shift_size=0, mlp_ratio=4.0
          (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
          (attn): WindowAttention(
            dim=1536, window_size=(5, 5), num_heads=128
            (qkv): Linear(in_features=1536, out_features=4608, bias=True)
            (attn_drop): Dropout(p=0.0, inplace=False)
            (proj): Linear(in_features=1536, out_features=1536, bias=True)
            (proj_drop): Dropout(p=0.0, inplace=False)
            (softmax): Softmax(dim=-1)
          )
          (drop_path): DropPath()
          (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
          (mlp): Mlp(
            (fc1): Linear(in_features=1536, out_features=6144, bias=True)
            (act): GELU()
            (fc2): Linear(in_features=6144, out_features=1536, bias=True)
            (drop): Dropout(p=0.0, inplace=False)
          )
        )
      )
    )
  )
  (global_attn): Attention(
    (qkv): Linear(in_features=1536, out_features=4608, bias=False)
    (attn_drop): Dropout(p=0.0, inplace=False)
    (proj): Linear(in_features=1536, out_features=1536, bias=True)
    (proj_drop): Dropout(p=0.0, inplace=False)
  )
  (norm1): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (norm2): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (mlp): Mlp(
    (fc1): Linear(in_features=1536, out_features=3072, bias=True)
    (act): GELU()
    (fc2): Linear(in_features=3072, out_features=1536, bias=True)
    (drop): Dropout(p=0.0, inplace=False)
  )
  (drop_path): Identity()
  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)
  (chnorm): ChanNorm()
  (avgpool): AdaptiveAvgPool1d(output_size=1)
  (maxpool): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  (head): Linear(in_features=1536, out_features=6, bias=True)
  (head_coarse): Linear(in_features=768, out_features=8, bias=True)
)
Loading data...
Train Epoch: 1 [0/319902 (0%)] Loss: 0.747285, 1 batch cost time 1.87
Train Epoch: 1 [512/319902 (0%)] Loss: 0.076057, 1 batch cost time 0.51
Train Epoch: 1 [1024/319902 (0%)] Loss: 0.199569, 1 batch cost time 0.51
Train Epoch: 1 [1536/319902 (0%)] Loss: 0.102687, 1 batch cost time 0.51
Train Epoch: 1 [2048/319902 (1%)] Loss: 0.037557, 1 batch cost time 0.51
Train Epoch: 1 [2560/319902 (1%)] Loss: 0.085971, 1 batch cost time 0.51
Train Epoch: 1 [3072/319902 (1%)] Loss: 0.096871, 1 batch cost time 0.51
Train Epoch: 1 [3584/319902 (1%)] Loss: 0.053256, 1 batch cost time 0.51
Train Epoch: 1 [4096/319902 (1%)] Loss: 0.066219, 1 batch cost time 0.51
Train Epoch: 1 [4608/319902 (1%)] Loss: 0.119105, 1 batch cost time 0.51
Train Epoch: 1 [5120/319902 (2%)] Loss: 0.088440, 1 batch cost time 0.51
Train Epoch: 1 [5632/319902 (2%)] Loss: 0.105053, 1 batch cost time 0.51
Train Epoch: 1 [6144/319902 (2%)] Loss: 0.131343, 1 batch cost time 0.51
Train Epoch: 1 [6656/319902 (2%)] Loss: 0.112705, 1 batch cost time 0.51
Train Epoch: 1 [7168/319902 (2%)] Loss: 0.098621, 1 batch cost time 0.51
Train Epoch: 1 [7680/319902 (2%)] Loss: 0.128128, 1 batch cost time 0.51
Train Epoch: 1 [8192/319902 (3%)] Loss: 0.128785, 1 batch cost time 0.51
Train Epoch: 1 [8704/319902 (3%)] Loss: 0.070871, 1 batch cost time 0.51
Train Epoch: 1 [9216/319902 (3%)] Loss: 0.097943, 1 batch cost time 0.51
Train Epoch: 1 [9728/319902 (3%)] Loss: 0.088378, 1 batch cost time 0.51
Train Epoch: 1 [10240/319902 (3%)] Loss: 0.115463, 1 batch cost time 0.51
Train Epoch: 1 [10752/319902 (3%)] Loss: 0.115159, 1 batch cost time 0.51
Train Epoch: 1 [11264/319902 (4%)] Loss: 0.070806, 1 batch cost time 0.51
Train Epoch: 1 [11776/319902 (4%)] Loss: 0.084299, 1 batch cost time 0.51
Train Epoch: 1 [12288/319902 (4%)] Loss: 0.108194, 1 batch cost time 0.51
Train Epoch: 1 [12800/319902 (4%)] Loss: 0.104562, 1 batch cost time 0.51
Train Epoch: 1 [13312/319902 (4%)] Loss: 0.143637, 1 batch cost time 0.51
Train Epoch: 1 [13824/319902 (4%)] Loss: 0.090049, 1 batch cost time 0.51
Train Epoch: 1 [14336/319902 (4%)] Loss: 0.070471, 1 batch cost time 0.51
Train Epoch: 1 [14848/319902 (5%)] Loss: 0.063900, 1 batch cost time 0.51
Train Epoch: 1 [15360/319902 (5%)] Loss: 0.066846, 1 batch cost time 0.51
Train Epoch: 1 [15872/319902 (5%)] Loss: 0.140183, 1 batch cost time 0.51
Train Epoch: 1 [16384/319902 (5%)] Loss: 0.074958, 1 batch cost time 0.51
Train Epoch: 1 [16896/319902 (5%)] Loss: 0.151771, 1 batch cost time 0.51
Train Epoch: 1 [17408/319902 (5%)] Loss: 0.129109, 1 batch cost time 0.51
Train Epoch: 1 [17920/319902 (6%)] Loss: 0.089139, 1 batch cost time 0.51
Train Epoch: 1 [18432/319902 (6%)] Loss: 0.118081, 1 batch cost time 0.51
Train Epoch: 1 [18944/319902 (6%)] Loss: 0.076489, 1 batch cost time 0.51
Train Epoch: 1 [19456/319902 (6%)] Loss: 0.073504, 1 batch cost time 0.51
Train Epoch: 1 [19968/319902 (6%)] Loss: 0.075881, 1 batch cost time 0.51
Train Epoch: 1 [20480/319902 (6%)] Loss: 0.112155, 1 batch cost time 0.51
Train Epoch: 1 [20992/319902 (7%)] Loss: 0.082639, 1 batch cost time 0.51
Train Epoch: 1 [21504/319902 (7%)] Loss: 0.093387, 1 batch cost time 0.51
Train Epoch: 1 [22016/319902 (7%)] Loss: 0.035102, 1 batch cost time 0.51
Train Epoch: 1 [22528/319902 (7%)] Loss: 0.097011, 1 batch cost time 0.51
Train Epoch: 1 [23040/319902 (7%)] Loss: 0.105647, 1 batch cost time 0.51
Train Epoch: 1 [23552/319902 (7%)] Loss: 0.082917, 1 batch cost time 0.51
Train Epoch: 1 [24064/319902 (8%)] Loss: 0.098863, 1 batch cost time 0.51
Train Epoch: 1 [24576/319902 (8%)] Loss: 0.107248, 1 batch cost time 0.51
Train Epoch: 1 [25088/319902 (8%)] Loss: 0.110232, 1 batch cost time 0.51
Train Epoch: 1 [25600/319902 (8%)] Loss: 0.063536, 1 batch cost time 0.51
Train Epoch: 1 [26112/319902 (8%)] Loss: 0.127150, 1 batch cost time 0.51
Train Epoch: 1 [26624/319902 (8%)] Loss: 0.106919, 1 batch cost time 0.51
Train Epoch: 1 [27136/319902 (8%)] Loss: 0.101437, 1 batch cost time 0.51
Train Epoch: 1 [27648/319902 (9%)] Loss: 0.095331, 1 batch cost time 0.51
Train Epoch: 1 [28160/319902 (9%)] Loss: 0.114563, 1 batch cost time 0.51
Train Epoch: 1 [28672/319902 (9%)] Loss: 0.104255, 1 batch cost time 0.51
Train Epoch: 1 [29184/319902 (9%)] Loss: 0.079429, 1 batch cost time 0.51
Train Epoch: 1 [29696/319902 (9%)] Loss: 0.084167, 1 batch cost time 0.51
Train Epoch: 1 [30208/319902 (9%)] Loss: 0.108893, 1 batch cost time 0.51
Train Epoch: 1 [30720/319902 (10%)] Loss: 0.068916, 1 batch cost time 0.51
Train Epoch: 1 [31232/319902 (10%)] Loss: 0.114803, 1 batch cost time 0.51
Train Epoch: 1 [31744/319902 (10%)] Loss: 0.059847, 1 batch cost time 0.51
Train Epoch: 1 [32256/319902 (10%)] Loss: 0.156899, 1 batch cost time 0.51
Train Epoch: 1 [32768/319902 (10%)] Loss: 0.089222, 1 batch cost time 0.51
Train Epoch: 1 [33280/319902 (10%)] Loss: 0.058553, 1 batch cost time 0.51
Train Epoch: 1 [33792/319902 (11%)] Loss: 0.081422, 1 batch cost time 0.51
Train Epoch: 1 [34304/319902 (11%)] Loss: 0.113453, 1 batch cost time 0.51
Train Epoch: 1 [34816/319902 (11%)] Loss: 0.047094, 1 batch cost time 0.51
Train Epoch: 1 [35328/319902 (11%)] Loss: 0.092237, 1 batch cost time 0.51
Train Epoch: 1 [35840/319902 (11%)] Loss: 0.096799, 1 batch cost time 0.51
Train Epoch: 1 [36352/319902 (11%)] Loss: 0.095183, 1 batch cost time 0.51
Train Epoch: 1 [36864/319902 (12%)] Loss: 0.096672, 1 batch cost time 0.51
Train Epoch: 1 [37376/319902 (12%)] Loss: 0.091461, 1 batch cost time 0.51
Train Epoch: 1 [37888/319902 (12%)] Loss: 0.073339, 1 batch cost time 0.51
Train Epoch: 1 [38400/319902 (12%)] Loss: 0.081089, 1 batch cost time 0.51
Train Epoch: 1 [38912/319902 (12%)] Loss: 0.096442, 1 batch cost time 0.51
Train Epoch: 1 [39424/319902 (12%)] Loss: 0.142254, 1 batch cost time 0.51
Train Epoch: 1 [39936/319902 (12%)] Loss: 0.097023, 1 batch cost time 0.51
Train Epoch: 1 [40448/319902 (13%)] Loss: 0.063761, 1 batch cost time 0.51
Train Epoch: 1 [40960/319902 (13%)] Loss: 0.053832, 1 batch cost time 0.51
Train Epoch: 1 [41472/319902 (13%)] Loss: 0.089136, 1 batch cost time 0.51
Train Epoch: 1 [41984/319902 (13%)] Loss: 0.099732, 1 batch cost time 0.51
Train Epoch: 1 [42496/319902 (13%)] Loss: 0.080231, 1 batch cost time 0.51
Train Epoch: 1 [43008/319902 (13%)] Loss: 0.099710, 1 batch cost time 0.51
Train Epoch: 1 [43520/319902 (14%)] Loss: 0.110392, 1 batch cost time 0.51
Train Epoch: 1 [44032/319902 (14%)] Loss: 0.098718, 1 batch cost time 0.51
Train Epoch: 1 [44544/319902 (14%)] Loss: 0.126805, 1 batch cost time 0.51
Train Epoch: 1 [45056/319902 (14%)] Loss: 0.075226, 1 batch cost time 0.51
Train Epoch: 1 [45568/319902 (14%)] Loss: 0.071864, 1 batch cost time 0.51
Train Epoch: 1 [46080/319902 (14%)] Loss: 0.088573, 1 batch cost time 0.51
Train Epoch: 1 [46592/319902 (15%)] Loss: 0.066496, 1 batch cost time 0.51
Train Epoch: 1 [47104/319902 (15%)] Loss: 0.066720, 1 batch cost time 0.51
Train Epoch: 1 [47616/319902 (15%)] Loss: 0.044090, 1 batch cost time 0.51
Train Epoch: 1 [48128/319902 (15%)] Loss: 0.117029, 1 batch cost time 0.51
Train Epoch: 1 [48640/319902 (15%)] Loss: 0.069977, 1 batch cost time 0.51
Train Epoch: 1 [49152/319902 (15%)] Loss: 0.073620, 1 batch cost time 0.51
Train Epoch: 1 [49664/319902 (16%)] Loss: 0.033485, 1 batch cost time 0.51
Train Epoch: 1 [50176/319902 (16%)] Loss: 0.080132, 1 batch cost time 0.51
Train Epoch: 1 [50688/319902 (16%)] Loss: 0.070312, 1 batch cost time 0.51
Train Epoch: 1 [51200/319902 (16%)] Loss: 0.095393, 1 batch cost time 0.51
Train Epoch: 1 [51712/319902 (16%)] Loss: 0.059365, 1 batch cost time 0.51
Train Epoch: 1 [52224/319902 (16%)] Loss: 0.060861, 1 batch cost time 0.51
Train Epoch: 1 [52736/319902 (16%)] Loss: 0.077076, 1 batch cost time 0.51
Train Epoch: 1 [53248/319902 (17%)] Loss: 0.073832, 1 batch cost time 0.51
Train Epoch: 1 [53760/319902 (17%)] Loss: 0.090255, 1 batch cost time 0.51
Train Epoch: 1 [54272/319902 (17%)] Loss: 0.053943, 1 batch cost time 0.51
Train Epoch: 1 [54784/319902 (17%)] Loss: 0.066870, 1 batch cost time 0.51
Train Epoch: 1 [55296/319902 (17%)] Loss: 0.025560, 1 batch cost time 0.51
Train Epoch: 1 [55808/319902 (17%)] Loss: 0.071087, 1 batch cost time 0.51
Train Epoch: 1 [56320/319902 (18%)] Loss: 0.093564, 1 batch cost time 0.51
Train Epoch: 1 [56832/319902 (18%)] Loss: 0.050840, 1 batch cost time 0.51
Train Epoch: 1 [57344/319902 (18%)] Loss: 0.129039, 1 batch cost time 0.51
Train Epoch: 1 [57856/319902 (18%)] Loss: 0.097797, 1 batch cost time 0.51
Train Epoch: 1 [58368/319902 (18%)] Loss: 0.128121, 1 batch cost time 0.51
Train Epoch: 1 [58880/319902 (18%)] Loss: 0.066398, 1 batch cost time 0.51
Train Epoch: 1 [59392/319902 (19%)] Loss: 0.123832, 1 batch cost time 0.51
Train Epoch: 1 [59904/319902 (19%)] Loss: 0.089329, 1 batch cost time 0.51
Train Epoch: 1 [60416/319902 (19%)] Loss: 0.083447, 1 batch cost time 0.51
Train Epoch: 1 [60928/319902 (19%)] Loss: 0.076065, 1 batch cost time 0.51
Train Epoch: 1 [61440/319902 (19%)] Loss: 0.101086, 1 batch cost time 0.51
Train Epoch: 1 [61952/319902 (19%)] Loss: 0.089401, 1 batch cost time 0.51
Train Epoch: 1 [62464/319902 (20%)] Loss: 0.104713, 1 batch cost time 0.51
Train Epoch: 1 [62976/319902 (20%)] Loss: 0.057811, 1 batch cost time 0.51
Train Epoch: 1 [63488/319902 (20%)] Loss: 0.096001, 1 batch cost time 0.51
Train Epoch: 1 [64000/319902 (20%)] Loss: 0.102850, 1 batch cost time 0.51
Train Epoch: 1 [64512/319902 (20%)] Loss: 0.058356, 1 batch cost time 0.51
Train Epoch: 1 [65024/319902 (20%)] Loss: 0.145146, 1 batch cost time 0.51
Train Epoch: 1 [65536/319902 (20%)] Loss: 0.070606, 1 batch cost time 0.51
Train Epoch: 1 [66048/319902 (21%)] Loss: 0.075498, 1 batch cost time 0.51
Train Epoch: 1 [66560/319902 (21%)] Loss: 0.078838, 1 batch cost time 0.51
Train Epoch: 1 [67072/319902 (21%)] Loss: 0.068790, 1 batch cost time 0.51
Train Epoch: 1 [67584/319902 (21%)] Loss: 0.126810, 1 batch cost time 0.51
Train Epoch: 1 [68096/319902 (21%)] Loss: 0.056467, 1 batch cost time 0.51
Train Epoch: 1 [68608/319902 (21%)] Loss: 0.065088, 1 batch cost time 0.51
Train Epoch: 1 [69120/319902 (22%)] Loss: 0.051876, 1 batch cost time 0.51
Train Epoch: 1 [69632/319902 (22%)] Loss: 0.051369, 1 batch cost time 0.51
Train Epoch: 1 [70144/319902 (22%)] Loss: 0.058596, 1 batch cost time 0.51
Train Epoch: 1 [70656/319902 (22%)] Loss: 0.073436, 1 batch cost time 0.51
Train Epoch: 1 [71168/319902 (22%)] Loss: 0.050305, 1 batch cost time 0.51
Train Epoch: 1 [71680/319902 (22%)] Loss: 0.043172, 1 batch cost time 0.51
Train Epoch: 1 [72192/319902 (23%)] Loss: 0.084571, 1 batch cost time 0.51
Train Epoch: 1 [72704/319902 (23%)] Loss: 0.086104, 1 batch cost time 0.51
Train Epoch: 1 [73216/319902 (23%)] Loss: 0.085142, 1 batch cost time 0.51
Train Epoch: 1 [73728/319902 (23%)] Loss: 0.096010, 1 batch cost time 0.51
Train Epoch: 1 [74240/319902 (23%)] Loss: 0.075156, 1 batch cost time 0.51
Train Epoch: 1 [74752/319902 (23%)] Loss: 0.076107, 1 batch cost time 0.51
Train Epoch: 1 [75264/319902 (24%)] Loss: 0.144576, 1 batch cost time 0.51
Train Epoch: 1 [75776/319902 (24%)] Loss: 0.102737, 1 batch cost time 0.51
Train Epoch: 1 [76288/319902 (24%)] Loss: 0.069603, 1 batch cost time 0.51
Train Epoch: 1 [76800/319902 (24%)] Loss: 0.071096, 1 batch cost time 0.51
Train Epoch: 1 [77312/319902 (24%)] Loss: 0.086113, 1 batch cost time 0.51
Train Epoch: 1 [77824/319902 (24%)] Loss: 0.100249, 1 batch cost time 0.51
Train Epoch: 1 [78336/319902 (24%)] Loss: 0.038140, 1 batch cost time 0.51
Train Epoch: 1 [78848/319902 (25%)] Loss: 0.060224, 1 batch cost time 0.51
Train Epoch: 1 [79360/319902 (25%)] Loss: 0.069941, 1 batch cost time 0.51
Train Epoch: 1 [79872/319902 (25%)] Loss: 0.076450, 1 batch cost time 0.51
Train Epoch: 1 [80384/319902 (25%)] Loss: 0.068033, 1 batch cost time 0.51
Train Epoch: 1 [80896/319902 (25%)] Loss: 0.065072, 1 batch cost time 0.51
Train Epoch: 1 [81408/319902 (25%)] Loss: 0.093594, 1 batch cost time 0.51
Train Epoch: 1 [81920/319902 (26%)] Loss: 0.094200, 1 batch cost time 0.51
Train Epoch: 1 [82432/319902 (26%)] Loss: 0.089378, 1 batch cost time 0.51
Train Epoch: 1 [82944/319902 (26%)] Loss: 0.082677, 1 batch cost time 0.51
Train Epoch: 1 [83456/319902 (26%)] Loss: 0.060659, 1 batch cost time 0.51
Train Epoch: 1 [83968/319902 (26%)] Loss: 0.138836, 1 batch cost time 0.51
Train Epoch: 1 [84480/319902 (26%)] Loss: 0.034095, 1 batch cost time 0.51
Train Epoch: 1 [84992/319902 (27%)] Loss: 0.079138, 1 batch cost time 0.51
Train Epoch: 1 [85504/319902 (27%)] Loss: 0.059572, 1 batch cost time 0.51
Train Epoch: 1 [86016/319902 (27%)] Loss: 0.061995, 1 batch cost time 0.51
Train Epoch: 1 [86528/319902 (27%)] Loss: 0.079628, 1 batch cost time 0.51
Train Epoch: 1 [87040/319902 (27%)] Loss: 0.061560, 1 batch cost time 0.51
Train Epoch: 1 [87552/319902 (27%)] Loss: 0.071010, 1 batch cost time 0.51
Train Epoch: 1 [88064/319902 (28%)] Loss: 0.119274, 1 batch cost time 0.51
Train Epoch: 1 [88576/319902 (28%)] Loss: 0.071614, 1 batch cost time 0.51
Train Epoch: 1 [89088/319902 (28%)] Loss: 0.035133, 1 batch cost time 0.51
Train Epoch: 1 [89600/319902 (28%)] Loss: 0.062424, 1 batch cost time 0.51
Train Epoch: 1 [90112/319902 (28%)] Loss: 0.074300, 1 batch cost time 0.51
Train Epoch: 1 [90624/319902 (28%)] Loss: 0.047148, 1 batch cost time 0.51
Train Epoch: 1 [91136/319902 (28%)] Loss: 0.058367, 1 batch cost time 0.51
Train Epoch: 1 [91648/319902 (29%)] Loss: 0.051570, 1 batch cost time 0.51
Train Epoch: 1 [92160/319902 (29%)] Loss: 0.071389, 1 batch cost time 0.51
Train Epoch: 1 [92672/319902 (29%)] Loss: 0.050865, 1 batch cost time 0.51
Train Epoch: 1 [93184/319902 (29%)] Loss: 0.080128, 1 batch cost time 0.51
Train Epoch: 1 [93696/319902 (29%)] Loss: 0.072345, 1 batch cost time 0.51
Train Epoch: 1 [94208/319902 (29%)] Loss: 0.047281, 1 batch cost time 0.51
Train Epoch: 1 [94720/319902 (30%)] Loss: 0.055638, 1 batch cost time 0.51
Train Epoch: 1 [95232/319902 (30%)] Loss: 0.052451, 1 batch cost time 0.51
Train Epoch: 1 [95744/319902 (30%)] Loss: 0.083893, 1 batch cost time 0.51
Train Epoch: 1 [96256/319902 (30%)] Loss: 0.040375, 1 batch cost time 0.51
Train Epoch: 1 [96768/319902 (30%)] Loss: 0.057039, 1 batch cost time 0.51
Train Epoch: 1 [97280/319902 (30%)] Loss: 0.040440, 1 batch cost time 0.51
Train Epoch: 1 [97792/319902 (31%)] Loss: 0.088951, 1 batch cost time 0.51
Train Epoch: 1 [98304/319902 (31%)] Loss: 0.058158, 1 batch cost time 0.51
Train Epoch: 1 [98816/319902 (31%)] Loss: 0.076679, 1 batch cost time 0.51
Train Epoch: 1 [99328/319902 (31%)] Loss: 0.050080, 1 batch cost time 0.51
Train Epoch: 1 [99840/319902 (31%)] Loss: 0.046718, 1 batch cost time 0.51
Train Epoch: 1 [100352/319902 (31%)] Loss: 0.073921, 1 batch cost time 0.51
Train Epoch: 1 [100864/319902 (32%)] Loss: 0.052461, 1 batch cost time 0.51
Train Epoch: 1 [101376/319902 (32%)] Loss: 0.074075, 1 batch cost time 0.51
Train Epoch: 1 [101888/319902 (32%)] Loss: 0.043146, 1 batch cost time 0.51
Train Epoch: 1 [102400/319902 (32%)] Loss: 0.047522, 1 batch cost time 0.51
Train Epoch: 1 [102912/319902 (32%)] Loss: 0.087295, 1 batch cost time 0.51
Train Epoch: 1 [103424/319902 (32%)] Loss: 0.052924, 1 batch cost time 0.51
Train Epoch: 1 [103936/319902 (32%)] Loss: 0.097767, 1 batch cost time 0.51
Train Epoch: 1 [104448/319902 (33%)] Loss: 0.072470, 1 batch cost time 0.51
Train Epoch: 1 [104960/319902 (33%)] Loss: 0.054150, 1 batch cost time 0.51
Train Epoch: 1 [105472/319902 (33%)] Loss: 0.071324, 1 batch cost time 0.51
Train Epoch: 1 [105984/319902 (33%)] Loss: 0.049026, 1 batch cost time 0.51
Train Epoch: 1 [106496/319902 (33%)] Loss: 0.095249, 1 batch cost time 0.51
Train Epoch: 1 [107008/319902 (33%)] Loss: 0.048976, 1 batch cost time 0.51
Train Epoch: 1 [107520/319902 (34%)] Loss: 0.079972, 1 batch cost time 0.51
Train Epoch: 1 [108032/319902 (34%)] Loss: 0.078366, 1 batch cost time 0.51
Train Epoch: 1 [108544/319902 (34%)] Loss: 0.035465, 1 batch cost time 0.51
Train Epoch: 1 [109056/319902 (34%)] Loss: 0.053320, 1 batch cost time 0.51
Train Epoch: 1 [109568/319902 (34%)] Loss: 0.035382, 1 batch cost time 0.51
Train Epoch: 1 [110080/319902 (34%)] Loss: 0.071716, 1 batch cost time 0.51
Train Epoch: 1 [110592/319902 (35%)] Loss: 0.062557, 1 batch cost time 0.51
Train Epoch: 1 [111104/319902 (35%)] Loss: 0.051931, 1 batch cost time 0.51
Train Epoch: 1 [111616/319902 (35%)] Loss: 0.104865, 1 batch cost time 0.51
Train Epoch: 1 [112128/319902 (35%)] Loss: 0.032456, 1 batch cost time 0.51
Train Epoch: 1 [112640/319902 (35%)] Loss: 0.058879, 1 batch cost time 0.51
Train Epoch: 1 [113152/319902 (35%)] Loss: 0.059731, 1 batch cost time 0.51
Train Epoch: 1 [113664/319902 (36%)] Loss: 0.052644, 1 batch cost time 0.51
Train Epoch: 1 [114176/319902 (36%)] Loss: 0.055393, 1 batch cost time 0.51
Train Epoch: 1 [114688/319902 (36%)] Loss: 0.088008, 1 batch cost time 0.51
Train Epoch: 1 [115200/319902 (36%)] Loss: 0.053334, 1 batch cost time 0.51
Train Epoch: 1 [115712/319902 (36%)] Loss: 0.092702, 1 batch cost time 0.51
Train Epoch: 1 [116224/319902 (36%)] Loss: 0.071629, 1 batch cost time 0.51
Train Epoch: 1 [116736/319902 (36%)] Loss: 0.060165, 1 batch cost time 0.51
Train Epoch: 1 [117248/319902 (37%)] Loss: 0.039484, 1 batch cost time 0.51
Train Epoch: 1 [117760/319902 (37%)] Loss: 0.061447, 1 batch cost time 0.51
Train Epoch: 1 [118272/319902 (37%)] Loss: 0.030730, 1 batch cost time 0.51
Train Epoch: 1 [118784/319902 (37%)] Loss: 0.103796, 1 batch cost time 0.51
Train Epoch: 1 [119296/319902 (37%)] Loss: 0.121911, 1 batch cost time 0.51
Train Epoch: 1 [119808/319902 (37%)] Loss: 0.065664, 1 batch cost time 0.51
Train Epoch: 1 [120320/319902 (38%)] Loss: 0.039156, 1 batch cost time 0.51
Train Epoch: 1 [120832/319902 (38%)] Loss: 0.074076, 1 batch cost time 0.51
Train Epoch: 1 [121344/319902 (38%)] Loss: 0.030315, 1 batch cost time 0.51
Train Epoch: 1 [121856/319902 (38%)] Loss: 0.057568, 1 batch cost time 0.51
Train Epoch: 1 [122368/319902 (38%)] Loss: 0.084489, 1 batch cost time 0.51
Train Epoch: 1 [122880/319902 (38%)] Loss: 0.070920, 1 batch cost time 0.51
Train Epoch: 1 [123392/319902 (39%)] Loss: 0.047197, 1 batch cost time 0.51
Train Epoch: 1 [123904/319902 (39%)] Loss: 0.024091, 1 batch cost time 0.51
Train Epoch: 1 [124416/319902 (39%)] Loss: 0.067543, 1 batch cost time 0.51
Train Epoch: 1 [124928/319902 (39%)] Loss: 0.042545, 1 batch cost time 0.51
Train Epoch: 1 [125440/319902 (39%)] Loss: 0.051525, 1 batch cost time 0.51
Train Epoch: 1 [125952/319902 (39%)] Loss: 0.052065, 1 batch cost time 0.51
Train Epoch: 1 [126464/319902 (40%)] Loss: 0.074280, 1 batch cost time 0.51
Train Epoch: 1 [126976/319902 (40%)] Loss: 0.034814, 1 batch cost time 0.51
Train Epoch: 1 [127488/319902 (40%)] Loss: 0.039909, 1 batch cost time 0.51
Train Epoch: 1 [128000/319902 (40%)] Loss: 0.088376, 1 batch cost time 0.51
Train Epoch: 1 [128512/319902 (40%)] Loss: 0.099520, 1 batch cost time 0.51
Train Epoch: 1 [129024/319902 (40%)] Loss: 0.064369, 1 batch cost time 0.51
Train Epoch: 1 [129536/319902 (40%)] Loss: 0.078800, 1 batch cost time 0.51
Train Epoch: 1 [130048/319902 (41%)] Loss: 0.074622, 1 batch cost time 0.51
Train Epoch: 1 [130560/319902 (41%)] Loss: 0.037161, 1 batch cost time 0.51
Train Epoch: 1 [131072/319902 (41%)] Loss: 0.090787, 1 batch cost time 0.51
Train Epoch: 1 [131584/319902 (41%)] Loss: 0.041436, 1 batch cost time 0.51
Train Epoch: 1 [132096/319902 (41%)] Loss: 0.094816, 1 batch cost time 0.51
Train Epoch: 1 [132608/319902 (41%)] Loss: 0.041346, 1 batch cost time 0.51
Train Epoch: 1 [133120/319902 (42%)] Loss: 0.063249, 1 batch cost time 0.51
Train Epoch: 1 [133632/319902 (42%)] Loss: 0.035059, 1 batch cost time 0.51
Train Epoch: 1 [134144/319902 (42%)] Loss: 0.057684, 1 batch cost time 0.51
Train Epoch: 1 [134656/319902 (42%)] Loss: 0.062837, 1 batch cost time 0.51
Train Epoch: 1 [135168/319902 (42%)] Loss: 0.068615, 1 batch cost time 0.51
Train Epoch: 1 [135680/319902 (42%)] Loss: 0.057547, 1 batch cost time 0.51
Train Epoch: 1 [136192/319902 (43%)] Loss: 0.057353, 1 batch cost time 0.51
Train Epoch: 1 [136704/319902 (43%)] Loss: 0.074900, 1 batch cost time 0.51
Train Epoch: 1 [137216/319902 (43%)] Loss: 0.032370, 1 batch cost time 0.51
Train Epoch: 1 [137728/319902 (43%)] Loss: 0.057067, 1 batch cost time 0.51
Train Epoch: 1 [138240/319902 (43%)] Loss: 0.039813, 1 batch cost time 0.51
Train Epoch: 1 [138752/319902 (43%)] Loss: 0.062061, 1 batch cost time 0.51
Train Epoch: 1 [139264/319902 (44%)] Loss: 0.046633, 1 batch cost time 0.51
Train Epoch: 1 [139776/319902 (44%)] Loss: 0.099820, 1 batch cost time 0.51
Train Epoch: 1 [140288/319902 (44%)] Loss: 0.071398, 1 batch cost time 0.51
Train Epoch: 1 [140800/319902 (44%)] Loss: 0.064955, 1 batch cost time 0.51
Train Epoch: 1 [141312/319902 (44%)] Loss: 0.071737, 1 batch cost time 0.51
Train Epoch: 1 [141824/319902 (44%)] Loss: 0.049970, 1 batch cost time 0.51
Train Epoch: 1 [142336/319902 (44%)] Loss: 0.053831, 1 batch cost time 0.51
Train Epoch: 1 [142848/319902 (45%)] Loss: 0.046505, 1 batch cost time 0.51
Train Epoch: 1 [143360/319902 (45%)] Loss: 0.027224, 1 batch cost time 0.51
Train Epoch: 1 [143872/319902 (45%)] Loss: 0.052558, 1 batch cost time 0.51
Train Epoch: 1 [144384/319902 (45%)] Loss: 0.032788, 1 batch cost time 0.51
Train Epoch: 1 [144896/319902 (45%)] Loss: 0.058648, 1 batch cost time 0.51
Train Epoch: 1 [145408/319902 (45%)] Loss: 0.037570, 1 batch cost time 0.51
Train Epoch: 1 [145920/319902 (46%)] Loss: 0.090424, 1 batch cost time 0.51
Train Epoch: 1 [146432/319902 (46%)] Loss: 0.046154, 1 batch cost time 0.51
Train Epoch: 1 [146944/319902 (46%)] Loss: 0.087569, 1 batch cost time 0.51
Train Epoch: 1 [147456/319902 (46%)] Loss: 0.037890, 1 batch cost time 0.51
Train Epoch: 1 [147968/319902 (46%)] Loss: 0.047449, 1 batch cost time 0.51
Train Epoch: 1 [148480/319902 (46%)] Loss: 0.045980, 1 batch cost time 0.51
Train Epoch: 1 [148992/319902 (47%)] Loss: 0.056576, 1 batch cost time 0.51
Train Epoch: 1 [149504/319902 (47%)] Loss: 0.053247, 1 batch cost time 0.51
Train Epoch: 1 [150016/319902 (47%)] Loss: 0.066056, 1 batch cost time 0.51
Train Epoch: 1 [150528/319902 (47%)] Loss: 0.057646, 1 batch cost time 0.51
Train Epoch: 1 [151040/319902 (47%)] Loss: 0.041297, 1 batch cost time 0.51
Train Epoch: 1 [151552/319902 (47%)] Loss: 0.074343, 1 batch cost time 0.51
Train Epoch: 1 [152064/319902 (48%)] Loss: 0.062519, 1 batch cost time 0.51
Train Epoch: 1 [152576/319902 (48%)] Loss: 0.090760, 1 batch cost time 0.51
Train Epoch: 1 [153088/319902 (48%)] Loss: 0.089846, 1 batch cost time 0.51
Train Epoch: 1 [153600/319902 (48%)] Loss: 0.055272, 1 batch cost time 0.51
Train Epoch: 1 [154112/319902 (48%)] Loss: 0.078671, 1 batch cost time 0.51
Train Epoch: 1 [154624/319902 (48%)] Loss: 0.055373, 1 batch cost time 0.51
Train Epoch: 1 [155136/319902 (48%)] Loss: 0.064598, 1 batch cost time 0.51
Train Epoch: 1 [155648/319902 (49%)] Loss: 0.061472, 1 batch cost time 0.51
Train Epoch: 1 [156160/319902 (49%)] Loss: 0.069352, 1 batch cost time 0.51
Train Epoch: 1 [156672/319902 (49%)] Loss: 0.076496, 1 batch cost time 0.51
Train Epoch: 1 [157184/319902 (49%)] Loss: 0.055702, 1 batch cost time 0.51
Train Epoch: 1 [157696/319902 (49%)] Loss: 0.077875, 1 batch cost time 0.51
Train Epoch: 1 [158208/319902 (49%)] Loss: 0.079375, 1 batch cost time 0.51
Train Epoch: 1 [158720/319902 (50%)] Loss: 0.047437, 1 batch cost time 0.51
Train Epoch: 1 [159232/319902 (50%)] Loss: 0.038045, 1 batch cost time 0.51
Train Epoch: 1 [159744/319902 (50%)] Loss: 0.058015, 1 batch cost time 0.51
Train Epoch: 1 [160256/319902 (50%)] Loss: 0.049617, 1 batch cost time 0.51
Train Epoch: 1 [160768/319902 (50%)] Loss: 0.058418, 1 batch cost time 0.51
Train Epoch: 1 [161280/319902 (50%)] Loss: 0.054406, 1 batch cost time 0.51
Train Epoch: 1 [161792/319902 (51%)] Loss: 0.038804, 1 batch cost time 0.51
Train Epoch: 1 [162304/319902 (51%)] Loss: 0.034607, 1 batch cost time 0.51
Train Epoch: 1 [162816/319902 (51%)] Loss: 0.048919, 1 batch cost time 0.51
Train Epoch: 1 [163328/319902 (51%)] Loss: 0.052467, 1 batch cost time 0.51
Train Epoch: 1 [163840/319902 (51%)] Loss: 0.035288, 1 batch cost time 0.51
Train Epoch: 1 [164352/319902 (51%)] Loss: 0.039051, 1 batch cost time 0.51
Train Epoch: 1 [164864/319902 (52%)] Loss: 0.043677, 1 batch cost time 0.51
Train Epoch: 1 [165376/319902 (52%)] Loss: 0.053195, 1 batch cost time 0.51
Train Epoch: 1 [165888/319902 (52%)] Loss: 0.036193, 1 batch cost time 0.51
Train Epoch: 1 [166400/319902 (52%)] Loss: 0.045658, 1 batch cost time 0.51
Train Epoch: 1 [166912/319902 (52%)] Loss: 0.060137, 1 batch cost time 0.51
Train Epoch: 1 [167424/319902 (52%)] Loss: 0.025219, 1 batch cost time 0.51
Train Epoch: 1 [167936/319902 (52%)] Loss: 0.029026, 1 batch cost time 0.51
Train Epoch: 1 [168448/319902 (53%)] Loss: 0.037608, 1 batch cost time 0.51
Train Epoch: 1 [168960/319902 (53%)] Loss: 0.046245, 1 batch cost time 0.51
Train Epoch: 1 [169472/319902 (53%)] Loss: 0.054518, 1 batch cost time 0.51
Train Epoch: 1 [169984/319902 (53%)] Loss: 0.044668, 1 batch cost time 0.51
Train Epoch: 1 [170496/319902 (53%)] Loss: 0.049283, 1 batch cost time 0.51
Train Epoch: 1 [171008/319902 (53%)] Loss: 0.025409, 1 batch cost time 0.51
Train Epoch: 1 [171520/319902 (54%)] Loss: 0.044417, 1 batch cost time 0.51
Train Epoch: 1 [172032/319902 (54%)] Loss: 0.043177, 1 batch cost time 0.51
Train Epoch: 1 [172544/319902 (54%)] Loss: 0.034653, 1 batch cost time 0.51
Train Epoch: 1 [173056/319902 (54%)] Loss: 0.075907, 1 batch cost time 0.51
Train Epoch: 1 [173568/319902 (54%)] Loss: 0.044184, 1 batch cost time 0.51
Train Epoch: 1 [174080/319902 (54%)] Loss: 0.056199, 1 batch cost time 0.51
Train Epoch: 1 [174592/319902 (55%)] Loss: 0.068692, 1 batch cost time 0.51
Train Epoch: 1 [175104/319902 (55%)] Loss: 0.085462, 1 batch cost time 0.51
Train Epoch: 1 [175616/319902 (55%)] Loss: 0.057443, 1 batch cost time 0.51
Train Epoch: 1 [176128/319902 (55%)] Loss: 0.078676, 1 batch cost time 0.51
Train Epoch: 1 [176640/319902 (55%)] Loss: 0.019318, 1 batch cost time 0.51
Train Epoch: 1 [177152/319902 (55%)] Loss: 0.085546, 1 batch cost time 0.51
Train Epoch: 1 [177664/319902 (56%)] Loss: 0.048958, 1 batch cost time 0.51
Train Epoch: 1 [178176/319902 (56%)] Loss: 0.089329, 1 batch cost time 0.51
Train Epoch: 1 [178688/319902 (56%)] Loss: 0.061096, 1 batch cost time 0.51
Train Epoch: 1 [179200/319902 (56%)] Loss: 0.055773, 1 batch cost time 0.51
Train Epoch: 1 [179712/319902 (56%)] Loss: 0.035506, 1 batch cost time 0.51
Train Epoch: 1 [180224/319902 (56%)] Loss: 0.062303, 1 batch cost time 0.51
Train Epoch: 1 [180736/319902 (56%)] Loss: 0.080404, 1 batch cost time 0.51
Train Epoch: 1 [181248/319902 (57%)] Loss: 0.085509, 1 batch cost time 0.51
Train Epoch: 1 [181760/319902 (57%)] Loss: 0.057523, 1 batch cost time 0.51
Train Epoch: 1 [182272/319902 (57%)] Loss: 0.047957, 1 batch cost time 0.51
Train Epoch: 1 [182784/319902 (57%)] Loss: 0.028960, 1 batch cost time 0.51
Train Epoch: 1 [183296/319902 (57%)] Loss: 0.043812, 1 batch cost time 0.51
Train Epoch: 1 [183808/319902 (57%)] Loss: 0.094415, 1 batch cost time 0.51
Train Epoch: 1 [184320/319902 (58%)] Loss: 0.020079, 1 batch cost time 0.51
Train Epoch: 1 [184832/319902 (58%)] Loss: 0.038374, 1 batch cost time 0.51
Train Epoch: 1 [185344/319902 (58%)] Loss: 0.046990, 1 batch cost time 0.51
Train Epoch: 1 [185856/319902 (58%)] Loss: 0.019992, 1 batch cost time 0.51
Train Epoch: 1 [186368/319902 (58%)] Loss: 0.112757, 1 batch cost time 0.51
Train Epoch: 1 [186880/319902 (58%)] Loss: 0.038204, 1 batch cost time 0.51
Train Epoch: 1 [187392/319902 (59%)] Loss: 0.045357, 1 batch cost time 0.51
Train Epoch: 1 [187904/319902 (59%)] Loss: 0.058284, 1 batch cost time 0.51
Train Epoch: 1 [188416/319902 (59%)] Loss: 0.043716, 1 batch cost time 0.51
Train Epoch: 1 [188928/319902 (59%)] Loss: 0.088551, 1 batch cost time 0.51
Train Epoch: 1 [189440/319902 (59%)] Loss: 0.083489, 1 batch cost time 0.51
Train Epoch: 1 [189952/319902 (59%)] Loss: 0.045836, 1 batch cost time 0.51
Train Epoch: 1 [190464/319902 (60%)] Loss: 0.026421, 1 batch cost time 0.51
Train Epoch: 1 [190976/319902 (60%)] Loss: 0.044695, 1 batch cost time 0.51
Train Epoch: 1 [191488/319902 (60%)] Loss: 0.090484, 1 batch cost time 0.51
Train Epoch: 1 [192000/319902 (60%)] Loss: 0.044988, 1 batch cost time 0.51
Train Epoch: 1 [192512/319902 (60%)] Loss: 0.047580, 1 batch cost time 0.51
Train Epoch: 1 [193024/319902 (60%)] Loss: 0.036490, 1 batch cost time 0.51
Train Epoch: 1 [193536/319902 (60%)] Loss: 0.021115, 1 batch cost time 0.51
Train Epoch: 1 [194048/319902 (61%)] Loss: 0.096015, 1 batch cost time 0.51
Train Epoch: 1 [194560/319902 (61%)] Loss: 0.055024, 1 batch cost time 0.51
Train Epoch: 1 [195072/319902 (61%)] Loss: 0.061153, 1 batch cost time 0.51
Train Epoch: 1 [195584/319902 (61%)] Loss: 0.026171, 1 batch cost time 0.51
Train Epoch: 1 [196096/319902 (61%)] Loss: 0.030993, 1 batch cost time 0.51
Train Epoch: 1 [196608/319902 (61%)] Loss: 0.046257, 1 batch cost time 0.51
Train Epoch: 1 [197120/319902 (62%)] Loss: 0.073787, 1 batch cost time 0.51
Train Epoch: 1 [197632/319902 (62%)] Loss: 0.041341, 1 batch cost time 0.51
Train Epoch: 1 [198144/319902 (62%)] Loss: 0.051510, 1 batch cost time 0.51
Train Epoch: 1 [198656/319902 (62%)] Loss: 0.028612, 1 batch cost time 0.51
Train Epoch: 1 [199168/319902 (62%)] Loss: 0.037809, 1 batch cost time 0.51
Train Epoch: 1 [199680/319902 (62%)] Loss: 0.044361, 1 batch cost time 0.51
Train Epoch: 1 [200192/319902 (63%)] Loss: 0.032776, 1 batch cost time 0.51
Train Epoch: 1 [200704/319902 (63%)] Loss: 0.052453, 1 batch cost time 0.51
Train Epoch: 1 [201216/319902 (63%)] Loss: 0.086804, 1 batch cost time 0.51
Train Epoch: 1 [201728/319902 (63%)] Loss: 0.057785, 1 batch cost time 0.51
Train Epoch: 1 [202240/319902 (63%)] Loss: 0.031077, 1 batch cost time 0.51
Train Epoch: 1 [202752/319902 (63%)] Loss: 0.068540, 1 batch cost time 0.51
Train Epoch: 1 [203264/319902 (64%)] Loss: 0.038123, 1 batch cost time 0.51
Train Epoch: 1 [203776/319902 (64%)] Loss: 0.076433, 1 batch cost time 0.51
Train Epoch: 1 [204288/319902 (64%)] Loss: 0.056175, 1 batch cost time 0.51
Train Epoch: 1 [204800/319902 (64%)] Loss: 0.081921, 1 batch cost time 0.51
Train Epoch: 1 [205312/319902 (64%)] Loss: 0.042031, 1 batch cost time 0.51
Train Epoch: 1 [205824/319902 (64%)] Loss: 0.040883, 1 batch cost time 0.51
Train Epoch: 1 [206336/319902 (64%)] Loss: 0.024436, 1 batch cost time 0.51
Train Epoch: 1 [206848/319902 (65%)] Loss: 0.053872, 1 batch cost time 0.51
Train Epoch: 1 [207360/319902 (65%)] Loss: 0.052699, 1 batch cost time 0.51
Train Epoch: 1 [207872/319902 (65%)] Loss: 0.053267, 1 batch cost time 0.51
Train Epoch: 1 [208384/319902 (65%)] Loss: 0.049331, 1 batch cost time 0.51
Train Epoch: 1 [208896/319902 (65%)] Loss: 0.048621, 1 batch cost time 0.51
Train Epoch: 1 [209408/319902 (65%)] Loss: 0.044418, 1 batch cost time 0.51
Train Epoch: 1 [209920/319902 (66%)] Loss: 0.029257, 1 batch cost time 0.51
Train Epoch: 1 [210432/319902 (66%)] Loss: 0.030692, 1 batch cost time 0.51
Train Epoch: 1 [210944/319902 (66%)] Loss: 0.072217, 1 batch cost time 0.51
Train Epoch: 1 [211456/319902 (66%)] Loss: 0.028846, 1 batch cost time 0.51
Train Epoch: 1 [211968/319902 (66%)] Loss: 0.027617, 1 batch cost time 0.51
Train Epoch: 1 [212480/319902 (66%)] Loss: 0.055717, 1 batch cost time 0.51
Train Epoch: 1 [212992/319902 (67%)] Loss: 0.025495, 1 batch cost time 0.51
Train Epoch: 1 [213504/319902 (67%)] Loss: 0.012584, 1 batch cost time 0.51
Train Epoch: 1 [214016/319902 (67%)] Loss: 0.035392, 1 batch cost time 0.51
Train Epoch: 1 [214528/319902 (67%)] Loss: 0.042925, 1 batch cost time 0.51
Train Epoch: 1 [215040/319902 (67%)] Loss: 0.030655, 1 batch cost time 0.51
Train Epoch: 1 [215552/319902 (67%)] Loss: 0.037890, 1 batch cost time 0.51
Train Epoch: 1 [216064/319902 (68%)] Loss: 0.044775, 1 batch cost time 0.51
Train Epoch: 1 [216576/319902 (68%)] Loss: 0.027224, 1 batch cost time 0.51
Train Epoch: 1 [217088/319902 (68%)] Loss: 0.041858, 1 batch cost time 0.51
Train Epoch: 1 [217600/319902 (68%)] Loss: 0.011800, 1 batch cost time 0.51
Train Epoch: 1 [218112/319902 (68%)] Loss: 0.075264, 1 batch cost time 0.51
Train Epoch: 1 [218624/319902 (68%)] Loss: 0.029043, 1 batch cost time 0.51
Train Epoch: 1 [219136/319902 (69%)] Loss: 0.051094, 1 batch cost time 0.51
Train Epoch: 1 [219648/319902 (69%)] Loss: 0.094473, 1 batch cost time 0.51
Train Epoch: 1 [220160/319902 (69%)] Loss: 0.040975, 1 batch cost time 0.51
Train Epoch: 1 [220672/319902 (69%)] Loss: 0.039087, 1 batch cost time 0.51
Train Epoch: 1 [221184/319902 (69%)] Loss: 0.051390, 1 batch cost time 0.51
Train Epoch: 1 [221696/319902 (69%)] Loss: 0.031162, 1 batch cost time 0.51
Train Epoch: 1 [222208/319902 (69%)] Loss: 0.076526, 1 batch cost time 0.51
Train Epoch: 1 [222720/319902 (70%)] Loss: 0.041031, 1 batch cost time 0.51
Train Epoch: 1 [223232/319902 (70%)] Loss: 0.057568, 1 batch cost time 0.51
Train Epoch: 1 [223744/319902 (70%)] Loss: 0.072349, 1 batch cost time 0.51
Train Epoch: 1 [224256/319902 (70%)] Loss: 0.068145, 1 batch cost time 0.51
Train Epoch: 1 [224768/319902 (70%)] Loss: 0.041770, 1 batch cost time 0.51
Train Epoch: 1 [225280/319902 (70%)] Loss: 0.069290, 1 batch cost time 0.51
Train Epoch: 1 [225792/319902 (71%)] Loss: 0.088127, 1 batch cost time 0.51
Train Epoch: 1 [226304/319902 (71%)] Loss: 0.022728, 1 batch cost time 0.51
Train Epoch: 1 [226816/319902 (71%)] Loss: 0.046974, 1 batch cost time 0.51
Train Epoch: 1 [227328/319902 (71%)] Loss: 0.049256, 1 batch cost time 0.51
Train Epoch: 1 [227840/319902 (71%)] Loss: 0.033679, 1 batch cost time 0.51
Train Epoch: 1 [228352/319902 (71%)] Loss: 0.040937, 1 batch cost time 0.51
Train Epoch: 1 [228864/319902 (72%)] Loss: 0.059712, 1 batch cost time 0.51
Train Epoch: 1 [229376/319902 (72%)] Loss: 0.069036, 1 batch cost time 0.51
Train Epoch: 1 [229888/319902 (72%)] Loss: 0.065239, 1 batch cost time 0.51
Train Epoch: 1 [230400/319902 (72%)] Loss: 0.064522, 1 batch cost time 0.51
Train Epoch: 1 [230912/319902 (72%)] Loss: 0.053699, 1 batch cost time 0.51
Train Epoch: 1 [231424/319902 (72%)] Loss: 0.028560, 1 batch cost time 0.51
Train Epoch: 1 [231936/319902 (73%)] Loss: 0.065024, 1 batch cost time 0.51
Train Epoch: 1 [232448/319902 (73%)] Loss: 0.059961, 1 batch cost time 0.51
Train Epoch: 1 [232960/319902 (73%)] Loss: 0.029417, 1 batch cost time 0.51
Train Epoch: 1 [233472/319902 (73%)] Loss: 0.075273, 1 batch cost time 0.51
Train Epoch: 1 [233984/319902 (73%)] Loss: 0.031110, 1 batch cost time 0.51
Train Epoch: 1 [234496/319902 (73%)] Loss: 0.073971, 1 batch cost time 0.51
Train Epoch: 1 [235008/319902 (73%)] Loss: 0.044393, 1 batch cost time 0.51
Train Epoch: 1 [235520/319902 (74%)] Loss: 0.051197, 1 batch cost time 0.51
Train Epoch: 1 [236032/319902 (74%)] Loss: 0.028519, 1 batch cost time 0.51
Train Epoch: 1 [236544/319902 (74%)] Loss: 0.053143, 1 batch cost time 0.51
Train Epoch: 1 [237056/319902 (74%)] Loss: 0.058579, 1 batch cost time 0.51
Train Epoch: 1 [237568/319902 (74%)] Loss: 0.043497, 1 batch cost time 0.51
Train Epoch: 1 [238080/319902 (74%)] Loss: 0.050600, 1 batch cost time 0.51
Train Epoch: 1 [238592/319902 (75%)] Loss: 0.031775, 1 batch cost time 0.51
Train Epoch: 1 [239104/319902 (75%)] Loss: 0.030905, 1 batch cost time 0.51
Train Epoch: 1 [239616/319902 (75%)] Loss: 0.041399, 1 batch cost time 0.51
Train Epoch: 1 [240128/319902 (75%)] Loss: 0.033849, 1 batch cost time 0.51
Train Epoch: 1 [240640/319902 (75%)] Loss: 0.065268, 1 batch cost time 0.51
Train Epoch: 1 [241152/319902 (75%)] Loss: 0.047737, 1 batch cost time 0.51
Train Epoch: 1 [241664/319902 (76%)] Loss: 0.043655, 1 batch cost time 0.51
Train Epoch: 1 [242176/319902 (76%)] Loss: 0.028735, 1 batch cost time 0.51
Train Epoch: 1 [242688/319902 (76%)] Loss: 0.026099, 1 batch cost time 0.51
Train Epoch: 1 [243200/319902 (76%)] Loss: 0.126240, 1 batch cost time 0.51
Train Epoch: 1 [243712/319902 (76%)] Loss: 0.045690, 1 batch cost time 0.51
Train Epoch: 1 [244224/319902 (76%)] Loss: 0.034021, 1 batch cost time 0.51
Train Epoch: 1 [244736/319902 (77%)] Loss: 0.054888, 1 batch cost time 0.51
Train Epoch: 1 [245248/319902 (77%)] Loss: 0.043529, 1 batch cost time 0.51
Train Epoch: 1 [245760/319902 (77%)] Loss: 0.032965, 1 batch cost time 0.51
Train Epoch: 1 [246272/319902 (77%)] Loss: 0.017679, 1 batch cost time 0.51
Train Epoch: 1 [246784/319902 (77%)] Loss: 0.069213, 1 batch cost time 0.51
Train Epoch: 1 [247296/319902 (77%)] Loss: 0.040245, 1 batch cost time 0.51
Train Epoch: 1 [247808/319902 (77%)] Loss: 0.044229, 1 batch cost time 0.51
Train Epoch: 1 [248320/319902 (78%)] Loss: 0.065036, 1 batch cost time 0.51
Train Epoch: 1 [248832/319902 (78%)] Loss: 0.032142, 1 batch cost time 0.51
Train Epoch: 1 [249344/319902 (78%)] Loss: 0.077127, 1 batch cost time 0.51
Train Epoch: 1 [249856/319902 (78%)] Loss: 0.029529, 1 batch cost time 0.51
Train Epoch: 1 [250368/319902 (78%)] Loss: 0.039296, 1 batch cost time 0.51
Train Epoch: 1 [250880/319902 (78%)] Loss: 0.057289, 1 batch cost time 0.51
Train Epoch: 1 [251392/319902 (79%)] Loss: 0.060857, 1 batch cost time 0.51
Train Epoch: 1 [251904/319902 (79%)] Loss: 0.050721, 1 batch cost time 0.51
Train Epoch: 1 [252416/319902 (79%)] Loss: 0.047994, 1 batch cost time 0.51
Train Epoch: 1 [252928/319902 (79%)] Loss: 0.054510, 1 batch cost time 0.51
Train Epoch: 1 [253440/319902 (79%)] Loss: 0.024150, 1 batch cost time 0.51
Train Epoch: 1 [253952/319902 (79%)] Loss: 0.043832, 1 batch cost time 0.51
Train Epoch: 1 [254464/319902 (80%)] Loss: 0.037185, 1 batch cost time 0.51
Train Epoch: 1 [254976/319902 (80%)] Loss: 0.023445, 1 batch cost time 0.51
Train Epoch: 1 [255488/319902 (80%)] Loss: 0.045492, 1 batch cost time 0.51
Train Epoch: 1 [256000/319902 (80%)] Loss: 0.054199, 1 batch cost time 0.51
Train Epoch: 1 [256512/319902 (80%)] Loss: 0.027329, 1 batch cost time 0.51
Train Epoch: 1 [257024/319902 (80%)] Loss: 0.040953, 1 batch cost time 0.51
Train Epoch: 1 [257536/319902 (81%)] Loss: 0.039575, 1 batch cost time 0.51
Train Epoch: 1 [258048/319902 (81%)] Loss: 0.034692, 1 batch cost time 0.51
Train Epoch: 1 [258560/319902 (81%)] Loss: 0.033013, 1 batch cost time 0.51
Train Epoch: 1 [259072/319902 (81%)] Loss: 0.028616, 1 batch cost time 0.51
Train Epoch: 1 [259584/319902 (81%)] Loss: 0.040072, 1 batch cost time 0.51
Train Epoch: 1 [260096/319902 (81%)] Loss: 0.035334, 1 batch cost time 0.51
Train Epoch: 1 [260608/319902 (81%)] Loss: 0.061729, 1 batch cost time 0.51
Train Epoch: 1 [261120/319902 (82%)] Loss: 0.025648, 1 batch cost time 0.51
Train Epoch: 1 [261632/319902 (82%)] Loss: 0.064759, 1 batch cost time 0.51
Train Epoch: 1 [262144/319902 (82%)] Loss: 0.031076, 1 batch cost time 0.51
Train Epoch: 1 [262656/319902 (82%)] Loss: 0.026577, 1 batch cost time 0.51
Train Epoch: 1 [263168/319902 (82%)] Loss: 0.074900, 1 batch cost time 0.51
Train Epoch: 1 [263680/319902 (82%)] Loss: 0.035796, 1 batch cost time 0.51
Train Epoch: 1 [264192/319902 (83%)] Loss: 0.052016, 1 batch cost time 0.51
Train Epoch: 1 [264704/319902 (83%)] Loss: 0.029310, 1 batch cost time 0.51
Train Epoch: 1 [265216/319902 (83%)] Loss: 0.043000, 1 batch cost time 0.51
Train Epoch: 1 [265728/319902 (83%)] Loss: 0.060131, 1 batch cost time 0.51
Train Epoch: 1 [266240/319902 (83%)] Loss: 0.075272, 1 batch cost time 0.51
Train Epoch: 1 [266752/319902 (83%)] Loss: 0.024029, 1 batch cost time 0.51
Train Epoch: 1 [267264/319902 (84%)] Loss: 0.059300, 1 batch cost time 0.51
Train Epoch: 1 [267776/319902 (84%)] Loss: 0.059165, 1 batch cost time 0.51
Train Epoch: 1 [268288/319902 (84%)] Loss: 0.086752, 1 batch cost time 0.51
Train Epoch: 1 [268800/319902 (84%)] Loss: 0.041617, 1 batch cost time 0.51
Train Epoch: 1 [269312/319902 (84%)] Loss: 0.037149, 1 batch cost time 0.51
Train Epoch: 1 [269824/319902 (84%)] Loss: 0.097055, 1 batch cost time 0.51
Train Epoch: 1 [270336/319902 (85%)] Loss: 0.019139, 1 batch cost time 0.51
Train Epoch: 1 [270848/319902 (85%)] Loss: 0.051682, 1 batch cost time 0.51
Train Epoch: 1 [271360/319902 (85%)] Loss: 0.036056, 1 batch cost time 0.51
Train Epoch: 1 [271872/319902 (85%)] Loss: 0.057095, 1 batch cost time 0.51
Train Epoch: 1 [272384/319902 (85%)] Loss: 0.039439, 1 batch cost time 0.51
Train Epoch: 1 [272896/319902 (85%)] Loss: 0.028537, 1 batch cost time 0.51
Train Epoch: 1 [273408/319902 (85%)] Loss: 0.053785, 1 batch cost time 0.51
Train Epoch: 1 [273920/319902 (86%)] Loss: 0.026643, 1 batch cost time 0.53
Train Epoch: 1 [274432/319902 (86%)] Loss: 0.040682, 1 batch cost time 0.51
Train Epoch: 1 [274944/319902 (86%)] Loss: 0.056127, 1 batch cost time 0.51
Train Epoch: 1 [275456/319902 (86%)] Loss: 0.102271, 1 batch cost time 0.51
Train Epoch: 1 [275968/319902 (86%)] Loss: 0.062183, 1 batch cost time 0.51
Train Epoch: 1 [276480/319902 (86%)] Loss: 0.054512, 1 batch cost time 0.51
Train Epoch: 1 [276992/319902 (87%)] Loss: 0.036787, 1 batch cost time 0.51
Train Epoch: 1 [277504/319902 (87%)] Loss: 0.027558, 1 batch cost time 0.51
Train Epoch: 1 [278016/319902 (87%)] Loss: 0.040040, 1 batch cost time 0.51
Train Epoch: 1 [278528/319902 (87%)] Loss: 0.041333, 1 batch cost time 0.51
Train Epoch: 1 [279040/319902 (87%)] Loss: 0.035591, 1 batch cost time 0.51
Train Epoch: 1 [279552/319902 (87%)] Loss: 0.060671, 1 batch cost time 0.51
Train Epoch: 1 [280064/319902 (88%)] Loss: 0.052776, 1 batch cost time 0.51
Train Epoch: 1 [280576/319902 (88%)] Loss: 0.026568, 1 batch cost time 0.51
Train Epoch: 1 [281088/319902 (88%)] Loss: 0.045237, 1 batch cost time 0.51
Train Epoch: 1 [281600/319902 (88%)] Loss: 0.025374, 1 batch cost time 0.51
Train Epoch: 1 [282112/319902 (88%)] Loss: 0.058191, 1 batch cost time 0.51
Train Epoch: 1 [282624/319902 (88%)] Loss: 0.043130, 1 batch cost time 0.51
Train Epoch: 1 [283136/319902 (89%)] Loss: 0.049055, 1 batch cost time 0.51
Train Epoch: 1 [283648/319902 (89%)] Loss: 0.041047, 1 batch cost time 0.51
Train Epoch: 1 [284160/319902 (89%)] Loss: 0.039347, 1 batch cost time 0.51
Train Epoch: 1 [284672/319902 (89%)] Loss: 0.041907, 1 batch cost time 0.51
Train Epoch: 1 [285184/319902 (89%)] Loss: 0.048727, 1 batch cost time 0.51
Train Epoch: 1 [285696/319902 (89%)] Loss: 0.030747, 1 batch cost time 0.51
Train Epoch: 1 [286208/319902 (89%)] Loss: 0.062542, 1 batch cost time 0.51
Train Epoch: 1 [286720/319902 (90%)] Loss: 0.030705, 1 batch cost time 0.51
Train Epoch: 1 [287232/319902 (90%)] Loss: 0.066091, 1 batch cost time 0.51
Train Epoch: 1 [287744/319902 (90%)] Loss: 0.016646, 1 batch cost time 0.51
Train Epoch: 1 [288256/319902 (90%)] Loss: 0.041728, 1 batch cost time 0.51
Train Epoch: 1 [288768/319902 (90%)] Loss: 0.034498, 1 batch cost time 0.51
Train Epoch: 1 [289280/319902 (90%)] Loss: 0.041950, 1 batch cost time 0.51
Train Epoch: 1 [289792/319902 (91%)] Loss: 0.022459, 1 batch cost time 0.51
Train Epoch: 1 [290304/319902 (91%)] Loss: 0.033454, 1 batch cost time 0.51
Train Epoch: 1 [290816/319902 (91%)] Loss: 0.040036, 1 batch cost time 0.51
Train Epoch: 1 [291328/319902 (91%)] Loss: 0.024699, 1 batch cost time 0.51
Train Epoch: 1 [291840/319902 (91%)] Loss: 0.049778, 1 batch cost time 0.51
Train Epoch: 1 [292352/319902 (91%)] Loss: 0.022841, 1 batch cost time 0.51
Train Epoch: 1 [292864/319902 (92%)] Loss: 0.021511, 1 batch cost time 0.51
Train Epoch: 1 [293376/319902 (92%)] Loss: 0.034338, 1 batch cost time 0.51
Train Epoch: 1 [293888/319902 (92%)] Loss: 0.032583, 1 batch cost time 0.51
Train Epoch: 1 [294400/319902 (92%)] Loss: 0.039049, 1 batch cost time 0.51
Train Epoch: 1 [294912/319902 (92%)] Loss: 0.021293, 1 batch cost time 0.51
Train Epoch: 1 [295424/319902 (92%)] Loss: 0.073881, 1 batch cost time 0.51
Train Epoch: 1 [295936/319902 (93%)] Loss: 0.034441, 1 batch cost time 0.51
Train Epoch: 1 [296448/319902 (93%)] Loss: 0.035840, 1 batch cost time 0.51
Train Epoch: 1 [296960/319902 (93%)] Loss: 0.051149, 1 batch cost time 0.51
Train Epoch: 1 [297472/319902 (93%)] Loss: 0.031926, 1 batch cost time 0.51
Train Epoch: 1 [297984/319902 (93%)] Loss: 0.034433, 1 batch cost time 0.51
Train Epoch: 1 [298496/319902 (93%)] Loss: 0.032741, 1 batch cost time 0.51
Train Epoch: 1 [299008/319902 (93%)] Loss: 0.063948, 1 batch cost time 0.51
Train Epoch: 1 [299520/319902 (94%)] Loss: 0.045914, 1 batch cost time 0.51
Train Epoch: 1 [300032/319902 (94%)] Loss: 0.024199, 1 batch cost time 0.51
Train Epoch: 1 [300544/319902 (94%)] Loss: 0.050083, 1 batch cost time 0.51
Train Epoch: 1 [301056/319902 (94%)] Loss: 0.036964, 1 batch cost time 0.51
Train Epoch: 1 [301568/319902 (94%)] Loss: 0.059026, 1 batch cost time 0.51
Train Epoch: 1 [302080/319902 (94%)] Loss: 0.049872, 1 batch cost time 0.51
Train Epoch: 1 [302592/319902 (95%)] Loss: 0.026576, 1 batch cost time 0.51
Train Epoch: 1 [303104/319902 (95%)] Loss: 0.043653, 1 batch cost time 0.51
Train Epoch: 1 [303616/319902 (95%)] Loss: 0.054937, 1 batch cost time 0.51
Train Epoch: 1 [304128/319902 (95%)] Loss: 0.013647, 1 batch cost time 0.51
Train Epoch: 1 [304640/319902 (95%)] Loss: 0.027247, 1 batch cost time 0.51
Train Epoch: 1 [305152/319902 (95%)] Loss: 0.037511, 1 batch cost time 0.51
Train Epoch: 1 [305664/319902 (96%)] Loss: 0.037894, 1 batch cost time 0.51
Train Epoch: 1 [306176/319902 (96%)] Loss: 0.050143, 1 batch cost time 0.51
Train Epoch: 1 [306688/319902 (96%)] Loss: 0.073384, 1 batch cost time 0.51
Train Epoch: 1 [307200/319902 (96%)] Loss: 0.023171, 1 batch cost time 0.51
Train Epoch: 1 [307712/319902 (96%)] Loss: 0.016470, 1 batch cost time 0.51
Train Epoch: 1 [308224/319902 (96%)] Loss: 0.061063, 1 batch cost time 0.51
Train Epoch: 1 [308736/319902 (97%)] Loss: 0.043489, 1 batch cost time 0.51
Train Epoch: 1 [309248/319902 (97%)] Loss: 0.050266, 1 batch cost time 0.51
Train Epoch: 1 [309760/319902 (97%)] Loss: 0.068403, 1 batch cost time 0.51
Train Epoch: 1 [310272/319902 (97%)] Loss: 0.054444, 1 batch cost time 0.51
Train Epoch: 1 [310784/319902 (97%)] Loss: 0.020401, 1 batch cost time 0.51
Train Epoch: 1 [311296/319902 (97%)] Loss: 0.039629, 1 batch cost time 0.51
Train Epoch: 1 [311808/319902 (97%)] Loss: 0.037141, 1 batch cost time 0.51
Train Epoch: 1 [312320/319902 (98%)] Loss: 0.036929, 1 batch cost time 0.51
Train Epoch: 1 [312832/319902 (98%)] Loss: 0.015661, 1 batch cost time 0.51
Train Epoch: 1 [313344/319902 (98%)] Loss: 0.040292, 1 batch cost time 0.51
Train Epoch: 1 [313856/319902 (98%)] Loss: 0.023401, 1 batch cost time 0.51
Train Epoch: 1 [314368/319902 (98%)] Loss: 0.024945, 1 batch cost time 0.51
Train Epoch: 1 [314880/319902 (98%)] Loss: 0.048219, 1 batch cost time 0.51
Train Epoch: 1 [315392/319902 (99%)] Loss: 0.029809, 1 batch cost time 0.51
Train Epoch: 1 [315904/319902 (99%)] Loss: 0.038737, 1 batch cost time 0.51
Train Epoch: 1 [316416/319902 (99%)] Loss: 0.039538, 1 batch cost time 0.51
Train Epoch: 1 [316928/319902 (99%)] Loss: 0.055232, 1 batch cost time 0.51
Train Epoch: 1 [317440/319902 (99%)] Loss: 0.052439, 1 batch cost time 0.51
Train Epoch: 1 [317952/319902 (99%)] Loss: 0.055945, 1 batch cost time 0.51
Train Epoch: 1 [318464/319902 (100%)] Loss: 0.034546, 1 batch cost time 0.51
Train Epoch: 1 [318976/319902 (100%)] Loss: 0.056619, 1 batch cost time 0.51
Train Epoch: 1 [319488/319902 (100%)] Loss: 0.024729, 1 batch cost time 0.51
training epoch cost 8019.780084848404 seconds
    epoch          : 1
    lr             : 0.0001
    loss           : 0.061760955991982974
    accuracy       : 0.9037177370948379
    f_measure      : 0.25544666867683413
    val_loss       : 0.033807992906076834
    val_accuracy   : 0.9268391927083334
    val_f_measure  : 0.32126307720057745
Saving current best: model_best.pth ...
Train Epoch: 2 [0/319902 (0%)] Loss: 0.069569, 1 batch cost time 0.53
Train Epoch: 2 [512/319902 (0%)] Loss: 0.044987, 1 batch cost time 0.51
Train Epoch: 2 [1024/319902 (0%)] Loss: 0.034201, 1 batch cost time 0.51
Train Epoch: 2 [1536/319902 (0%)] Loss: 0.101630, 1 batch cost time 0.51
Train Epoch: 2 [2048/319902 (1%)] Loss: 0.044409, 1 batch cost time 0.51
Train Epoch: 2 [2560/319902 (1%)] Loss: 0.051116, 1 batch cost time 0.51
Train Epoch: 2 [3072/319902 (1%)] Loss: 0.023555, 1 batch cost time 0.51
Train Epoch: 2 [3584/319902 (1%)] Loss: 0.051034, 1 batch cost time 0.51
Train Epoch: 2 [4096/319902 (1%)] Loss: 0.064183, 1 batch cost time 0.51
Train Epoch: 2 [4608/319902 (1%)] Loss: 0.048773, 1 batch cost time 0.51
Train Epoch: 2 [5120/319902 (2%)] Loss: 0.041473, 1 batch cost time 0.51
Train Epoch: 2 [5632/319902 (2%)] Loss: 0.038826, 1 batch cost time 0.51
Train Epoch: 2 [6144/319902 (2%)] Loss: 0.019917, 1 batch cost time 0.51
Train Epoch: 2 [6656/319902 (2%)] Loss: 0.019217, 1 batch cost time 0.51
Train Epoch: 2 [7168/319902 (2%)] Loss: 0.045245, 1 batch cost time 0.51
Train Epoch: 2 [7680/319902 (2%)] Loss: 0.053379, 1 batch cost time 0.51
Train Epoch: 2 [8192/319902 (3%)] Loss: 0.033983, 1 batch cost time 0.51
Train Epoch: 2 [8704/319902 (3%)] Loss: 0.048703, 1 batch cost time 0.51
Train Epoch: 2 [9216/319902 (3%)] Loss: 0.039029, 1 batch cost time 0.51
Train Epoch: 2 [9728/319902 (3%)] Loss: 0.017892, 1 batch cost time 0.51
Train Epoch: 2 [10240/319902 (3%)] Loss: 0.042350, 1 batch cost time 0.51
Train Epoch: 2 [10752/319902 (3%)] Loss: 0.046436, 1 batch cost time 0.51
Train Epoch: 2 [11264/319902 (4%)] Loss: 0.039867, 1 batch cost time 0.51
Train Epoch: 2 [11776/319902 (4%)] Loss: 0.019898, 1 batch cost time 0.51
Train Epoch: 2 [12288/319902 (4%)] Loss: 0.033576, 1 batch cost time 0.51
Train Epoch: 2 [12800/319902 (4%)] Loss: 0.033036, 1 batch cost time 0.51
Train Epoch: 2 [13312/319902 (4%)] Loss: 0.037223, 1 batch cost time 0.51
Train Epoch: 2 [13824/319902 (4%)] Loss: 0.043325, 1 batch cost time 0.51
Train Epoch: 2 [14336/319902 (4%)] Loss: 0.071391, 1 batch cost time 0.51
Train Epoch: 2 [14848/319902 (5%)] Loss: 0.038631, 1 batch cost time 0.51
Train Epoch: 2 [15360/319902 (5%)] Loss: 0.049948, 1 batch cost time 0.51
Train Epoch: 2 [15872/319902 (5%)] Loss: 0.059943, 1 batch cost time 0.51
Train Epoch: 2 [16384/319902 (5%)] Loss: 0.037698, 1 batch cost time 0.51
Train Epoch: 2 [16896/319902 (5%)] Loss: 0.053856, 1 batch cost time 0.51
Train Epoch: 2 [17408/319902 (5%)] Loss: 0.033662, 1 batch cost time 0.51
Train Epoch: 2 [17920/319902 (6%)] Loss: 0.055609, 1 batch cost time 0.51
Train Epoch: 2 [18432/319902 (6%)] Loss: 0.068509, 1 batch cost time 0.51
Train Epoch: 2 [18944/319902 (6%)] Loss: 0.032467, 1 batch cost time 0.51
Train Epoch: 2 [19456/319902 (6%)] Loss: 0.049705, 1 batch cost time 0.51
Train Epoch: 2 [19968/319902 (6%)] Loss: 0.039790, 1 batch cost time 0.51
Train Epoch: 2 [20480/319902 (6%)] Loss: 0.044024, 1 batch cost time 0.51
Train Epoch: 2 [20992/319902 (7%)] Loss: 0.042812, 1 batch cost time 0.51
Train Epoch: 2 [21504/319902 (7%)] Loss: 0.043028, 1 batch cost time 0.51
Train Epoch: 2 [22016/319902 (7%)] Loss: 0.036521, 1 batch cost time 0.51
Train Epoch: 2 [22528/319902 (7%)] Loss: 0.034798, 1 batch cost time 0.51
Train Epoch: 2 [23040/319902 (7%)] Loss: 0.070425, 1 batch cost time 0.51
Train Epoch: 2 [23552/319902 (7%)] Loss: 0.034838, 1 batch cost time 0.51
Train Epoch: 2 [24064/319902 (8%)] Loss: 0.034717, 1 batch cost time 0.51
Train Epoch: 2 [24576/319902 (8%)] Loss: 0.032479, 1 batch cost time 0.51
Train Epoch: 2 [25088/319902 (8%)] Loss: 0.032119, 1 batch cost time 0.51
Train Epoch: 2 [25600/319902 (8%)] Loss: 0.039656, 1 batch cost time 0.51
Train Epoch: 2 [26112/319902 (8%)] Loss: 0.050806, 1 batch cost time 0.51
Train Epoch: 2 [26624/319902 (8%)] Loss: 0.043607, 1 batch cost time 0.51
Train Epoch: 2 [27136/319902 (8%)] Loss: 0.026663, 1 batch cost time 0.51
Train Epoch: 2 [27648/319902 (9%)] Loss: 0.047547, 1 batch cost time 0.51
Train Epoch: 2 [28160/319902 (9%)] Loss: 0.036308, 1 batch cost time 0.51
Train Epoch: 2 [28672/319902 (9%)] Loss: 0.033166, 1 batch cost time 0.51
Train Epoch: 2 [29184/319902 (9%)] Loss: 0.060617, 1 batch cost time 0.51
Train Epoch: 2 [29696/319902 (9%)] Loss: 0.055704, 1 batch cost time 0.51
Train Epoch: 2 [30208/319902 (9%)] Loss: 0.035456, 1 batch cost time 0.51
Train Epoch: 2 [30720/319902 (10%)] Loss: 0.052135, 1 batch cost time 0.51
Train Epoch: 2 [31232/319902 (10%)] Loss: 0.028044, 1 batch cost time 0.51
Train Epoch: 2 [31744/319902 (10%)] Loss: 0.026703, 1 batch cost time 0.51
Train Epoch: 2 [32256/319902 (10%)] Loss: 0.042619, 1 batch cost time 0.51
Train Epoch: 2 [32768/319902 (10%)] Loss: 0.049185, 1 batch cost time 0.51
Train Epoch: 2 [33280/319902 (10%)] Loss: 0.049532, 1 batch cost time 0.51
Train Epoch: 2 [33792/319902 (11%)] Loss: 0.059229, 1 batch cost time 0.51
Train Epoch: 2 [34304/319902 (11%)] Loss: 0.024249, 1 batch cost time 0.51
Train Epoch: 2 [34816/319902 (11%)] Loss: 0.068859, 1 batch cost time 0.51
Train Epoch: 2 [35328/319902 (11%)] Loss: 0.051073, 1 batch cost time 0.51
Train Epoch: 2 [35840/319902 (11%)] Loss: 0.025261, 1 batch cost time 0.51
Train Epoch: 2 [36352/319902 (11%)] Loss: 0.023005, 1 batch cost time 0.51
Train Epoch: 2 [36864/319902 (12%)] Loss: 0.072646, 1 batch cost time 0.51
Train Epoch: 2 [37376/319902 (12%)] Loss: 0.039231, 1 batch cost time 0.51
Train Epoch: 2 [37888/319902 (12%)] Loss: 0.039008, 1 batch cost time 0.51
Train Epoch: 2 [38400/319902 (12%)] Loss: 0.064035, 1 batch cost time 0.51
Train Epoch: 2 [38912/319902 (12%)] Loss: 0.046075, 1 batch cost time 0.51
Train Epoch: 2 [39424/319902 (12%)] Loss: 0.022811, 1 batch cost time 0.51
Train Epoch: 2 [39936/319902 (12%)] Loss: 0.035563, 1 batch cost time 0.51
Train Epoch: 2 [40448/319902 (13%)] Loss: 0.029059, 1 batch cost time 0.51
Train Epoch: 2 [40960/319902 (13%)] Loss: 0.049203, 1 batch cost time 0.51
Train Epoch: 2 [41472/319902 (13%)] Loss: 0.055824, 1 batch cost time 0.51
Train Epoch: 2 [41984/319902 (13%)] Loss: 0.030779, 1 batch cost time 0.51
Train Epoch: 2 [42496/319902 (13%)] Loss: 0.035741, 1 batch cost time 0.51
Train Epoch: 2 [43008/319902 (13%)] Loss: 0.033435, 1 batch cost time 0.51
Train Epoch: 2 [43520/319902 (14%)] Loss: 0.037902, 1 batch cost time 0.51
Train Epoch: 2 [44032/319902 (14%)] Loss: 0.029128, 1 batch cost time 0.51
Train Epoch: 2 [44544/319902 (14%)] Loss: 0.030953, 1 batch cost time 0.51
Train Epoch: 2 [45056/319902 (14%)] Loss: 0.076372, 1 batch cost time 0.51
Train Epoch: 2 [45568/319902 (14%)] Loss: 0.050450, 1 batch cost time 0.51
Train Epoch: 2 [46080/319902 (14%)] Loss: 0.033754, 1 batch cost time 0.51
Train Epoch: 2 [46592/319902 (15%)] Loss: 0.032987, 1 batch cost time 0.51
Train Epoch: 2 [47104/319902 (15%)] Loss: 0.029469, 1 batch cost time 0.51
Train Epoch: 2 [47616/319902 (15%)] Loss: 0.058899, 1 batch cost time 0.51
Train Epoch: 2 [48128/319902 (15%)] Loss: 0.059659, 1 batch cost time 0.51
Train Epoch: 2 [48640/319902 (15%)] Loss: 0.028491, 1 batch cost time 0.51
Train Epoch: 2 [49152/319902 (15%)] Loss: 0.046541, 1 batch cost time 0.51
Train Epoch: 2 [49664/319902 (16%)] Loss: 0.069433, 1 batch cost time 0.51
Train Epoch: 2 [50176/319902 (16%)] Loss: 0.054879, 1 batch cost time 0.51
Train Epoch: 2 [50688/319902 (16%)] Loss: 0.015982, 1 batch cost time 0.51
Train Epoch: 2 [51200/319902 (16%)] Loss: 0.028914, 1 batch cost time 0.51
Train Epoch: 2 [51712/319902 (16%)] Loss: 0.060379, 1 batch cost time 0.51
Train Epoch: 2 [52224/319902 (16%)] Loss: 0.026785, 1 batch cost time 0.51
Train Epoch: 2 [52736/319902 (16%)] Loss: 0.054051, 1 batch cost time 0.51
Train Epoch: 2 [53248/319902 (17%)] Loss: 0.074494, 1 batch cost time 0.51
Train Epoch: 2 [53760/319902 (17%)] Loss: 0.030514, 1 batch cost time 0.51
Train Epoch: 2 [54272/319902 (17%)] Loss: 0.032879, 1 batch cost time 0.51
Train Epoch: 2 [54784/319902 (17%)] Loss: 0.065876, 1 batch cost time 0.51
Train Epoch: 2 [55296/319902 (17%)] Loss: 0.030586, 1 batch cost time 0.51
Train Epoch: 2 [55808/319902 (17%)] Loss: 0.041617, 1 batch cost time 0.51
Train Epoch: 2 [56320/319902 (18%)] Loss: 0.053694, 1 batch cost time 0.51
Train Epoch: 2 [56832/319902 (18%)] Loss: 0.032476, 1 batch cost time 0.51
Train Epoch: 2 [57344/319902 (18%)] Loss: 0.019664, 1 batch cost time 0.51
Train Epoch: 2 [57856/319902 (18%)] Loss: 0.032162, 1 batch cost time 0.51
Train Epoch: 2 [58368/319902 (18%)] Loss: 0.034106, 1 batch cost time 0.51
Train Epoch: 2 [58880/319902 (18%)] Loss: 0.041217, 1 batch cost time 0.51
Train Epoch: 2 [59392/319902 (19%)] Loss: 0.043856, 1 batch cost time 0.51
Train Epoch: 2 [59904/319902 (19%)] Loss: 0.083353, 1 batch cost time 0.51
Train Epoch: 2 [60416/319902 (19%)] Loss: 0.042122, 1 batch cost time 0.51
Train Epoch: 2 [60928/319902 (19%)] Loss: 0.036571, 1 batch cost time 0.51
Train Epoch: 2 [61440/319902 (19%)] Loss: 0.046612, 1 batch cost time 0.51
Train Epoch: 2 [61952/319902 (19%)] Loss: 0.045006, 1 batch cost time 0.51
Train Epoch: 2 [62464/319902 (20%)] Loss: 0.040648, 1 batch cost time 0.51
Train Epoch: 2 [62976/319902 (20%)] Loss: 0.032772, 1 batch cost time 0.51
Train Epoch: 2 [63488/319902 (20%)] Loss: 0.057185, 1 batch cost time 0.51
Train Epoch: 2 [64000/319902 (20%)] Loss: 0.041622, 1 batch cost time 0.51
Train Epoch: 2 [64512/319902 (20%)] Loss: 0.031555, 1 batch cost time 0.51
Train Epoch: 2 [65024/319902 (20%)] Loss: 0.033165, 1 batch cost time 0.51
Train Epoch: 2 [65536/319902 (20%)] Loss: 0.030331, 1 batch cost time 0.51
Train Epoch: 2 [66048/319902 (21%)] Loss: 0.054812, 1 batch cost time 0.51
Train Epoch: 2 [66560/319902 (21%)] Loss: 0.028247, 1 batch cost time 0.51
Train Epoch: 2 [67072/319902 (21%)] Loss: 0.032705, 1 batch cost time 0.51
Train Epoch: 2 [67584/319902 (21%)] Loss: 0.033538, 1 batch cost time 0.51
Train Epoch: 2 [68096/319902 (21%)] Loss: 0.054111, 1 batch cost time 0.51
Train Epoch: 2 [68608/319902 (21%)] Loss: 0.025701, 1 batch cost time 0.51
Train Epoch: 2 [69120/319902 (22%)] Loss: 0.040148, 1 batch cost time 0.51
Train Epoch: 2 [69632/319902 (22%)] Loss: 0.037165, 1 batch cost time 0.51
Train Epoch: 2 [70144/319902 (22%)] Loss: 0.045328, 1 batch cost time 0.51
Train Epoch: 2 [70656/319902 (22%)] Loss: 0.052211, 1 batch cost time 0.51
Train Epoch: 2 [71168/319902 (22%)] Loss: 0.041012, 1 batch cost time 0.51
Train Epoch: 2 [71680/319902 (22%)] Loss: 0.076695, 1 batch cost time 0.51
Train Epoch: 2 [72192/319902 (23%)] Loss: 0.084560, 1 batch cost time 0.51
Train Epoch: 2 [72704/319902 (23%)] Loss: 0.011411, 1 batch cost time 0.51
Train Epoch: 2 [73216/319902 (23%)] Loss: 0.036654, 1 batch cost time 0.51
Train Epoch: 2 [73728/319902 (23%)] Loss: 0.026727, 1 batch cost time 0.51
Train Epoch: 2 [74240/319902 (23%)] Loss: 0.032127, 1 batch cost time 0.51
Train Epoch: 2 [74752/319902 (23%)] Loss: 0.046282, 1 batch cost time 0.51
Train Epoch: 2 [75264/319902 (24%)] Loss: 0.014702, 1 batch cost time 0.51
Train Epoch: 2 [75776/319902 (24%)] Loss: 0.040082, 1 batch cost time 0.51
Train Epoch: 2 [76288/319902 (24%)] Loss: 0.054371, 1 batch cost time 0.51
Train Epoch: 2 [76800/319902 (24%)] Loss: 0.050220, 1 batch cost time 0.51
Train Epoch: 2 [77312/319902 (24%)] Loss: 0.057945, 1 batch cost time 0.51
Train Epoch: 2 [77824/319902 (24%)] Loss: 0.048118, 1 batch cost time 0.51
Train Epoch: 2 [78336/319902 (24%)] Loss: 0.036935, 1 batch cost time 0.51
Train Epoch: 2 [78848/319902 (25%)] Loss: 0.040030, 1 batch cost time 0.51
Train Epoch: 2 [79360/319902 (25%)] Loss: 0.024790, 1 batch cost time 0.51
Train Epoch: 2 [79872/319902 (25%)] Loss: 0.027984, 1 batch cost time 0.51
Train Epoch: 2 [80384/319902 (25%)] Loss: 0.034472, 1 batch cost time 0.51
Train Epoch: 2 [80896/319902 (25%)] Loss: 0.040485, 1 batch cost time 0.51
Train Epoch: 2 [81408/319902 (25%)] Loss: 0.041320, 1 batch cost time 0.51
Train Epoch: 2 [81920/319902 (26%)] Loss: 0.021095, 1 batch cost time 0.51
Train Epoch: 2 [82432/319902 (26%)] Loss: 0.071817, 1 batch cost time 0.51
Train Epoch: 2 [82944/319902 (26%)] Loss: 0.048928, 1 batch cost time 0.51
Train Epoch: 2 [83456/319902 (26%)] Loss: 0.036038, 1 batch cost time 0.51
Train Epoch: 2 [83968/319902 (26%)] Loss: 0.059433, 1 batch cost time 0.51
Train Epoch: 2 [84480/319902 (26%)] Loss: 0.025293, 1 batch cost time 0.51
Train Epoch: 2 [84992/319902 (27%)] Loss: 0.057075, 1 batch cost time 0.51
Train Epoch: 2 [85504/319902 (27%)] Loss: 0.061994, 1 batch cost time 0.51
Train Epoch: 2 [86016/319902 (27%)] Loss: 0.042317, 1 batch cost time 0.51
Train Epoch: 2 [86528/319902 (27%)] Loss: 0.045169, 1 batch cost time 0.51
Train Epoch: 2 [87040/319902 (27%)] Loss: 0.058154, 1 batch cost time 0.51
Train Epoch: 2 [87552/319902 (27%)] Loss: 0.048946, 1 batch cost time 0.51
Train Epoch: 2 [88064/319902 (28%)] Loss: 0.037131, 1 batch cost time 0.51
Train Epoch: 2 [88576/319902 (28%)] Loss: 0.041910, 1 batch cost time 0.51
Train Epoch: 2 [89088/319902 (28%)] Loss: 0.019094, 1 batch cost time 0.51
Train Epoch: 2 [89600/319902 (28%)] Loss: 0.042049, 1 batch cost time 0.51
Train Epoch: 2 [90112/319902 (28%)] Loss: 0.013614, 1 batch cost time 0.51
Train Epoch: 2 [90624/319902 (28%)] Loss: 0.044822, 1 batch cost time 0.51
Train Epoch: 2 [91136/319902 (28%)] Loss: 0.059860, 1 batch cost time 0.51
Train Epoch: 2 [91648/319902 (29%)] Loss: 0.061314, 1 batch cost time 0.51
Train Epoch: 2 [92160/319902 (29%)] Loss: 0.045784, 1 batch cost time 0.51
Train Epoch: 2 [92672/319902 (29%)] Loss: 0.044040, 1 batch cost time 0.51
Train Epoch: 2 [93184/319902 (29%)] Loss: 0.062270, 1 batch cost time 0.51
Train Epoch: 2 [93696/319902 (29%)] Loss: 0.035011, 1 batch cost time 0.51
Train Epoch: 2 [94208/319902 (29%)] Loss: 0.056826, 1 batch cost time 0.51
Train Epoch: 2 [94720/319902 (30%)] Loss: 0.049823, 1 batch cost time 0.51
Train Epoch: 2 [95232/319902 (30%)] Loss: 0.037087, 1 batch cost time 0.51
Train Epoch: 2 [95744/319902 (30%)] Loss: 0.064126, 1 batch cost time 0.51
Train Epoch: 2 [96256/319902 (30%)] Loss: 0.050798, 1 batch cost time 0.51
Train Epoch: 2 [96768/319902 (30%)] Loss: 0.033675, 1 batch cost time 0.51
Train Epoch: 2 [97280/319902 (30%)] Loss: 0.029335, 1 batch cost time 0.51
Train Epoch: 2 [97792/319902 (31%)] Loss: 0.031390, 1 batch cost time 0.51
Train Epoch: 2 [98304/319902 (31%)] Loss: 0.034606, 1 batch cost time 0.51
Train Epoch: 2 [98816/319902 (31%)] Loss: 0.026147, 1 batch cost time 0.51
Train Epoch: 2 [99328/319902 (31%)] Loss: 0.050230, 1 batch cost time 0.51
Train Epoch: 2 [99840/319902 (31%)] Loss: 0.057031, 1 batch cost time 0.51
Train Epoch: 2 [100352/319902 (31%)] Loss: 0.058231, 1 batch cost time 0.51
Train Epoch: 2 [100864/319902 (32%)] Loss: 0.057169, 1 batch cost time 0.51
Train Epoch: 2 [101376/319902 (32%)] Loss: 0.053822, 1 batch cost time 0.51
Train Epoch: 2 [101888/319902 (32%)] Loss: 0.037882, 1 batch cost time 0.51
Train Epoch: 2 [102400/319902 (32%)] Loss: 0.032385, 1 batch cost time 0.51
Train Epoch: 2 [102912/319902 (32%)] Loss: 0.056569, 1 batch cost time 0.51
Train Epoch: 2 [103424/319902 (32%)] Loss: 0.033848, 1 batch cost time 0.51
Train Epoch: 2 [103936/319902 (32%)] Loss: 0.042669, 1 batch cost time 0.51
Train Epoch: 2 [104448/319902 (33%)] Loss: 0.030218, 1 batch cost time 0.51
Train Epoch: 2 [104960/319902 (33%)] Loss: 0.035097, 1 batch cost time 0.51
Train Epoch: 2 [105472/319902 (33%)] Loss: 0.053547, 1 batch cost time 0.51
Train Epoch: 2 [105984/319902 (33%)] Loss: 0.022283, 1 batch cost time 0.51
Train Epoch: 2 [106496/319902 (33%)] Loss: 0.065229, 1 batch cost time 0.51
Train Epoch: 2 [107008/319902 (33%)] Loss: 0.021083, 1 batch cost time 0.51
Train Epoch: 2 [107520/319902 (34%)] Loss: 0.020415, 1 batch cost time 0.51
Train Epoch: 2 [108032/319902 (34%)] Loss: 0.036615, 1 batch cost time 0.51
Train Epoch: 2 [108544/319902 (34%)] Loss: 0.027784, 1 batch cost time 0.51
Train Epoch: 2 [109056/319902 (34%)] Loss: 0.017455, 1 batch cost time 0.51
Train Epoch: 2 [109568/319902 (34%)] Loss: 0.048030, 1 batch cost time 0.51
Train Epoch: 2 [110080/319902 (34%)] Loss: 0.021455, 1 batch cost time 0.51
Train Epoch: 2 [110592/319902 (35%)] Loss: 0.035474, 1 batch cost time 0.51
Train Epoch: 2 [111104/319902 (35%)] Loss: 0.044366, 1 batch cost time 0.51
Train Epoch: 2 [111616/319902 (35%)] Loss: 0.024308, 1 batch cost time 0.51
Train Epoch: 2 [112128/319902 (35%)] Loss: 0.042903, 1 batch cost time 0.51
Train Epoch: 2 [112640/319902 (35%)] Loss: 0.036314, 1 batch cost time 0.51
Train Epoch: 2 [113152/319902 (35%)] Loss: 0.037984, 1 batch cost time 0.51
Train Epoch: 2 [113664/319902 (36%)] Loss: 0.022545, 1 batch cost time 0.51
Train Epoch: 2 [114176/319902 (36%)] Loss: 0.016053, 1 batch cost time 0.51
Train Epoch: 2 [114688/319902 (36%)] Loss: 0.013598, 1 batch cost time 0.51
Train Epoch: 2 [115200/319902 (36%)] Loss: 0.018512, 1 batch cost time 0.51
Train Epoch: 2 [115712/319902 (36%)] Loss: 0.057055, 1 batch cost time 0.51
Train Epoch: 2 [116224/319902 (36%)] Loss: 0.031602, 1 batch cost time 0.51
Train Epoch: 2 [116736/319902 (36%)] Loss: 0.045153, 1 batch cost time 0.51
Train Epoch: 2 [117248/319902 (37%)] Loss: 0.064739, 1 batch cost time 0.51
Train Epoch: 2 [117760/319902 (37%)] Loss: 0.086265, 1 batch cost time 0.51
Train Epoch: 2 [118272/319902 (37%)] Loss: 0.048097, 1 batch cost time 0.51
Train Epoch: 2 [118784/319902 (37%)] Loss: 0.058682, 1 batch cost time 0.51
Train Epoch: 2 [119296/319902 (37%)] Loss: 0.042061, 1 batch cost time 0.51
Train Epoch: 2 [119808/319902 (37%)] Loss: 0.068620, 1 batch cost time 0.51
Train Epoch: 2 [120320/319902 (38%)] Loss: 0.039212, 1 batch cost time 0.51
Train Epoch: 2 [120832/319902 (38%)] Loss: 0.021986, 1 batch cost time 0.51
Train Epoch: 2 [121344/319902 (38%)] Loss: 0.034217, 1 batch cost time 0.51
Train Epoch: 2 [121856/319902 (38%)] Loss: 0.057182, 1 batch cost time 0.51
Train Epoch: 2 [122368/319902 (38%)] Loss: 0.024924, 1 batch cost time 0.51
Train Epoch: 2 [122880/319902 (38%)] Loss: 0.025558, 1 batch cost time 0.51
Train Epoch: 2 [123392/319902 (39%)] Loss: 0.005737, 1 batch cost time 0.51
Train Epoch: 2 [123904/319902 (39%)] Loss: 0.044021, 1 batch cost time 0.51
Train Epoch: 2 [124416/319902 (39%)] Loss: 0.026697, 1 batch cost time 0.51
Train Epoch: 2 [124928/319902 (39%)] Loss: 0.028585, 1 batch cost time 0.51
Train Epoch: 2 [125440/319902 (39%)] Loss: 0.039298, 1 batch cost time 0.51
Train Epoch: 2 [125952/319902 (39%)] Loss: 0.039330, 1 batch cost time 0.51
Train Epoch: 2 [126464/319902 (40%)] Loss: 0.034211, 1 batch cost time 0.51
Train Epoch: 2 [126976/319902 (40%)] Loss: 0.046666, 1 batch cost time 0.51
Train Epoch: 2 [127488/319902 (40%)] Loss: 0.088551, 1 batch cost time 0.51
Train Epoch: 2 [128000/319902 (40%)] Loss: 0.066720, 1 batch cost time 0.51
Train Epoch: 2 [128512/319902 (40%)] Loss: 0.012891, 1 batch cost time 0.51
Train Epoch: 2 [129024/319902 (40%)] Loss: 0.033978, 1 batch cost time 0.51
Train Epoch: 2 [129536/319902 (40%)] Loss: 0.021052, 1 batch cost time 0.51
Train Epoch: 2 [130048/319902 (41%)] Loss: 0.017908, 1 batch cost time 0.51
Train Epoch: 2 [130560/319902 (41%)] Loss: 0.023739, 1 batch cost time 0.51
Train Epoch: 2 [131072/319902 (41%)] Loss: 0.039479, 1 batch cost time 0.51
Train Epoch: 2 [131584/319902 (41%)] Loss: 0.032771, 1 batch cost time 0.51
Train Epoch: 2 [132096/319902 (41%)] Loss: 0.040884, 1 batch cost time 0.51
Train Epoch: 2 [132608/319902 (41%)] Loss: 0.047839, 1 batch cost time 0.51
Train Epoch: 2 [133120/319902 (42%)] Loss: 0.027291, 1 batch cost time 0.51
Train Epoch: 2 [133632/319902 (42%)] Loss: 0.043563, 1 batch cost time 0.51
Train Epoch: 2 [134144/319902 (42%)] Loss: 0.033802, 1 batch cost time 0.51
Train Epoch: 2 [134656/319902 (42%)] Loss: 0.028923, 1 batch cost time 0.51
Train Epoch: 2 [135168/319902 (42%)] Loss: 0.032956, 1 batch cost time 0.51
Train Epoch: 2 [135680/319902 (42%)] Loss: 0.026354, 1 batch cost time 0.51
Train Epoch: 2 [136192/319902 (43%)] Loss: 0.019116, 1 batch cost time 0.51
Train Epoch: 2 [136704/319902 (43%)] Loss: 0.028269, 1 batch cost time 0.51
Train Epoch: 2 [137216/319902 (43%)] Loss: 0.020965, 1 batch cost time 0.51
Train Epoch: 2 [137728/319902 (43%)] Loss: 0.049790, 1 batch cost time 0.51
Train Epoch: 2 [138240/319902 (43%)] Loss: 0.033092, 1 batch cost time 0.51
Train Epoch: 2 [138752/319902 (43%)] Loss: 0.076315, 1 batch cost time 0.51
Train Epoch: 2 [139264/319902 (44%)] Loss: 0.046307, 1 batch cost time 0.51
Train Epoch: 2 [139776/319902 (44%)] Loss: 0.024201, 1 batch cost time 0.51
Train Epoch: 2 [140288/319902 (44%)] Loss: 0.043481, 1 batch cost time 0.51
Train Epoch: 2 [140800/319902 (44%)] Loss: 0.047773, 1 batch cost time 0.51
Train Epoch: 2 [141312/319902 (44%)] Loss: 0.035493, 1 batch cost time 0.51
Train Epoch: 2 [141824/319902 (44%)] Loss: 0.049271, 1 batch cost time 0.51
Train Epoch: 2 [142336/319902 (44%)] Loss: 0.035612, 1 batch cost time 0.51
Train Epoch: 2 [142848/319902 (45%)] Loss: 0.061380, 1 batch cost time 0.51
Train Epoch: 2 [143360/319902 (45%)] Loss: 0.048356, 1 batch cost time 0.51
Train Epoch: 2 [143872/319902 (45%)] Loss: 0.044888, 1 batch cost time 0.51
Train Epoch: 2 [144384/319902 (45%)] Loss: 0.026964, 1 batch cost time 0.51
Train Epoch: 2 [144896/319902 (45%)] Loss: 0.028523, 1 batch cost time 0.51
Train Epoch: 2 [145408/319902 (45%)] Loss: 0.040400, 1 batch cost time 0.51
Train Epoch: 2 [145920/319902 (46%)] Loss: 0.030571, 1 batch cost time 0.51
Train Epoch: 2 [146432/319902 (46%)] Loss: 0.036082, 1 batch cost time 0.51
Train Epoch: 2 [146944/319902 (46%)] Loss: 0.036438, 1 batch cost time 0.51
Train Epoch: 2 [147456/319902 (46%)] Loss: 0.030897, 1 batch cost time 0.51
Train Epoch: 2 [147968/319902 (46%)] Loss: 0.032077, 1 batch cost time 0.51
Train Epoch: 2 [148480/319902 (46%)] Loss: 0.065592, 1 batch cost time 0.51
Train Epoch: 2 [148992/319902 (47%)] Loss: 0.033316, 1 batch cost time 0.51
Train Epoch: 2 [149504/319902 (47%)] Loss: 0.033952, 1 batch cost time 0.51
Train Epoch: 2 [150016/319902 (47%)] Loss: 0.039547, 1 batch cost time 0.51
Train Epoch: 2 [150528/319902 (47%)] Loss: 0.032356, 1 batch cost time 0.51
Train Epoch: 2 [151040/319902 (47%)] Loss: 0.032387, 1 batch cost time 0.51
Train Epoch: 2 [151552/319902 (47%)] Loss: 0.082871, 1 batch cost time 0.51
Train Epoch: 2 [152064/319902 (48%)] Loss: 0.032484, 1 batch cost time 0.51
Train Epoch: 2 [152576/319902 (48%)] Loss: 0.025679, 1 batch cost time 0.51
Train Epoch: 2 [153088/319902 (48%)] Loss: 0.037060, 1 batch cost time 0.51
Train Epoch: 2 [153600/319902 (48%)] Loss: 0.045891, 1 batch cost time 0.51
Train Epoch: 2 [154112/319902 (48%)] Loss: 0.044862, 1 batch cost time 0.51
Train Epoch: 2 [154624/319902 (48%)] Loss: 0.040658, 1 batch cost time 0.51
Train Epoch: 2 [155136/319902 (48%)] Loss: 0.041420, 1 batch cost time 0.51
Train Epoch: 2 [155648/319902 (49%)] Loss: 0.032481, 1 batch cost time 0.51
Train Epoch: 2 [156160/319902 (49%)] Loss: 0.037224, 1 batch cost time 0.51
Train Epoch: 2 [156672/319902 (49%)] Loss: 0.049310, 1 batch cost time 0.51
Train Epoch: 2 [157184/319902 (49%)] Loss: 0.045202, 1 batch cost time 0.51
Train Epoch: 2 [157696/319902 (49%)] Loss: 0.031654, 1 batch cost time 0.51
Train Epoch: 2 [158208/319902 (49%)] Loss: 0.055592, 1 batch cost time 0.51
Train Epoch: 2 [158720/319902 (50%)] Loss: 0.061226, 1 batch cost time 0.51
Train Epoch: 2 [159232/319902 (50%)] Loss: 0.066714, 1 batch cost time 0.51
Train Epoch: 2 [159744/319902 (50%)] Loss: 0.030960, 1 batch cost time 0.51
Train Epoch: 2 [160256/319902 (50%)] Loss: 0.059945, 1 batch cost time 0.51
Train Epoch: 2 [160768/319902 (50%)] Loss: 0.055509, 1 batch cost time 0.51
Train Epoch: 2 [161280/319902 (50%)] Loss: 0.027362, 1 batch cost time 0.51
Train Epoch: 2 [161792/319902 (51%)] Loss: 0.038051, 1 batch cost time 0.51
Train Epoch: 2 [162304/319902 (51%)] Loss: 0.036096, 1 batch cost time 0.51
Train Epoch: 2 [162816/319902 (51%)] Loss: 0.029775, 1 batch cost time 0.51
Train Epoch: 2 [163328/319902 (51%)] Loss: 0.036060, 1 batch cost time 0.51
Train Epoch: 2 [163840/319902 (51%)] Loss: 0.016245, 1 batch cost time 0.51
Train Epoch: 2 [164352/319902 (51%)] Loss: 0.055158, 1 batch cost time 0.51
Train Epoch: 2 [164864/319902 (52%)] Loss: 0.031608, 1 batch cost time 0.51
Train Epoch: 2 [165376/319902 (52%)] Loss: 0.033042, 1 batch cost time 0.51
Train Epoch: 2 [165888/319902 (52%)] Loss: 0.017865, 1 batch cost time 0.51
Train Epoch: 2 [166400/319902 (52%)] Loss: 0.078099, 1 batch cost time 0.51
Train Epoch: 2 [166912/319902 (52%)] Loss: 0.035371, 1 batch cost time 0.51
Train Epoch: 2 [167424/319902 (52%)] Loss: 0.060776, 1 batch cost time 0.51
Train Epoch: 2 [167936/319902 (52%)] Loss: 0.046436, 1 batch cost time 0.51
Train Epoch: 2 [168448/319902 (53%)] Loss: 0.040880, 1 batch cost time 0.51
Train Epoch: 2 [168960/319902 (53%)] Loss: 0.043062, 1 batch cost time 0.51
Train Epoch: 2 [169472/319902 (53%)] Loss: 0.016369, 1 batch cost time 0.51
Train Epoch: 2 [169984/319902 (53%)] Loss: 0.025613, 1 batch cost time 0.51
Train Epoch: 2 [170496/319902 (53%)] Loss: 0.034890, 1 batch cost time 0.51
Train Epoch: 2 [171008/319902 (53%)] Loss: 0.047998, 1 batch cost time 0.51
Train Epoch: 2 [171520/319902 (54%)] Loss: 0.049709, 1 batch cost time 0.51
Train Epoch: 2 [172032/319902 (54%)] Loss: 0.019476, 1 batch cost time 0.51
Train Epoch: 2 [172544/319902 (54%)] Loss: 0.020977, 1 batch cost time 0.51
Train Epoch: 2 [173056/319902 (54%)] Loss: 0.030776, 1 batch cost time 0.51
Train Epoch: 2 [173568/319902 (54%)] Loss: 0.023921, 1 batch cost time 0.51
Train Epoch: 2 [174080/319902 (54%)] Loss: 0.024333, 1 batch cost time 0.51
Train Epoch: 2 [174592/319902 (55%)] Loss: 0.042013, 1 batch cost time 0.51
Train Epoch: 2 [175104/319902 (55%)] Loss: 0.043574, 1 batch cost time 0.51
Train Epoch: 2 [175616/319902 (55%)] Loss: 0.044670, 1 batch cost time 0.51
Train Epoch: 2 [176128/319902 (55%)] Loss: 0.035833, 1 batch cost time 0.51
Train Epoch: 2 [176640/319902 (55%)] Loss: 0.040023, 1 batch cost time 0.51
Train Epoch: 2 [177152/319902 (55%)] Loss: 0.025624, 1 batch cost time 0.51
Train Epoch: 2 [177664/319902 (56%)] Loss: 0.051091, 1 batch cost time 0.51
Train Epoch: 2 [178176/319902 (56%)] Loss: 0.059436, 1 batch cost time 0.51
Train Epoch: 2 [178688/319902 (56%)] Loss: 0.056962, 1 batch cost time 0.51
Train Epoch: 2 [179200/319902 (56%)] Loss: 0.033144, 1 batch cost time 0.51
Train Epoch: 2 [179712/319902 (56%)] Loss: 0.018852, 1 batch cost time 0.51
Train Epoch: 2 [180224/319902 (56%)] Loss: 0.015624, 1 batch cost time 0.51
Train Epoch: 2 [180736/319902 (56%)] Loss: 0.038568, 1 batch cost time 0.51
Train Epoch: 2 [181248/319902 (57%)] Loss: 0.050942, 1 batch cost time 0.51
Train Epoch: 2 [181760/319902 (57%)] Loss: 0.035351, 1 batch cost time 0.51
Train Epoch: 2 [182272/319902 (57%)] Loss: 0.077916, 1 batch cost time 0.51
Train Epoch: 2 [182784/319902 (57%)] Loss: 0.027542, 1 batch cost time 0.51
Train Epoch: 2 [183296/319902 (57%)] Loss: 0.033829, 1 batch cost time 0.51
Train Epoch: 2 [183808/319902 (57%)] Loss: 0.040868, 1 batch cost time 0.51
Train Epoch: 2 [184320/319902 (58%)] Loss: 0.032789, 1 batch cost time 0.51
Train Epoch: 2 [184832/319902 (58%)] Loss: 0.028722, 1 batch cost time 0.51
Train Epoch: 2 [185344/319902 (58%)] Loss: 0.056981, 1 batch cost time 0.51
Train Epoch: 2 [185856/319902 (58%)] Loss: 0.053483, 1 batch cost time 0.51
Train Epoch: 2 [186368/319902 (58%)] Loss: 0.037625, 1 batch cost time 0.51
Train Epoch: 2 [186880/319902 (58%)] Loss: 0.046105, 1 batch cost time 0.51
Train Epoch: 2 [187392/319902 (59%)] Loss: 0.014478, 1 batch cost time 0.51
Train Epoch: 2 [187904/319902 (59%)] Loss: 0.027932, 1 batch cost time 0.51
Train Epoch: 2 [188416/319902 (59%)] Loss: 0.014376, 1 batch cost time 0.51
Train Epoch: 2 [188928/319902 (59%)] Loss: 0.048609, 1 batch cost time 0.51
Train Epoch: 2 [189440/319902 (59%)] Loss: 0.050914, 1 batch cost time 0.51
Train Epoch: 2 [189952/319902 (59%)] Loss: 0.018494, 1 batch cost time 0.51
Train Epoch: 2 [190464/319902 (60%)] Loss: 0.024638, 1 batch cost time 0.51
Train Epoch: 2 [190976/319902 (60%)] Loss: 0.019458, 1 batch cost time 0.51
Train Epoch: 2 [191488/319902 (60%)] Loss: 0.026719, 1 batch cost time 0.51
Train Epoch: 2 [192000/319902 (60%)] Loss: 0.059747, 1 batch cost time 0.51
Train Epoch: 2 [192512/319902 (60%)] Loss: 0.033664, 1 batch cost time 0.51
Train Epoch: 2 [193024/319902 (60%)] Loss: 0.019594, 1 batch cost time 0.51
Train Epoch: 2 [193536/319902 (60%)] Loss: 0.026253, 1 batch cost time 0.51
Train Epoch: 2 [194048/319902 (61%)] Loss: 0.021964, 1 batch cost time 0.51
Train Epoch: 2 [194560/319902 (61%)] Loss: 0.041572, 1 batch cost time 0.51
Train Epoch: 2 [195072/319902 (61%)] Loss: 0.041554, 1 batch cost time 0.51
Train Epoch: 2 [195584/319902 (61%)] Loss: 0.033366, 1 batch cost time 0.51
Train Epoch: 2 [196096/319902 (61%)] Loss: 0.035649, 1 batch cost time 0.51
Train Epoch: 2 [196608/319902 (61%)] Loss: 0.047514, 1 batch cost time 0.51
Train Epoch: 2 [197120/319902 (62%)] Loss: 0.039408, 1 batch cost time 0.51
Train Epoch: 2 [197632/319902 (62%)] Loss: 0.024834, 1 batch cost time 0.51
Train Epoch: 2 [198144/319902 (62%)] Loss: 0.018043, 1 batch cost time 0.51
Train Epoch: 2 [198656/319902 (62%)] Loss: 0.058737, 1 batch cost time 0.51
Train Epoch: 2 [199168/319902 (62%)] Loss: 0.041700, 1 batch cost time 0.51
Train Epoch: 2 [199680/319902 (62%)] Loss: 0.059297, 1 batch cost time 0.51
Train Epoch: 2 [200192/319902 (63%)] Loss: 0.060673, 1 batch cost time 0.51
Train Epoch: 2 [200704/319902 (63%)] Loss: 0.043755, 1 batch cost time 0.51
Train Epoch: 2 [201216/319902 (63%)] Loss: 0.028946, 1 batch cost time 0.51
Train Epoch: 2 [201728/319902 (63%)] Loss: 0.040566, 1 batch cost time 0.51
Train Epoch: 2 [202240/319902 (63%)] Loss: 0.031913, 1 batch cost time 0.51
Train Epoch: 2 [202752/319902 (63%)] Loss: 0.042104, 1 batch cost time 0.51
Train Epoch: 2 [203264/319902 (64%)] Loss: 0.028668, 1 batch cost time 0.51
Train Epoch: 2 [203776/319902 (64%)] Loss: 0.024067, 1 batch cost time 0.51
Train Epoch: 2 [204288/319902 (64%)] Loss: 0.075886, 1 batch cost time 0.51
Train Epoch: 2 [204800/319902 (64%)] Loss: 0.047028, 1 batch cost time 0.51
Train Epoch: 2 [205312/319902 (64%)] Loss: 0.054645, 1 batch cost time 0.51
Train Epoch: 2 [205824/319902 (64%)] Loss: 0.056231, 1 batch cost time 0.51
Train Epoch: 2 [206336/319902 (64%)] Loss: 0.042407, 1 batch cost time 0.51
Train Epoch: 2 [206848/319902 (65%)] Loss: 0.010128, 1 batch cost time 0.51
Train Epoch: 2 [207360/319902 (65%)] Loss: 0.020486, 1 batch cost time 0.51
Train Epoch: 2 [207872/319902 (65%)] Loss: 0.016909, 1 batch cost time 0.51
Train Epoch: 2 [208384/319902 (65%)] Loss: 0.048254, 1 batch cost time 0.51
Train Epoch: 2 [208896/319902 (65%)] Loss: 0.030801, 1 batch cost time 0.51
Train Epoch: 2 [209408/319902 (65%)] Loss: 0.030296, 1 batch cost time 0.51
Train Epoch: 2 [209920/319902 (66%)] Loss: 0.049879, 1 batch cost time 0.51
Train Epoch: 2 [210432/319902 (66%)] Loss: 0.026100, 1 batch cost time 0.51
Train Epoch: 2 [210944/319902 (66%)] Loss: 0.061810, 1 batch cost time 0.51
Train Epoch: 2 [211456/319902 (66%)] Loss: 0.031544, 1 batch cost time 0.51
Train Epoch: 2 [211968/319902 (66%)] Loss: 0.027788, 1 batch cost time 0.51
Train Epoch: 2 [212480/319902 (66%)] Loss: 0.049224, 1 batch cost time 0.51
Train Epoch: 2 [212992/319902 (67%)] Loss: 0.041660, 1 batch cost time 0.51
Train Epoch: 2 [213504/319902 (67%)] Loss: 0.035959, 1 batch cost time 0.51
Train Epoch: 2 [214016/319902 (67%)] Loss: 0.035332, 1 batch cost time 0.51
Train Epoch: 2 [214528/319902 (67%)] Loss: 0.050457, 1 batch cost time 0.51
Train Epoch: 2 [215040/319902 (67%)] Loss: 0.039773, 1 batch cost time 0.51
Train Epoch: 2 [215552/319902 (67%)] Loss: 0.043708, 1 batch cost time 0.51
Train Epoch: 2 [216064/319902 (68%)] Loss: 0.031072, 1 batch cost time 0.51
Train Epoch: 2 [216576/319902 (68%)] Loss: 0.026505, 1 batch cost time 0.51
Train Epoch: 2 [217088/319902 (68%)] Loss: 0.029303, 1 batch cost time 0.51
Train Epoch: 2 [217600/319902 (68%)] Loss: 0.060071, 1 batch cost time 0.51
Train Epoch: 2 [218112/319902 (68%)] Loss: 0.029740, 1 batch cost time 0.51
Train Epoch: 2 [218624/319902 (68%)] Loss: 0.075618, 1 batch cost time 0.51
Train Epoch: 2 [219136/319902 (69%)] Loss: 0.050478, 1 batch cost time 0.51
Train Epoch: 2 [219648/319902 (69%)] Loss: 0.038252, 1 batch cost time 0.51
Train Epoch: 2 [220160/319902 (69%)] Loss: 0.049351, 1 batch cost time 0.51
Train Epoch: 2 [220672/319902 (69%)] Loss: 0.027932, 1 batch cost time 0.51
Train Epoch: 2 [221184/319902 (69%)] Loss: 0.031541, 1 batch cost time 0.51
Train Epoch: 2 [221696/319902 (69%)] Loss: 0.035865, 1 batch cost time 0.51
Train Epoch: 2 [222208/319902 (69%)] Loss: 0.035939, 1 batch cost time 0.51
Train Epoch: 2 [222720/319902 (70%)] Loss: 0.037746, 1 batch cost time 0.51
Train Epoch: 2 [223232/319902 (70%)] Loss: 0.023675, 1 batch cost time 0.51
Train Epoch: 2 [223744/319902 (70%)] Loss: 0.082369, 1 batch cost time 0.51
Train Epoch: 2 [224256/319902 (70%)] Loss: 0.033371, 1 batch cost time 0.51
Train Epoch: 2 [224768/319902 (70%)] Loss: 0.033657, 1 batch cost time 0.51
Train Epoch: 2 [225280/319902 (70%)] Loss: 0.033380, 1 batch cost time 0.51
Train Epoch: 2 [225792/319902 (71%)] Loss: 0.049608, 1 batch cost time 0.51
Train Epoch: 2 [226304/319902 (71%)] Loss: 0.038293, 1 batch cost time 0.51
Train Epoch: 2 [226816/319902 (71%)] Loss: 0.015741, 1 batch cost time 0.51
Train Epoch: 2 [227328/319902 (71%)] Loss: 0.105010, 1 batch cost time 0.51
Train Epoch: 2 [227840/319902 (71%)] Loss: 0.031579, 1 batch cost time 0.51
Train Epoch: 2 [228352/319902 (71%)] Loss: 0.022735, 1 batch cost time 0.51
Train Epoch: 2 [228864/319902 (72%)] Loss: 0.015472, 1 batch cost time 0.51
Train Epoch: 2 [229376/319902 (72%)] Loss: 0.031579, 1 batch cost time 0.51
Train Epoch: 2 [229888/319902 (72%)] Loss: 0.032993, 1 batch cost time 0.51
Train Epoch: 2 [230400/319902 (72%)] Loss: 0.048333, 1 batch cost time 0.51
Train Epoch: 2 [230912/319902 (72%)] Loss: 0.035004, 1 batch cost time 0.51
Train Epoch: 2 [231424/319902 (72%)] Loss: 0.066022, 1 batch cost time 0.51
Train Epoch: 2 [231936/319902 (73%)] Loss: 0.055285, 1 batch cost time 0.51
Train Epoch: 2 [232448/319902 (73%)] Loss: 0.036351, 1 batch cost time 0.51
Train Epoch: 2 [232960/319902 (73%)] Loss: 0.025391, 1 batch cost time 0.51
Train Epoch: 2 [233472/319902 (73%)] Loss: 0.039563, 1 batch cost time 0.51
Train Epoch: 2 [233984/319902 (73%)] Loss: 0.047702, 1 batch cost time 0.51
Train Epoch: 2 [234496/319902 (73%)] Loss: 0.059006, 1 batch cost time 0.51
Train Epoch: 2 [235008/319902 (73%)] Loss: 0.050814, 1 batch cost time 0.51
Train Epoch: 2 [235520/319902 (74%)] Loss: 0.054885, 1 batch cost time 0.51
Train Epoch: 2 [236032/319902 (74%)] Loss: 0.085191, 1 batch cost time 0.51
Train Epoch: 2 [236544/319902 (74%)] Loss: 0.072367, 1 batch cost time 0.51
Train Epoch: 2 [237056/319902 (74%)] Loss: 0.018422, 1 batch cost time 0.51
Train Epoch: 2 [237568/319902 (74%)] Loss: 0.040925, 1 batch cost time 0.51
Train Epoch: 2 [238080/319902 (74%)] Loss: 0.038020, 1 batch cost time 0.51
Train Epoch: 2 [238592/319902 (75%)] Loss: 0.032964, 1 batch cost time 0.51
Train Epoch: 2 [239104/319902 (75%)] Loss: 0.023273, 1 batch cost time 0.51
Train Epoch: 2 [239616/319902 (75%)] Loss: 0.019410, 1 batch cost time 0.51
Train Epoch: 2 [240128/319902 (75%)] Loss: 0.014355, 1 batch cost time 0.51
Train Epoch: 2 [240640/319902 (75%)] Loss: 0.050151, 1 batch cost time 0.51
Train Epoch: 2 [241152/319902 (75%)] Loss: 0.017713, 1 batch cost time 0.51
Train Epoch: 2 [241664/319902 (76%)] Loss: 0.039479, 1 batch cost time 0.51
Train Epoch: 2 [242176/319902 (76%)] Loss: 0.057234, 1 batch cost time 0.51
Train Epoch: 2 [242688/319902 (76%)] Loss: 0.048752, 1 batch cost time 0.51
Train Epoch: 2 [243200/319902 (76%)] Loss: 0.050584, 1 batch cost time 0.51
Train Epoch: 2 [243712/319902 (76%)] Loss: 0.025864, 1 batch cost time 0.51
Train Epoch: 2 [244224/319902 (76%)] Loss: 0.040520, 1 batch cost time 0.51
Train Epoch: 2 [244736/319902 (77%)] Loss: 0.018295, 1 batch cost time 0.51
Train Epoch: 2 [245248/319902 (77%)] Loss: 0.052955, 1 batch cost time 0.51
Train Epoch: 2 [245760/319902 (77%)] Loss: 0.025900, 1 batch cost time 0.51
Train Epoch: 2 [246272/319902 (77%)] Loss: 0.056782, 1 batch cost time 0.51
Train Epoch: 2 [246784/319902 (77%)] Loss: 0.022205, 1 batch cost time 0.51
Train Epoch: 2 [247296/319902 (77%)] Loss: 0.023932, 1 batch cost time 0.51
Train Epoch: 2 [247808/319902 (77%)] Loss: 0.077698, 1 batch cost time 0.51
Train Epoch: 2 [248320/319902 (78%)] Loss: 0.043210, 1 batch cost time 0.51
Train Epoch: 2 [248832/319902 (78%)] Loss: 0.019831, 1 batch cost time 0.51
Train Epoch: 2 [249344/319902 (78%)] Loss: 0.036657, 1 batch cost time 0.51
Train Epoch: 2 [249856/319902 (78%)] Loss: 0.020238, 1 batch cost time 0.51
Train Epoch: 2 [250368/319902 (78%)] Loss: 0.050774, 1 batch cost time 0.51
Train Epoch: 2 [250880/319902 (78%)] Loss: 0.053662, 1 batch cost time 0.51
Train Epoch: 2 [251392/319902 (79%)] Loss: 0.038820, 1 batch cost time 0.51
Train Epoch: 2 [251904/319902 (79%)] Loss: 0.056120, 1 batch cost time 0.51
Train Epoch: 2 [252416/319902 (79%)] Loss: 0.039402, 1 batch cost time 0.51
Train Epoch: 2 [252928/319902 (79%)] Loss: 0.037903, 1 batch cost time 0.51
Train Epoch: 2 [253440/319902 (79%)] Loss: 0.027784, 1 batch cost time 0.51
Train Epoch: 2 [253952/319902 (79%)] Loss: 0.019742, 1 batch cost time 0.51
Train Epoch: 2 [254464/319902 (80%)] Loss: 0.043566, 1 batch cost time 0.51
Train Epoch: 2 [254976/319902 (80%)] Loss: 0.081510, 1 batch cost time 0.51
Train Epoch: 2 [255488/319902 (80%)] Loss: 0.042720, 1 batch cost time 0.51
Train Epoch: 2 [256000/319902 (80%)] Loss: 0.037082, 1 batch cost time 0.51
Train Epoch: 2 [256512/319902 (80%)] Loss: 0.047581, 1 batch cost time 0.51
Train Epoch: 2 [257024/319902 (80%)] Loss: 0.045040, 1 batch cost time 0.51
Train Epoch: 2 [257536/319902 (81%)] Loss: 0.028563, 1 batch cost time 0.51
Train Epoch: 2 [258048/319902 (81%)] Loss: 0.045147, 1 batch cost time 0.51
Train Epoch: 2 [258560/319902 (81%)] Loss: 0.028136, 1 batch cost time 0.51
Train Epoch: 2 [259072/319902 (81%)] Loss: 0.043861, 1 batch cost time 0.51
Train Epoch: 2 [259584/319902 (81%)] Loss: 0.079180, 1 batch cost time 0.51
Train Epoch: 2 [260096/319902 (81%)] Loss: 0.046581, 1 batch cost time 0.51
Train Epoch: 2 [260608/319902 (81%)] Loss: 0.014077, 1 batch cost time 0.51
Train Epoch: 2 [261120/319902 (82%)] Loss: 0.029922, 1 batch cost time 0.51
Train Epoch: 2 [261632/319902 (82%)] Loss: 0.032928, 1 batch cost time 0.51
Train Epoch: 2 [262144/319902 (82%)] Loss: 0.025170, 1 batch cost time 0.51
Train Epoch: 2 [262656/319902 (82%)] Loss: 0.067059, 1 batch cost time 0.51
Train Epoch: 2 [263168/319902 (82%)] Loss: 0.024913, 1 batch cost time 0.51
Train Epoch: 2 [263680/319902 (82%)] Loss: 0.037846, 1 batch cost time 0.51
Train Epoch: 2 [264192/319902 (83%)] Loss: 0.047953, 1 batch cost time 0.51
Train Epoch: 2 [264704/319902 (83%)] Loss: 0.031361, 1 batch cost time 0.51
Train Epoch: 2 [265216/319902 (83%)] Loss: 0.051353, 1 batch cost time 0.51
Train Epoch: 2 [265728/319902 (83%)] Loss: 0.041001, 1 batch cost time 0.51
Train Epoch: 2 [266240/319902 (83%)] Loss: 0.039530, 1 batch cost time 0.51
Train Epoch: 2 [266752/319902 (83%)] Loss: 0.034635, 1 batch cost time 0.51
Train Epoch: 2 [267264/319902 (84%)] Loss: 0.042222, 1 batch cost time 0.51
Train Epoch: 2 [267776/319902 (84%)] Loss: 0.049430, 1 batch cost time 0.51
Train Epoch: 2 [268288/319902 (84%)] Loss: 0.038084, 1 batch cost time 0.51
Train Epoch: 2 [268800/319902 (84%)] Loss: 0.042651, 1 batch cost time 0.51
Train Epoch: 2 [269312/319902 (84%)] Loss: 0.036034, 1 batch cost time 0.51
Train Epoch: 2 [269824/319902 (84%)] Loss: 0.056161, 1 batch cost time 0.51
Train Epoch: 2 [270336/319902 (85%)] Loss: 0.039389, 1 batch cost time 0.51
Train Epoch: 2 [270848/319902 (85%)] Loss: 0.027573, 1 batch cost time 0.51
Train Epoch: 2 [271360/319902 (85%)] Loss: 0.040772, 1 batch cost time 0.51
Train Epoch: 2 [271872/319902 (85%)] Loss: 0.058184, 1 batch cost time 0.51
Train Epoch: 2 [272384/319902 (85%)] Loss: 0.035425, 1 batch cost time 0.51
Train Epoch: 2 [272896/319902 (85%)] Loss: 0.033737, 1 batch cost time 0.51
Train Epoch: 2 [273408/319902 (85%)] Loss: 0.017415, 1 batch cost time 0.51
Train Epoch: 2 [273920/319902 (86%)] Loss: 0.026990, 1 batch cost time 0.51
Train Epoch: 2 [274432/319902 (86%)] Loss: 0.076502, 1 batch cost time 0.51
Train Epoch: 2 [274944/319902 (86%)] Loss: 0.038590, 1 batch cost time 0.51
Train Epoch: 2 [275456/319902 (86%)] Loss: 0.030370, 1 batch cost time 0.51
Train Epoch: 2 [275968/319902 (86%)] Loss: 0.022675, 1 batch cost time 0.51
Train Epoch: 2 [276480/319902 (86%)] Loss: 0.053599, 1 batch cost time 0.51
Train Epoch: 2 [276992/319902 (87%)] Loss: 0.043773, 1 batch cost time 0.51
Train Epoch: 2 [277504/319902 (87%)] Loss: 0.049508, 1 batch cost time 0.51
Train Epoch: 2 [278016/319902 (87%)] Loss: 0.032661, 1 batch cost time 0.51
Train Epoch: 2 [278528/319902 (87%)] Loss: 0.032022, 1 batch cost time 0.51
Train Epoch: 2 [279040/319902 (87%)] Loss: 0.031633, 1 batch cost time 0.51
Train Epoch: 2 [279552/319902 (87%)] Loss: 0.025138, 1 batch cost time 0.51
Train Epoch: 2 [280064/319902 (88%)] Loss: 0.009931, 1 batch cost time 0.51
Train Epoch: 2 [280576/319902 (88%)] Loss: 0.082919, 1 batch cost time 0.51
Train Epoch: 2 [281088/319902 (88%)] Loss: 0.030399, 1 batch cost time 0.51
Train Epoch: 2 [281600/319902 (88%)] Loss: 0.075018, 1 batch cost time 0.51
Train Epoch: 2 [282112/319902 (88%)] Loss: 0.026282, 1 batch cost time 0.51
Train Epoch: 2 [282624/319902 (88%)] Loss: 0.023797, 1 batch cost time 0.51
Train Epoch: 2 [283136/319902 (89%)] Loss: 0.045894, 1 batch cost time 0.51
Train Epoch: 2 [283648/319902 (89%)] Loss: 0.024056, 1 batch cost time 0.51
Train Epoch: 2 [284160/319902 (89%)] Loss: 0.037372, 1 batch cost time 0.51
Train Epoch: 2 [284672/319902 (89%)] Loss: 0.030900, 1 batch cost time 0.51
Train Epoch: 2 [285184/319902 (89%)] Loss: 0.032959, 1 batch cost time 0.51
Train Epoch: 2 [285696/319902 (89%)] Loss: 0.012127, 1 batch cost time 0.51
Train Epoch: 2 [286208/319902 (89%)] Loss: 0.022891, 1 batch cost time 0.51
Train Epoch: 2 [286720/319902 (90%)] Loss: 0.032185, 1 batch cost time 0.51
Train Epoch: 2 [287232/319902 (90%)] Loss: 0.050333, 1 batch cost time 0.51
Train Epoch: 2 [287744/319902 (90%)] Loss: 0.049404, 1 batch cost time 0.51
Train Epoch: 2 [288256/319902 (90%)] Loss: 0.050689, 1 batch cost time 0.51
Train Epoch: 2 [288768/319902 (90%)] Loss: 0.031176, 1 batch cost time 0.51
Train Epoch: 2 [289280/319902 (90%)] Loss: 0.023735, 1 batch cost time 0.51
Train Epoch: 2 [289792/319902 (91%)] Loss: 0.027423, 1 batch cost time 0.51
Train Epoch: 2 [290304/319902 (91%)] Loss: 0.014913, 1 batch cost time 0.51
Train Epoch: 2 [290816/319902 (91%)] Loss: 0.052176, 1 batch cost time 0.51
Train Epoch: 2 [291328/319902 (91%)] Loss: 0.049997, 1 batch cost time 0.51
Train Epoch: 2 [291840/319902 (91%)] Loss: 0.070394, 1 batch cost time 0.51
Train Epoch: 2 [292352/319902 (91%)] Loss: 0.046236, 1 batch cost time 0.51
Train Epoch: 2 [292864/319902 (92%)] Loss: 0.050788, 1 batch cost time 0.51
Train Epoch: 2 [293376/319902 (92%)] Loss: 0.051818, 1 batch cost time 0.51
Train Epoch: 2 [293888/319902 (92%)] Loss: 0.038601, 1 batch cost time 0.51
Train Epoch: 2 [294400/319902 (92%)] Loss: 0.024949, 1 batch cost time 0.51
Train Epoch: 2 [294912/319902 (92%)] Loss: 0.021741, 1 batch cost time 0.51
Train Epoch: 2 [295424/319902 (92%)] Loss: 0.034247, 1 batch cost time 0.51
Train Epoch: 2 [295936/319902 (93%)] Loss: 0.052237, 1 batch cost time 0.51
Train Epoch: 2 [296448/319902 (93%)] Loss: 0.047359, 1 batch cost time 0.51
Train Epoch: 2 [296960/319902 (93%)] Loss: 0.040146, 1 batch cost time 0.51
Train Epoch: 2 [297472/319902 (93%)] Loss: 0.059488, 1 batch cost time 0.51
Train Epoch: 2 [297984/319902 (93%)] Loss: 0.043615, 1 batch cost time 0.51
Train Epoch: 2 [298496/319902 (93%)] Loss: 0.008558, 1 batch cost time 0.51
Train Epoch: 2 [299008/319902 (93%)] Loss: 0.021585, 1 batch cost time 0.51
Train Epoch: 2 [299520/319902 (94%)] Loss: 0.031081, 1 batch cost time 0.51
Train Epoch: 2 [300032/319902 (94%)] Loss: 0.048121, 1 batch cost time 0.51
Train Epoch: 2 [300544/319902 (94%)] Loss: 0.042131, 1 batch cost time 0.51
Train Epoch: 2 [301056/319902 (94%)] Loss: 0.030511, 1 batch cost time 0.51
Train Epoch: 2 [301568/319902 (94%)] Loss: 0.031848, 1 batch cost time 0.51
Train Epoch: 2 [302080/319902 (94%)] Loss: 0.049147, 1 batch cost time 0.51
Train Epoch: 2 [302592/319902 (95%)] Loss: 0.015519, 1 batch cost time 0.51
Train Epoch: 2 [303104/319902 (95%)] Loss: 0.025997, 1 batch cost time 0.51
Train Epoch: 2 [303616/319902 (95%)] Loss: 0.037135, 1 batch cost time 0.51
Train Epoch: 2 [304128/319902 (95%)] Loss: 0.043378, 1 batch cost time 0.51
Train Epoch: 2 [304640/319902 (95%)] Loss: 0.024819, 1 batch cost time 0.51
Train Epoch: 2 [305152/319902 (95%)] Loss: 0.027031, 1 batch cost time 0.51
Train Epoch: 2 [305664/319902 (96%)] Loss: 0.029114, 1 batch cost time 0.51
Train Epoch: 2 [306176/319902 (96%)] Loss: 0.047563, 1 batch cost time 0.51
Train Epoch: 2 [306688/319902 (96%)] Loss: 0.029680, 1 batch cost time 0.51
Train Epoch: 2 [307200/319902 (96%)] Loss: 0.039616, 1 batch cost time 0.51
Train Epoch: 2 [307712/319902 (96%)] Loss: 0.041996, 1 batch cost time 0.51
Train Epoch: 2 [308224/319902 (96%)] Loss: 0.061858, 1 batch cost time 0.51
Train Epoch: 2 [308736/319902 (97%)] Loss: 0.045373, 1 batch cost time 0.51
Train Epoch: 2 [309248/319902 (97%)] Loss: 0.046792, 1 batch cost time 0.51
Train Epoch: 2 [309760/319902 (97%)] Loss: 0.055824, 1 batch cost time 0.51
Train Epoch: 2 [310272/319902 (97%)] Loss: 0.034346, 1 batch cost time 0.51
Train Epoch: 2 [310784/319902 (97%)] Loss: 0.051458, 1 batch cost time 0.51
Train Epoch: 2 [311296/319902 (97%)] Loss: 0.073007, 1 batch cost time 0.51
Train Epoch: 2 [311808/319902 (97%)] Loss: 0.039169, 1 batch cost time 0.51
Train Epoch: 2 [312320/319902 (98%)] Loss: 0.027521, 1 batch cost time 0.51
Train Epoch: 2 [312832/319902 (98%)] Loss: 0.023299, 1 batch cost time 0.51
Train Epoch: 2 [313344/319902 (98%)] Loss: 0.037011, 1 batch cost time 0.51
Train Epoch: 2 [313856/319902 (98%)] Loss: 0.037328, 1 batch cost time 0.51
Train Epoch: 2 [314368/319902 (98%)] Loss: 0.064726, 1 batch cost time 0.51
Train Epoch: 2 [314880/319902 (98%)] Loss: 0.022195, 1 batch cost time 0.51
Train Epoch: 2 [315392/319902 (99%)] Loss: 0.016105, 1 batch cost time 0.51
Train Epoch: 2 [315904/319902 (99%)] Loss: 0.016384, 1 batch cost time 0.51
Train Epoch: 2 [316416/319902 (99%)] Loss: 0.046251, 1 batch cost time 0.51
Train Epoch: 2 [316928/319902 (99%)] Loss: 0.043070, 1 batch cost time 0.51
Train Epoch: 2 [317440/319902 (99%)] Loss: 0.031198, 1 batch cost time 0.51
Train Epoch: 2 [317952/319902 (99%)] Loss: 0.061049, 1 batch cost time 0.51
Train Epoch: 2 [318464/319902 (100%)] Loss: 0.029088, 1 batch cost time 0.51
Train Epoch: 2 [318976/319902 (100%)] Loss: 0.040617, 1 batch cost time 0.51
Train Epoch: 2 [319488/319902 (100%)] Loss: 0.042261, 1 batch cost time 0.51
training epoch cost 7968.2008402347565 seconds
    epoch          : 2
    lr             : 0.0001
    loss           : 0.03933774510852429
    accuracy       : 0.9199398509403761
    f_measure      : 0.44029335835233213
    val_loss       : 0.030052625668758992
    val_accuracy   : 0.9358723958333334
    val_f_measure  : 0.5181078455687832
Saving current best: model_best.pth ...
Train Epoch: 3 [0/319902 (0%)] Loss: 0.067202, 1 batch cost time 0.52
Train Epoch: 3 [512/319902 (0%)] Loss: 0.028399, 1 batch cost time 0.51
Train Epoch: 3 [1024/319902 (0%)] Loss: 0.047585, 1 batch cost time 0.51
Train Epoch: 3 [1536/319902 (0%)] Loss: 0.054438, 1 batch cost time 0.51
Train Epoch: 3 [2048/319902 (1%)] Loss: 0.048842, 1 batch cost time 0.51
Train Epoch: 3 [2560/319902 (1%)] Loss: 0.013711, 1 batch cost time 0.51
Train Epoch: 3 [3072/319902 (1%)] Loss: 0.039605, 1 batch cost time 0.51
Train Epoch: 3 [3584/319902 (1%)] Loss: 0.027716, 1 batch cost time 0.51
Train Epoch: 3 [4096/319902 (1%)] Loss: 0.046168, 1 batch cost time 0.51
Train Epoch: 3 [4608/319902 (1%)] Loss: 0.051400, 1 batch cost time 0.51
Train Epoch: 3 [5120/319902 (2%)] Loss: 0.030520, 1 batch cost time 0.51
Train Epoch: 3 [5632/319902 (2%)] Loss: 0.030752, 1 batch cost time 0.51
Train Epoch: 3 [6144/319902 (2%)] Loss: 0.038610, 1 batch cost time 0.51
Train Epoch: 3 [6656/319902 (2%)] Loss: 0.017336, 1 batch cost time 0.51
Train Epoch: 3 [7168/319902 (2%)] Loss: 0.036041, 1 batch cost time 0.51
Train Epoch: 3 [7680/319902 (2%)] Loss: 0.033550, 1 batch cost time 0.51
Train Epoch: 3 [8192/319902 (3%)] Loss: 0.030099, 1 batch cost time 0.51
Train Epoch: 3 [8704/319902 (3%)] Loss: 0.015792, 1 batch cost time 0.51
Train Epoch: 3 [9216/319902 (3%)] Loss: 0.031419, 1 batch cost time 0.51
Train Epoch: 3 [9728/319902 (3%)] Loss: 0.060086, 1 batch cost time 0.51
Train Epoch: 3 [10240/319902 (3%)] Loss: 0.016581, 1 batch cost time 0.51
Train Epoch: 3 [10752/319902 (3%)] Loss: 0.028013, 1 batch cost time 0.51
Train Epoch: 3 [11264/319902 (4%)] Loss: 0.032752, 1 batch cost time 0.51
Train Epoch: 3 [11776/319902 (4%)] Loss: 0.028804, 1 batch cost time 0.51
Train Epoch: 3 [12288/319902 (4%)] Loss: 0.034437, 1 batch cost time 0.51
Train Epoch: 3 [12800/319902 (4%)] Loss: 0.043988, 1 batch cost time 0.51
Train Epoch: 3 [13312/319902 (4%)] Loss: 0.032711, 1 batch cost time 0.51
Train Epoch: 3 [13824/319902 (4%)] Loss: 0.016481, 1 batch cost time 0.51
Train Epoch: 3 [14336/319902 (4%)] Loss: 0.014483, 1 batch cost time 0.51
Train Epoch: 3 [14848/319902 (5%)] Loss: 0.045679, 1 batch cost time 0.51
Train Epoch: 3 [15360/319902 (5%)] Loss: 0.047460, 1 batch cost time 0.51
Train Epoch: 3 [15872/319902 (5%)] Loss: 0.027923, 1 batch cost time 0.51
Train Epoch: 3 [16384/319902 (5%)] Loss: 0.039190, 1 batch cost time 0.51
Train Epoch: 3 [16896/319902 (5%)] Loss: 0.043636, 1 batch cost time 0.51
Train Epoch: 3 [17408/319902 (5%)] Loss: 0.057193, 1 batch cost time 0.51
Train Epoch: 3 [17920/319902 (6%)] Loss: 0.037077, 1 batch cost time 0.51
Train Epoch: 3 [18432/319902 (6%)] Loss: 0.033761, 1 batch cost time 0.51
Train Epoch: 3 [18944/319902 (6%)] Loss: 0.039598, 1 batch cost time 0.51
Train Epoch: 3 [19456/319902 (6%)] Loss: 0.061306, 1 batch cost time 0.51
Train Epoch: 3 [19968/319902 (6%)] Loss: 0.016148, 1 batch cost time 0.51
Train Epoch: 3 [20480/319902 (6%)] Loss: 0.031538, 1 batch cost time 0.51
Train Epoch: 3 [20992/319902 (7%)] Loss: 0.020172, 1 batch cost time 0.51
Train Epoch: 3 [21504/319902 (7%)] Loss: 0.016571, 1 batch cost time 0.51
Train Epoch: 3 [22016/319902 (7%)] Loss: 0.056177, 1 batch cost time 0.51
Train Epoch: 3 [22528/319902 (7%)] Loss: 0.026036, 1 batch cost time 0.51
Train Epoch: 3 [23040/319902 (7%)] Loss: 0.058256, 1 batch cost time 0.51
Train Epoch: 3 [23552/319902 (7%)] Loss: 0.034482, 1 batch cost time 0.51
Train Epoch: 3 [24064/319902 (8%)] Loss: 0.014539, 1 batch cost time 0.51
Train Epoch: 3 [24576/319902 (8%)] Loss: 0.025295, 1 batch cost time 0.51
Train Epoch: 3 [25088/319902 (8%)] Loss: 0.022138, 1 batch cost time 0.51
Train Epoch: 3 [25600/319902 (8%)] Loss: 0.038192, 1 batch cost time 0.51
Train Epoch: 3 [26112/319902 (8%)] Loss: 0.048516, 1 batch cost time 0.51
Train Epoch: 3 [26624/319902 (8%)] Loss: 0.091946, 1 batch cost time 0.51
Train Epoch: 3 [27136/319902 (8%)] Loss: 0.034013, 1 batch cost time 0.51
Train Epoch: 3 [27648/319902 (9%)] Loss: 0.024567, 1 batch cost time 0.51
Train Epoch: 3 [28160/319902 (9%)] Loss: 0.040132, 1 batch cost time 0.51
Train Epoch: 3 [28672/319902 (9%)] Loss: 0.011897, 1 batch cost time 0.51
Train Epoch: 3 [29184/319902 (9%)] Loss: 0.027619, 1 batch cost time 0.51
Train Epoch: 3 [29696/319902 (9%)] Loss: 0.040805, 1 batch cost time 0.51
Train Epoch: 3 [30208/319902 (9%)] Loss: 0.034116, 1 batch cost time 0.51
Train Epoch: 3 [30720/319902 (10%)] Loss: 0.049283, 1 batch cost time 0.51
Train Epoch: 3 [31232/319902 (10%)] Loss: 0.037037, 1 batch cost time 0.51
Train Epoch: 3 [31744/319902 (10%)] Loss: 0.044345, 1 batch cost time 0.51
Train Epoch: 3 [32256/319902 (10%)] Loss: 0.022141, 1 batch cost time 0.51
Train Epoch: 3 [32768/319902 (10%)] Loss: 0.051987, 1 batch cost time 0.51
Train Epoch: 3 [33280/319902 (10%)] Loss: 0.047651, 1 batch cost time 0.51
Train Epoch: 3 [33792/319902 (11%)] Loss: 0.031635, 1 batch cost time 0.51
Train Epoch: 3 [34304/319902 (11%)] Loss: 0.047901, 1 batch cost time 0.51
Train Epoch: 3 [34816/319902 (11%)] Loss: 0.038077, 1 batch cost time 0.51
Train Epoch: 3 [35328/319902 (11%)] Loss: 0.016746, 1 batch cost time 0.51
Train Epoch: 3 [35840/319902 (11%)] Loss: 0.053018, 1 batch cost time 0.51
Train Epoch: 3 [36352/319902 (11%)] Loss: 0.042613, 1 batch cost time 0.51
Train Epoch: 3 [36864/319902 (12%)] Loss: 0.031928, 1 batch cost time 0.51
Train Epoch: 3 [37376/319902 (12%)] Loss: 0.046076, 1 batch cost time 0.51
Train Epoch: 3 [37888/319902 (12%)] Loss: 0.015422, 1 batch cost time 0.51
Train Epoch: 3 [38400/319902 (12%)] Loss: 0.052166, 1 batch cost time 0.51
Train Epoch: 3 [38912/319902 (12%)] Loss: 0.028209, 1 batch cost time 0.51
Train Epoch: 3 [39424/319902 (12%)] Loss: 0.032744, 1 batch cost time 0.51
Train Epoch: 3 [39936/319902 (12%)] Loss: 0.039328, 1 batch cost time 0.51
Train Epoch: 3 [40448/319902 (13%)] Loss: 0.027637, 1 batch cost time 0.51
Train Epoch: 3 [40960/319902 (13%)] Loss: 0.038664, 1 batch cost time 0.51
Train Epoch: 3 [41472/319902 (13%)] Loss: 0.039937, 1 batch cost time 0.51
Train Epoch: 3 [41984/319902 (13%)] Loss: 0.031827, 1 batch cost time 0.51
Train Epoch: 3 [42496/319902 (13%)] Loss: 0.042304, 1 batch cost time 0.51
Train Epoch: 3 [43008/319902 (13%)] Loss: 0.058045, 1 batch cost time 0.51
Train Epoch: 3 [43520/319902 (14%)] Loss: 0.051958, 1 batch cost time 0.51
Train Epoch: 3 [44032/319902 (14%)] Loss: 0.097316, 1 batch cost time 0.51
Train Epoch: 3 [44544/319902 (14%)] Loss: 0.030765, 1 batch cost time 0.51
Train Epoch: 3 [45056/319902 (14%)] Loss: 0.038721, 1 batch cost time 0.51
Train Epoch: 3 [45568/319902 (14%)] Loss: 0.041151, 1 batch cost time 0.51
Train Epoch: 3 [46080/319902 (14%)] Loss: 0.023637, 1 batch cost time 0.51
Train Epoch: 3 [46592/319902 (15%)] Loss: 0.035470, 1 batch cost time 0.51
Train Epoch: 3 [47104/319902 (15%)] Loss: 0.053066, 1 batch cost time 0.51
Train Epoch: 3 [47616/319902 (15%)] Loss: 0.036750, 1 batch cost time 0.51
Train Epoch: 3 [48128/319902 (15%)] Loss: 0.062549, 1 batch cost time 0.51
Train Epoch: 3 [48640/319902 (15%)] Loss: 0.026058, 1 batch cost time 0.51
Train Epoch: 3 [49152/319902 (15%)] Loss: 0.026885, 1 batch cost time 0.51
Train Epoch: 3 [49664/319902 (16%)] Loss: 0.032532, 1 batch cost time 0.51
Train Epoch: 3 [50176/319902 (16%)] Loss: 0.050629, 1 batch cost time 0.51
Train Epoch: 3 [50688/319902 (16%)] Loss: 0.044858, 1 batch cost time 0.51
Train Epoch: 3 [51200/319902 (16%)] Loss: 0.070079, 1 batch cost time 0.51
Train Epoch: 3 [51712/319902 (16%)] Loss: 0.037998, 1 batch cost time 0.51
Train Epoch: 3 [52224/319902 (16%)] Loss: 0.043185, 1 batch cost time 0.51
Train Epoch: 3 [52736/319902 (16%)] Loss: 0.032166, 1 batch cost time 0.51
Train Epoch: 3 [53248/319902 (17%)] Loss: 0.025609, 1 batch cost time 0.51
Train Epoch: 3 [53760/319902 (17%)] Loss: 0.020238, 1 batch cost time 0.51
Train Epoch: 3 [54272/319902 (17%)] Loss: 0.039314, 1 batch cost time 0.51
Train Epoch: 3 [54784/319902 (17%)] Loss: 0.075819, 1 batch cost time 0.51
Train Epoch: 3 [55296/319902 (17%)] Loss: 0.032492, 1 batch cost time 0.51
Train Epoch: 3 [55808/319902 (17%)] Loss: 0.021807, 1 batch cost time 0.51
Train Epoch: 3 [56320/319902 (18%)] Loss: 0.024718, 1 batch cost time 0.51
Train Epoch: 3 [56832/319902 (18%)] Loss: 0.026840, 1 batch cost time 0.51
Train Epoch: 3 [57344/319902 (18%)] Loss: 0.018178, 1 batch cost time 0.51
Train Epoch: 3 [57856/319902 (18%)] Loss: 0.044545, 1 batch cost time 0.51
Train Epoch: 3 [58368/319902 (18%)] Loss: 0.016273, 1 batch cost time 0.51
Train Epoch: 3 [58880/319902 (18%)] Loss: 0.038365, 1 batch cost time 0.51
Train Epoch: 3 [59392/319902 (19%)] Loss: 0.036678, 1 batch cost time 0.51
Train Epoch: 3 [59904/319902 (19%)] Loss: 0.031661, 1 batch cost time 0.51
Train Epoch: 3 [60416/319902 (19%)] Loss: 0.022063, 1 batch cost time 0.51
Train Epoch: 3 [60928/319902 (19%)] Loss: 0.044909, 1 batch cost time 0.51
Train Epoch: 3 [61440/319902 (19%)] Loss: 0.052435, 1 batch cost time 0.51
Train Epoch: 3 [61952/319902 (19%)] Loss: 0.017100, 1 batch cost time 0.51
Train Epoch: 3 [62464/319902 (20%)] Loss: 0.018931, 1 batch cost time 0.51
Train Epoch: 3 [62976/319902 (20%)] Loss: 0.021468, 1 batch cost time 0.51
Train Epoch: 3 [63488/319902 (20%)] Loss: 0.038987, 1 batch cost time 0.51
Train Epoch: 3 [64000/319902 (20%)] Loss: 0.043780, 1 batch cost time 0.51
Train Epoch: 3 [64512/319902 (20%)] Loss: 0.016823, 1 batch cost time 0.51
Train Epoch: 3 [65024/319902 (20%)] Loss: 0.027061, 1 batch cost time 0.51
Train Epoch: 3 [65536/319902 (20%)] Loss: 0.034481, 1 batch cost time 0.51
Train Epoch: 3 [66048/319902 (21%)] Loss: 0.037847, 1 batch cost time 0.51
Train Epoch: 3 [66560/319902 (21%)] Loss: 0.045628, 1 batch cost time 0.51
Train Epoch: 3 [67072/319902 (21%)] Loss: 0.033118, 1 batch cost time 0.51
Train Epoch: 3 [67584/319902 (21%)] Loss: 0.023484, 1 batch cost time 0.51
Train Epoch: 3 [68096/319902 (21%)] Loss: 0.023807, 1 batch cost time 0.51
Train Epoch: 3 [68608/319902 (21%)] Loss: 0.017632, 1 batch cost time 0.51
Train Epoch: 3 [69120/319902 (22%)] Loss: 0.032882, 1 batch cost time 0.51
Train Epoch: 3 [69632/319902 (22%)] Loss: 0.024576, 1 batch cost time 0.51
Train Epoch: 3 [70144/319902 (22%)] Loss: 0.035609, 1 batch cost time 0.51
Train Epoch: 3 [70656/319902 (22%)] Loss: 0.048345, 1 batch cost time 0.51
Train Epoch: 3 [71168/319902 (22%)] Loss: 0.033675, 1 batch cost time 0.51
Train Epoch: 3 [71680/319902 (22%)] Loss: 0.047847, 1 batch cost time 0.51
Train Epoch: 3 [72192/319902 (23%)] Loss: 0.035546, 1 batch cost time 0.51
Train Epoch: 3 [72704/319902 (23%)] Loss: 0.029838, 1 batch cost time 0.51
Train Epoch: 3 [73216/319902 (23%)] Loss: 0.046515, 1 batch cost time 0.51
Train Epoch: 3 [73728/319902 (23%)] Loss: 0.016239, 1 batch cost time 0.51
Train Epoch: 3 [74240/319902 (23%)] Loss: 0.039599, 1 batch cost time 0.51
Train Epoch: 3 [74752/319902 (23%)] Loss: 0.052255, 1 batch cost time 0.51
Train Epoch: 3 [75264/319902 (24%)] Loss: 0.031413, 1 batch cost time 0.51
Train Epoch: 3 [75776/319902 (24%)] Loss: 0.049468, 1 batch cost time 0.51
Train Epoch: 3 [76288/319902 (24%)] Loss: 0.047978, 1 batch cost time 0.51
Train Epoch: 3 [76800/319902 (24%)] Loss: 0.050274, 1 batch cost time 0.51
Train Epoch: 3 [77312/319902 (24%)] Loss: 0.014372, 1 batch cost time 0.51
Train Epoch: 3 [77824/319902 (24%)] Loss: 0.044491, 1 batch cost time 0.51
Train Epoch: 3 [78336/319902 (24%)] Loss: 0.028895, 1 batch cost time 0.51
Train Epoch: 3 [78848/319902 (25%)] Loss: 0.039693, 1 batch cost time 0.51
Train Epoch: 3 [79360/319902 (25%)] Loss: 0.063050, 1 batch cost time 0.51
Train Epoch: 3 [79872/319902 (25%)] Loss: 0.022240, 1 batch cost time 0.51
Train Epoch: 3 [80384/319902 (25%)] Loss: 0.040950, 1 batch cost time 0.51
Train Epoch: 3 [80896/319902 (25%)] Loss: 0.031652, 1 batch cost time 0.51
Train Epoch: 3 [81408/319902 (25%)] Loss: 0.014235, 1 batch cost time 0.51
Train Epoch: 3 [81920/319902 (26%)] Loss: 0.042370, 1 batch cost time 0.51
Train Epoch: 3 [82432/319902 (26%)] Loss: 0.024866, 1 batch cost time 0.51
Train Epoch: 3 [82944/319902 (26%)] Loss: 0.031793, 1 batch cost time 0.51
Train Epoch: 3 [83456/319902 (26%)] Loss: 0.044126, 1 batch cost time 0.51
Train Epoch: 3 [83968/319902 (26%)] Loss: 0.023483, 1 batch cost time 0.51
Train Epoch: 3 [84480/319902 (26%)] Loss: 0.025510, 1 batch cost time 0.51
Train Epoch: 3 [84992/319902 (27%)] Loss: 0.039857, 1 batch cost time 0.51
Train Epoch: 3 [85504/319902 (27%)] Loss: 0.031518, 1 batch cost time 0.51
Train Epoch: 3 [86016/319902 (27%)] Loss: 0.033558, 1 batch cost time 0.51
Train Epoch: 3 [86528/319902 (27%)] Loss: 0.040484, 1 batch cost time 0.51
Train Epoch: 3 [87040/319902 (27%)] Loss: 0.055374, 1 batch cost time 0.51
Train Epoch: 3 [87552/319902 (27%)] Loss: 0.047984, 1 batch cost time 0.51
Train Epoch: 3 [88064/319902 (28%)] Loss: 0.015554, 1 batch cost time 0.51
Train Epoch: 3 [88576/319902 (28%)] Loss: 0.029131, 1 batch cost time 0.51
Train Epoch: 3 [89088/319902 (28%)] Loss: 0.021738, 1 batch cost time 0.51
Train Epoch: 3 [89600/319902 (28%)] Loss: 0.045123, 1 batch cost time 0.51
Train Epoch: 3 [90112/319902 (28%)] Loss: 0.046683, 1 batch cost time 0.51
Train Epoch: 3 [90624/319902 (28%)] Loss: 0.020273, 1 batch cost time 0.51
Train Epoch: 3 [91136/319902 (28%)] Loss: 0.050859, 1 batch cost time 0.51
Train Epoch: 3 [91648/319902 (29%)] Loss: 0.050157, 1 batch cost time 0.51
Train Epoch: 3 [92160/319902 (29%)] Loss: 0.052443, 1 batch cost time 0.51
Train Epoch: 3 [92672/319902 (29%)] Loss: 0.041853, 1 batch cost time 0.51
Train Epoch: 3 [93184/319902 (29%)] Loss: 0.039459, 1 batch cost time 0.51
Train Epoch: 3 [93696/319902 (29%)] Loss: 0.033379, 1 batch cost time 0.51
Train Epoch: 3 [94208/319902 (29%)] Loss: 0.049015, 1 batch cost time 0.51
Train Epoch: 3 [94720/319902 (30%)] Loss: 0.022984, 1 batch cost time 0.51
Train Epoch: 3 [95232/319902 (30%)] Loss: 0.045281, 1 batch cost time 0.51
Train Epoch: 3 [95744/319902 (30%)] Loss: 0.034624, 1 batch cost time 0.51
Train Epoch: 3 [96256/319902 (30%)] Loss: 0.016143, 1 batch cost time 0.51
Train Epoch: 3 [96768/319902 (30%)] Loss: 0.049228, 1 batch cost time 0.51
Train Epoch: 3 [97280/319902 (30%)] Loss: 0.018537, 1 batch cost time 0.51
Train Epoch: 3 [97792/319902 (31%)] Loss: 0.016820, 1 batch cost time 0.51
Train Epoch: 3 [98304/319902 (31%)] Loss: 0.030063, 1 batch cost time 0.51
Train Epoch: 3 [98816/319902 (31%)] Loss: 0.052611, 1 batch cost time 0.51
Train Epoch: 3 [99328/319902 (31%)] Loss: 0.028808, 1 batch cost time 0.51
Train Epoch: 3 [99840/319902 (31%)] Loss: 0.026094, 1 batch cost time 0.51
Train Epoch: 3 [100352/319902 (31%)] Loss: 0.036363, 1 batch cost time 0.51
Train Epoch: 3 [100864/319902 (32%)] Loss: 0.032464, 1 batch cost time 0.51
Train Epoch: 3 [101376/319902 (32%)] Loss: 0.066447, 1 batch cost time 0.51
Train Epoch: 3 [101888/319902 (32%)] Loss: 0.043089, 1 batch cost time 0.51
Train Epoch: 3 [102400/319902 (32%)] Loss: 0.037057, 1 batch cost time 0.51
Train Epoch: 3 [102912/319902 (32%)] Loss: 0.027224, 1 batch cost time 0.51
Train Epoch: 3 [103424/319902 (32%)] Loss: 0.026856, 1 batch cost time 0.51
Train Epoch: 3 [103936/319902 (32%)] Loss: 0.027961, 1 batch cost time 0.51
Train Epoch: 3 [104448/319902 (33%)] Loss: 0.036007, 1 batch cost time 0.51
Train Epoch: 3 [104960/319902 (33%)] Loss: 0.027972, 1 batch cost time 0.51
Train Epoch: 3 [105472/319902 (33%)] Loss: 0.054384, 1 batch cost time 0.51
Train Epoch: 3 [105984/319902 (33%)] Loss: 0.050945, 1 batch cost time 0.51
Train Epoch: 3 [106496/319902 (33%)] Loss: 0.052139, 1 batch cost time 0.51
Train Epoch: 3 [107008/319902 (33%)] Loss: 0.067392, 1 batch cost time 0.51
Train Epoch: 3 [107520/319902 (34%)] Loss: 0.044875, 1 batch cost time 0.51
Train Epoch: 3 [108032/319902 (34%)] Loss: 0.038992, 1 batch cost time 0.51
Train Epoch: 3 [108544/319902 (34%)] Loss: 0.029235, 1 batch cost time 0.51
Train Epoch: 3 [109056/319902 (34%)] Loss: 0.024618, 1 batch cost time 0.51
Train Epoch: 3 [109568/319902 (34%)] Loss: 0.025722, 1 batch cost time 0.51
Train Epoch: 3 [110080/319902 (34%)] Loss: 0.070582, 1 batch cost time 0.51
Train Epoch: 3 [110592/319902 (35%)] Loss: 0.057618, 1 batch cost time 0.51
Train Epoch: 3 [111104/319902 (35%)] Loss: 0.028871, 1 batch cost time 0.51
Train Epoch: 3 [111616/319902 (35%)] Loss: 0.024933, 1 batch cost time 0.51
Train Epoch: 3 [112128/319902 (35%)] Loss: 0.033841, 1 batch cost time 0.51
Train Epoch: 3 [112640/319902 (35%)] Loss: 0.015050, 1 batch cost time 0.51
Train Epoch: 3 [113152/319902 (35%)] Loss: 0.060492, 1 batch cost time 0.51
Train Epoch: 3 [113664/319902 (36%)] Loss: 0.021900, 1 batch cost time 0.51
Train Epoch: 3 [114176/319902 (36%)] Loss: 0.048413, 1 batch cost time 0.51
Train Epoch: 3 [114688/319902 (36%)] Loss: 0.022898, 1 batch cost time 0.51
Train Epoch: 3 [115200/319902 (36%)] Loss: 0.029339, 1 batch cost time 0.51
Train Epoch: 3 [115712/319902 (36%)] Loss: 0.067633, 1 batch cost time 0.51
Train Epoch: 3 [116224/319902 (36%)] Loss: 0.022513, 1 batch cost time 0.51
Train Epoch: 3 [116736/319902 (36%)] Loss: 0.024345, 1 batch cost time 0.51
Train Epoch: 3 [117248/319902 (37%)] Loss: 0.034114, 1 batch cost time 0.51
Train Epoch: 3 [117760/319902 (37%)] Loss: 0.049447, 1 batch cost time 0.51
Train Epoch: 3 [118272/319902 (37%)] Loss: 0.044697, 1 batch cost time 0.51
Train Epoch: 3 [118784/319902 (37%)] Loss: 0.021772, 1 batch cost time 0.51
Train Epoch: 3 [119296/319902 (37%)] Loss: 0.029962, 1 batch cost time 0.51
Train Epoch: 3 [119808/319902 (37%)] Loss: 0.026743, 1 batch cost time 0.51
Train Epoch: 3 [120320/319902 (38%)] Loss: 0.044932, 1 batch cost time 0.51
Train Epoch: 3 [120832/319902 (38%)] Loss: 0.040068, 1 batch cost time 0.51
Train Epoch: 3 [121344/319902 (38%)] Loss: 0.041753, 1 batch cost time 0.51
Train Epoch: 3 [121856/319902 (38%)] Loss: 0.045602, 1 batch cost time 0.51
Train Epoch: 3 [122368/319902 (38%)] Loss: 0.032159, 1 batch cost time 0.51
Train Epoch: 3 [122880/319902 (38%)] Loss: 0.038333, 1 batch cost time 0.51
Train Epoch: 3 [123392/319902 (39%)] Loss: 0.029969, 1 batch cost time 0.51
Train Epoch: 3 [123904/319902 (39%)] Loss: 0.045486, 1 batch cost time 0.51
Train Epoch: 3 [124416/319902 (39%)] Loss: 0.021950, 1 batch cost time 0.51
Train Epoch: 3 [124928/319902 (39%)] Loss: 0.020444, 1 batch cost time 0.51
Train Epoch: 3 [125440/319902 (39%)] Loss: 0.063887, 1 batch cost time 0.51
Train Epoch: 3 [125952/319902 (39%)] Loss: 0.053255, 1 batch cost time 0.51
Train Epoch: 3 [126464/319902 (40%)] Loss: 0.045450, 1 batch cost time 0.51
Train Epoch: 3 [126976/319902 (40%)] Loss: 0.060544, 1 batch cost time 0.51
Train Epoch: 3 [127488/319902 (40%)] Loss: 0.012773, 1 batch cost time 0.51
Train Epoch: 3 [128000/319902 (40%)] Loss: 0.051097, 1 batch cost time 0.51
Train Epoch: 3 [128512/319902 (40%)] Loss: 0.052310, 1 batch cost time 0.51
Train Epoch: 3 [129024/319902 (40%)] Loss: 0.020560, 1 batch cost time 0.51
Train Epoch: 3 [129536/319902 (40%)] Loss: 0.059974, 1 batch cost time 0.51
Train Epoch: 3 [130048/319902 (41%)] Loss: 0.025727, 1 batch cost time 0.51
Train Epoch: 3 [130560/319902 (41%)] Loss: 0.022202, 1 batch cost time 0.51
Train Epoch: 3 [131072/319902 (41%)] Loss: 0.043876, 1 batch cost time 0.51
Train Epoch: 3 [131584/319902 (41%)] Loss: 0.043626, 1 batch cost time 0.51
Train Epoch: 3 [132096/319902 (41%)] Loss: 0.041126, 1 batch cost time 0.51
Train Epoch: 3 [132608/319902 (41%)] Loss: 0.051303, 1 batch cost time 0.51
Train Epoch: 3 [133120/319902 (42%)] Loss: 0.074963, 1 batch cost time 0.51
Train Epoch: 3 [133632/319902 (42%)] Loss: 0.037619, 1 batch cost time 0.51
Train Epoch: 3 [134144/319902 (42%)] Loss: 0.052733, 1 batch cost time 0.51
Train Epoch: 3 [134656/319902 (42%)] Loss: 0.061001, 1 batch cost time 0.51
Train Epoch: 3 [135168/319902 (42%)] Loss: 0.023175, 1 batch cost time 0.51
Train Epoch: 3 [135680/319902 (42%)] Loss: 0.063500, 1 batch cost time 0.51
Train Epoch: 3 [136192/319902 (43%)] Loss: 0.065928, 1 batch cost time 0.51
Train Epoch: 3 [136704/319902 (43%)] Loss: 0.060508, 1 batch cost time 0.51
Train Epoch: 3 [137216/319902 (43%)] Loss: 0.032370, 1 batch cost time 0.51
Train Epoch: 3 [137728/319902 (43%)] Loss: 0.043981, 1 batch cost time 0.51
Train Epoch: 3 [138240/319902 (43%)] Loss: 0.060044, 1 batch cost time 0.51
Train Epoch: 3 [138752/319902 (43%)] Loss: 0.022515, 1 batch cost time 0.51
Train Epoch: 3 [139264/319902 (44%)] Loss: 0.025278, 1 batch cost time 0.51
Train Epoch: 3 [139776/319902 (44%)] Loss: 0.056795, 1 batch cost time 0.51
Train Epoch: 3 [140288/319902 (44%)] Loss: 0.038525, 1 batch cost time 0.51
Train Epoch: 3 [140800/319902 (44%)] Loss: 0.028482, 1 batch cost time 0.51
Train Epoch: 3 [141312/319902 (44%)] Loss: 0.066115, 1 batch cost time 0.51
Train Epoch: 3 [141824/319902 (44%)] Loss: 0.046945, 1 batch cost time 0.51
Train Epoch: 3 [142336/319902 (44%)] Loss: 0.046583, 1 batch cost time 0.51
Train Epoch: 3 [142848/319902 (45%)] Loss: 0.053067, 1 batch cost time 0.51
Train Epoch: 3 [143360/319902 (45%)] Loss: 0.023783, 1 batch cost time 0.51
Train Epoch: 3 [143872/319902 (45%)] Loss: 0.042298, 1 batch cost time 0.51
Train Epoch: 3 [144384/319902 (45%)] Loss: 0.040087, 1 batch cost time 0.51
Train Epoch: 3 [144896/319902 (45%)] Loss: 0.034886, 1 batch cost time 0.51
Train Epoch: 3 [145408/319902 (45%)] Loss: 0.034254, 1 batch cost time 0.51
Train Epoch: 3 [145920/319902 (46%)] Loss: 0.017216, 1 batch cost time 0.51
Train Epoch: 3 [146432/319902 (46%)] Loss: 0.023038, 1 batch cost time 0.51
Train Epoch: 3 [146944/319902 (46%)] Loss: 0.076449, 1 batch cost time 0.51
Train Epoch: 3 [147456/319902 (46%)] Loss: 0.016669, 1 batch cost time 0.51
Train Epoch: 3 [147968/319902 (46%)] Loss: 0.039009, 1 batch cost time 0.51
Train Epoch: 3 [148480/319902 (46%)] Loss: 0.035074, 1 batch cost time 0.51
Train Epoch: 3 [148992/319902 (47%)] Loss: 0.037649, 1 batch cost time 0.51
Train Epoch: 3 [149504/319902 (47%)] Loss: 0.044473, 1 batch cost time 0.51
Train Epoch: 3 [150016/319902 (47%)] Loss: 0.023835, 1 batch cost time 0.51
Train Epoch: 3 [150528/319902 (47%)] Loss: 0.035722, 1 batch cost time 0.51
Train Epoch: 3 [151040/319902 (47%)] Loss: 0.047712, 1 batch cost time 0.51
Train Epoch: 3 [151552/319902 (47%)] Loss: 0.029211, 1 batch cost time 0.51
Train Epoch: 3 [152064/319902 (48%)] Loss: 0.020112, 1 batch cost time 0.51
Train Epoch: 3 [152576/319902 (48%)] Loss: 0.045220, 1 batch cost time 0.51
Train Epoch: 3 [153088/319902 (48%)] Loss: 0.037177, 1 batch cost time 0.51
Train Epoch: 3 [153600/319902 (48%)] Loss: 0.021683, 1 batch cost time 0.51
Train Epoch: 3 [154112/319902 (48%)] Loss: 0.031546, 1 batch cost time 0.51
Train Epoch: 3 [154624/319902 (48%)] Loss: 0.065678, 1 batch cost time 0.51
Train Epoch: 3 [155136/319902 (48%)] Loss: 0.049723, 1 batch cost time 0.51
Train Epoch: 3 [155648/319902 (49%)] Loss: 0.069749, 1 batch cost time 0.51
Train Epoch: 3 [156160/319902 (49%)] Loss: 0.050489, 1 batch cost time 0.51
Train Epoch: 3 [156672/319902 (49%)] Loss: 0.026840, 1 batch cost time 0.51
Train Epoch: 3 [157184/319902 (49%)] Loss: 0.023135, 1 batch cost time 0.51
Train Epoch: 3 [157696/319902 (49%)] Loss: 0.024037, 1 batch cost time 0.51
Train Epoch: 3 [158208/319902 (49%)] Loss: 0.046407, 1 batch cost time 0.51
Train Epoch: 3 [158720/319902 (50%)] Loss: 0.048179, 1 batch cost time 0.51
Train Epoch: 3 [159232/319902 (50%)] Loss: 0.039570, 1 batch cost time 0.51
Train Epoch: 3 [159744/319902 (50%)] Loss: 0.024932, 1 batch cost time 0.51
Train Epoch: 3 [160256/319902 (50%)] Loss: 0.049923, 1 batch cost time 0.51
Train Epoch: 3 [160768/319902 (50%)] Loss: 0.023416, 1 batch cost time 0.51
Train Epoch: 3 [161280/319902 (50%)] Loss: 0.047126, 1 batch cost time 0.51
Train Epoch: 3 [161792/319902 (51%)] Loss: 0.040212, 1 batch cost time 0.51
Train Epoch: 3 [162304/319902 (51%)] Loss: 0.060063, 1 batch cost time 0.51
Train Epoch: 3 [162816/319902 (51%)] Loss: 0.049216, 1 batch cost time 0.51
Train Epoch: 3 [163328/319902 (51%)] Loss: 0.038540, 1 batch cost time 0.51
Train Epoch: 3 [163840/319902 (51%)] Loss: 0.044388, 1 batch cost time 0.51
Train Epoch: 3 [164352/319902 (51%)] Loss: 0.059197, 1 batch cost time 0.51
Train Epoch: 3 [164864/319902 (52%)] Loss: 0.022081, 1 batch cost time 0.51
Train Epoch: 3 [165376/319902 (52%)] Loss: 0.043782, 1 batch cost time 0.51
Train Epoch: 3 [165888/319902 (52%)] Loss: 0.068996, 1 batch cost time 0.51
Train Epoch: 3 [166400/319902 (52%)] Loss: 0.015559, 1 batch cost time 0.51
Train Epoch: 3 [166912/319902 (52%)] Loss: 0.068199, 1 batch cost time 0.51
Train Epoch: 3 [167424/319902 (52%)] Loss: 0.052334, 1 batch cost time 0.51
Train Epoch: 3 [167936/319902 (52%)] Loss: 0.056314, 1 batch cost time 0.51
Train Epoch: 3 [168448/319902 (53%)] Loss: 0.053518, 1 batch cost time 0.51
Train Epoch: 3 [168960/319902 (53%)] Loss: 0.039621, 1 batch cost time 0.51
Train Epoch: 3 [169472/319902 (53%)] Loss: 0.038691, 1 batch cost time 0.51
Train Epoch: 3 [169984/319902 (53%)] Loss: 0.019720, 1 batch cost time 0.51
Train Epoch: 3 [170496/319902 (53%)] Loss: 0.028778, 1 batch cost time 0.51
Train Epoch: 3 [171008/319902 (53%)] Loss: 0.036123, 1 batch cost time 0.51
Train Epoch: 3 [171520/319902 (54%)] Loss: 0.044132, 1 batch cost time 0.51
Train Epoch: 3 [172032/319902 (54%)] Loss: 0.041027, 1 batch cost time 0.51
Train Epoch: 3 [172544/319902 (54%)] Loss: 0.031556, 1 batch cost time 0.51
Train Epoch: 3 [173056/319902 (54%)] Loss: 0.026222, 1 batch cost time 0.51
Train Epoch: 3 [173568/319902 (54%)] Loss: 0.049166, 1 batch cost time 0.51
Train Epoch: 3 [174080/319902 (54%)] Loss: 0.018948, 1 batch cost time 0.51
Train Epoch: 3 [174592/319902 (55%)] Loss: 0.028034, 1 batch cost time 0.51
Train Epoch: 3 [175104/319902 (55%)] Loss: 0.055776, 1 batch cost time 0.51
Train Epoch: 3 [175616/319902 (55%)] Loss: 0.034519, 1 batch cost time 0.51
Train Epoch: 3 [176128/319902 (55%)] Loss: 0.029221, 1 batch cost time 0.51
Train Epoch: 3 [176640/319902 (55%)] Loss: 0.018460, 1 batch cost time 0.51
Train Epoch: 3 [177152/319902 (55%)] Loss: 0.051598, 1 batch cost time 0.51
Train Epoch: 3 [177664/319902 (56%)] Loss: 0.056171, 1 batch cost time 0.51
Train Epoch: 3 [178176/319902 (56%)] Loss: 0.019967, 1 batch cost time 0.51
Train Epoch: 3 [178688/319902 (56%)] Loss: 0.020984, 1 batch cost time 0.51
Train Epoch: 3 [179200/319902 (56%)] Loss: 0.044243, 1 batch cost time 0.51
Train Epoch: 3 [179712/319902 (56%)] Loss: 0.030577, 1 batch cost time 0.51
Train Epoch: 3 [180224/319902 (56%)] Loss: 0.022648, 1 batch cost time 0.51
Train Epoch: 3 [180736/319902 (56%)] Loss: 0.023221, 1 batch cost time 0.51
Train Epoch: 3 [181248/319902 (57%)] Loss: 0.032537, 1 batch cost time 0.51
Train Epoch: 3 [181760/319902 (57%)] Loss: 0.059500, 1 batch cost time 0.51
Train Epoch: 3 [182272/319902 (57%)] Loss: 0.044334, 1 batch cost time 0.51
Train Epoch: 3 [182784/319902 (57%)] Loss: 0.015105, 1 batch cost time 0.51
Train Epoch: 3 [183296/319902 (57%)] Loss: 0.042540, 1 batch cost time 0.51
Train Epoch: 3 [183808/319902 (57%)] Loss: 0.015062, 1 batch cost time 0.51
Train Epoch: 3 [184320/319902 (58%)] Loss: 0.020329, 1 batch cost time 0.51
Train Epoch: 3 [184832/319902 (58%)] Loss: 0.070566, 1 batch cost time 0.51
Train Epoch: 3 [185344/319902 (58%)] Loss: 0.023641, 1 batch cost time 0.51
Train Epoch: 3 [185856/319902 (58%)] Loss: 0.024737, 1 batch cost time 0.51
Train Epoch: 3 [186368/319902 (58%)] Loss: 0.033044, 1 batch cost time 0.51
Train Epoch: 3 [186880/319902 (58%)] Loss: 0.031448, 1 batch cost time 0.51
Train Epoch: 3 [187392/319902 (59%)] Loss: 0.040250, 1 batch cost time 0.51
Train Epoch: 3 [187904/319902 (59%)] Loss: 0.006609, 1 batch cost time 0.51
Train Epoch: 3 [188416/319902 (59%)] Loss: 0.020077, 1 batch cost time 0.51
Train Epoch: 3 [188928/319902 (59%)] Loss: 0.032293, 1 batch cost time 0.51
Train Epoch: 3 [189440/319902 (59%)] Loss: 0.024275, 1 batch cost time 0.51
Train Epoch: 3 [189952/319902 (59%)] Loss: 0.028460, 1 batch cost time 0.51
Train Epoch: 3 [190464/319902 (60%)] Loss: 0.019606, 1 batch cost time 0.51
Train Epoch: 3 [190976/319902 (60%)] Loss: 0.038826, 1 batch cost time 0.51
Train Epoch: 3 [191488/319902 (60%)] Loss: 0.035118, 1 batch cost time 0.51
Train Epoch: 3 [192000/319902 (60%)] Loss: 0.018263, 1 batch cost time 0.51
Train Epoch: 3 [192512/319902 (60%)] Loss: 0.025791, 1 batch cost time 0.51
Train Epoch: 3 [193024/319902 (60%)] Loss: 0.042819, 1 batch cost time 0.51
Train Epoch: 3 [193536/319902 (60%)] Loss: 0.021563, 1 batch cost time 0.51
Train Epoch: 3 [194048/319902 (61%)] Loss: 0.022576, 1 batch cost time 0.51
Train Epoch: 3 [194560/319902 (61%)] Loss: 0.021515, 1 batch cost time 0.51
Train Epoch: 3 [195072/319902 (61%)] Loss: 0.036823, 1 batch cost time 0.51
Train Epoch: 3 [195584/319902 (61%)] Loss: 0.008094, 1 batch cost time 0.51
Train Epoch: 3 [196096/319902 (61%)] Loss: 0.013064, 1 batch cost time 0.51
Train Epoch: 3 [196608/319902 (61%)] Loss: 0.026114, 1 batch cost time 0.51
Train Epoch: 3 [197120/319902 (62%)] Loss: 0.030974, 1 batch cost time 0.51
Train Epoch: 3 [197632/319902 (62%)] Loss: 0.017607, 1 batch cost time 0.51
Train Epoch: 3 [198144/319902 (62%)] Loss: 0.040308, 1 batch cost time 0.51
Train Epoch: 3 [198656/319902 (62%)] Loss: 0.022278, 1 batch cost time 0.51
Train Epoch: 3 [199168/319902 (62%)] Loss: 0.037996, 1 batch cost time 0.51
Train Epoch: 3 [199680/319902 (62%)] Loss: 0.051240, 1 batch cost time 0.51
Train Epoch: 3 [200192/319902 (63%)] Loss: 0.028042, 1 batch cost time 0.51
Train Epoch: 3 [200704/319902 (63%)] Loss: 0.058660, 1 batch cost time 0.51
Train Epoch: 3 [201216/319902 (63%)] Loss: 0.035241, 1 batch cost time 0.51
Train Epoch: 3 [201728/319902 (63%)] Loss: 0.030221, 1 batch cost time 0.51
Train Epoch: 3 [202240/319902 (63%)] Loss: 0.024537, 1 batch cost time 0.51
Train Epoch: 3 [202752/319902 (63%)] Loss: 0.039527, 1 batch cost time 0.51
Train Epoch: 3 [203264/319902 (64%)] Loss: 0.016126, 1 batch cost time 0.51
Train Epoch: 3 [203776/319902 (64%)] Loss: 0.032860, 1 batch cost time 0.51
Train Epoch: 3 [204288/319902 (64%)] Loss: 0.060856, 1 batch cost time 0.51
Train Epoch: 3 [204800/319902 (64%)] Loss: 0.043411, 1 batch cost time 0.51
Train Epoch: 3 [205312/319902 (64%)] Loss: 0.022714, 1 batch cost time 0.51
Train Epoch: 3 [205824/319902 (64%)] Loss: 0.039904, 1 batch cost time 0.51
Train Epoch: 3 [206336/319902 (64%)] Loss: 0.026285, 1 batch cost time 0.51
Train Epoch: 3 [206848/319902 (65%)] Loss: 0.013912, 1 batch cost time 0.51
Train Epoch: 3 [207360/319902 (65%)] Loss: 0.029716, 1 batch cost time 0.51
Train Epoch: 3 [207872/319902 (65%)] Loss: 0.043734, 1 batch cost time 0.51
Train Epoch: 3 [208384/319902 (65%)] Loss: 0.030574, 1 batch cost time 0.51
Train Epoch: 3 [208896/319902 (65%)] Loss: 0.026566, 1 batch cost time 0.51
Train Epoch: 3 [209408/319902 (65%)] Loss: 0.050190, 1 batch cost time 0.51
Train Epoch: 3 [209920/319902 (66%)] Loss: 0.030734, 1 batch cost time 0.51
Train Epoch: 3 [210432/319902 (66%)] Loss: 0.055008, 1 batch cost time 0.51
Train Epoch: 3 [210944/319902 (66%)] Loss: 0.044342, 1 batch cost time 0.51
Train Epoch: 3 [211456/319902 (66%)] Loss: 0.033525, 1 batch cost time 0.51
Train Epoch: 3 [211968/319902 (66%)] Loss: 0.027556, 1 batch cost time 0.51
Train Epoch: 3 [212480/319902 (66%)] Loss: 0.054919, 1 batch cost time 0.51
Train Epoch: 3 [212992/319902 (67%)] Loss: 0.016011, 1 batch cost time 0.51
Train Epoch: 3 [213504/319902 (67%)] Loss: 0.070235, 1 batch cost time 0.51
Train Epoch: 3 [214016/319902 (67%)] Loss: 0.029995, 1 batch cost time 0.51
Train Epoch: 3 [214528/319902 (67%)] Loss: 0.020271, 1 batch cost time 0.51
Train Epoch: 3 [215040/319902 (67%)] Loss: 0.043312, 1 batch cost time 0.51
Train Epoch: 3 [215552/319902 (67%)] Loss: 0.014147, 1 batch cost time 0.51
Train Epoch: 3 [216064/319902 (68%)] Loss: 0.061704, 1 batch cost time 0.51
Train Epoch: 3 [216576/319902 (68%)] Loss: 0.012219, 1 batch cost time 0.51
Train Epoch: 3 [217088/319902 (68%)] Loss: 0.026236, 1 batch cost time 0.51
Train Epoch: 3 [217600/319902 (68%)] Loss: 0.090205, 1 batch cost time 0.51
Train Epoch: 3 [218112/319902 (68%)] Loss: 0.023012, 1 batch cost time 0.51
Train Epoch: 3 [218624/319902 (68%)] Loss: 0.031920, 1 batch cost time 0.51
Train Epoch: 3 [219136/319902 (69%)] Loss: 0.023819, 1 batch cost time 0.51
Train Epoch: 3 [219648/319902 (69%)] Loss: 0.046530, 1 batch cost time 0.51
Train Epoch: 3 [220160/319902 (69%)] Loss: 0.027395, 1 batch cost time 0.51
Train Epoch: 3 [220672/319902 (69%)] Loss: 0.054919, 1 batch cost time 0.51
Train Epoch: 3 [221184/319902 (69%)] Loss: 0.024162, 1 batch cost time 0.51
Train Epoch: 3 [221696/319902 (69%)] Loss: 0.030978, 1 batch cost time 0.51
Train Epoch: 3 [222208/319902 (69%)] Loss: 0.042735, 1 batch cost time 0.51
Train Epoch: 3 [222720/319902 (70%)] Loss: 0.032924, 1 batch cost time 0.51
Train Epoch: 3 [223232/319902 (70%)] Loss: 0.013357, 1 batch cost time 0.51
Train Epoch: 3 [223744/319902 (70%)] Loss: 0.016824, 1 batch cost time 0.51
Train Epoch: 3 [224256/319902 (70%)] Loss: 0.022178, 1 batch cost time 0.51
Train Epoch: 3 [224768/319902 (70%)] Loss: 0.036145, 1 batch cost time 0.51
Train Epoch: 3 [225280/319902 (70%)] Loss: 0.068143, 1 batch cost time 0.51
Train Epoch: 3 [225792/319902 (71%)] Loss: 0.022852, 1 batch cost time 0.51
Train Epoch: 3 [226304/319902 (71%)] Loss: 0.019014, 1 batch cost time 0.51
Train Epoch: 3 [226816/319902 (71%)] Loss: 0.062845, 1 batch cost time 0.51
Train Epoch: 3 [227328/319902 (71%)] Loss: 0.043637, 1 batch cost time 0.51
Train Epoch: 3 [227840/319902 (71%)] Loss: 0.038595, 1 batch cost time 0.51
Train Epoch: 3 [228352/319902 (71%)] Loss: 0.017389, 1 batch cost time 0.51
Train Epoch: 3 [228864/319902 (72%)] Loss: 0.042099, 1 batch cost time 0.51
Train Epoch: 3 [229376/319902 (72%)] Loss: 0.034044, 1 batch cost time 0.51
Train Epoch: 3 [229888/319902 (72%)] Loss: 0.028787, 1 batch cost time 0.51
Train Epoch: 3 [230400/319902 (72%)] Loss: 0.019847, 1 batch cost time 0.51
Train Epoch: 3 [230912/319902 (72%)] Loss: 0.041932, 1 batch cost time 0.51
Train Epoch: 3 [231424/319902 (72%)] Loss: 0.016004, 1 batch cost time 0.51
Train Epoch: 3 [231936/319902 (73%)] Loss: 0.031785, 1 batch cost time 0.51
Train Epoch: 3 [232448/319902 (73%)] Loss: 0.045434, 1 batch cost time 0.51
Train Epoch: 3 [232960/319902 (73%)] Loss: 0.028853, 1 batch cost time 0.51
Train Epoch: 3 [233472/319902 (73%)] Loss: 0.025531, 1 batch cost time 0.51
Train Epoch: 3 [233984/319902 (73%)] Loss: 0.043888, 1 batch cost time 0.51
Train Epoch: 3 [234496/319902 (73%)] Loss: 0.019828, 1 batch cost time 0.51
Train Epoch: 3 [235008/319902 (73%)] Loss: 0.043690, 1 batch cost time 0.51
Train Epoch: 3 [235520/319902 (74%)] Loss: 0.045681, 1 batch cost time 0.51
Train Epoch: 3 [236032/319902 (74%)] Loss: 0.014064, 1 batch cost time 0.51
Train Epoch: 3 [236544/319902 (74%)] Loss: 0.027738, 1 batch cost time 0.51
Train Epoch: 3 [237056/319902 (74%)] Loss: 0.052150, 1 batch cost time 0.51
Train Epoch: 3 [237568/319902 (74%)] Loss: 0.024038, 1 batch cost time 0.51
Train Epoch: 3 [238080/319902 (74%)] Loss: 0.038873, 1 batch cost time 0.51
Train Epoch: 3 [238592/319902 (75%)] Loss: 0.043261, 1 batch cost time 0.51
Train Epoch: 3 [239104/319902 (75%)] Loss: 0.023952, 1 batch cost time 0.51
Train Epoch: 3 [239616/319902 (75%)] Loss: 0.024631, 1 batch cost time 0.51
Train Epoch: 3 [240128/319902 (75%)] Loss: 0.041723, 1 batch cost time 0.51
Train Epoch: 3 [240640/319902 (75%)] Loss: 0.021551, 1 batch cost time 0.51
Train Epoch: 3 [241152/319902 (75%)] Loss: 0.055534, 1 batch cost time 0.51
Train Epoch: 3 [241664/319902 (76%)] Loss: 0.055136, 1 batch cost time 0.51
Train Epoch: 3 [242176/319902 (76%)] Loss: 0.017348, 1 batch cost time 0.51
Train Epoch: 3 [242688/319902 (76%)] Loss: 0.060870, 1 batch cost time 0.51
Train Epoch: 3 [243200/319902 (76%)] Loss: 0.033531, 1 batch cost time 0.51
Train Epoch: 3 [243712/319902 (76%)] Loss: 0.012576, 1 batch cost time 0.51
Train Epoch: 3 [244224/319902 (76%)] Loss: 0.037357, 1 batch cost time 0.51
Train Epoch: 3 [244736/319902 (77%)] Loss: 0.045864, 1 batch cost time 0.51
Train Epoch: 3 [245248/319902 (77%)] Loss: 0.027357, 1 batch cost time 0.51
Train Epoch: 3 [245760/319902 (77%)] Loss: 0.038816, 1 batch cost time 0.51
Train Epoch: 3 [246272/319902 (77%)] Loss: 0.019491, 1 batch cost time 0.51
Train Epoch: 3 [246784/319902 (77%)] Loss: 0.020774, 1 batch cost time 0.51
Train Epoch: 3 [247296/319902 (77%)] Loss: 0.033699, 1 batch cost time 0.51
Train Epoch: 3 [247808/319902 (77%)] Loss: 0.032539, 1 batch cost time 0.51
Train Epoch: 3 [248320/319902 (78%)] Loss: 0.036969, 1 batch cost time 0.51
Train Epoch: 3 [248832/319902 (78%)] Loss: 0.036769, 1 batch cost time 0.51
Train Epoch: 3 [249344/319902 (78%)] Loss: 0.034703, 1 batch cost time 0.51
Train Epoch: 3 [249856/319902 (78%)] Loss: 0.017553, 1 batch cost time 0.51
Train Epoch: 3 [250368/319902 (78%)] Loss: 0.030342, 1 batch cost time 0.51
Train Epoch: 3 [250880/319902 (78%)] Loss: 0.011146, 1 batch cost time 0.51
Train Epoch: 3 [251392/319902 (79%)] Loss: 0.021142, 1 batch cost time 0.51
Train Epoch: 3 [251904/319902 (79%)] Loss: 0.042330, 1 batch cost time 0.51
Train Epoch: 3 [252416/319902 (79%)] Loss: 0.026333, 1 batch cost time 0.51
Train Epoch: 3 [252928/319902 (79%)] Loss: 0.026407, 1 batch cost time 0.51
Train Epoch: 3 [253440/319902 (79%)] Loss: 0.030273, 1 batch cost time 0.51
Train Epoch: 3 [253952/319902 (79%)] Loss: 0.043350, 1 batch cost time 0.51
Train Epoch: 3 [254464/319902 (80%)] Loss: 0.026378, 1 batch cost time 0.51
Train Epoch: 3 [254976/319902 (80%)] Loss: 0.049911, 1 batch cost time 0.51
Train Epoch: 3 [255488/319902 (80%)] Loss: 0.064646, 1 batch cost time 0.51
Train Epoch: 3 [256000/319902 (80%)] Loss: 0.026942, 1 batch cost time 0.51
Train Epoch: 3 [256512/319902 (80%)] Loss: 0.030663, 1 batch cost time 0.51
Train Epoch: 3 [257024/319902 (80%)] Loss: 0.031970, 1 batch cost time 0.51
Train Epoch: 3 [257536/319902 (81%)] Loss: 0.025325, 1 batch cost time 0.51
Train Epoch: 3 [258048/319902 (81%)] Loss: 0.050611, 1 batch cost time 0.51
Train Epoch: 3 [258560/319902 (81%)] Loss: 0.017440, 1 batch cost time 0.51
Train Epoch: 3 [259072/319902 (81%)] Loss: 0.027376, 1 batch cost time 0.51
Train Epoch: 3 [259584/319902 (81%)] Loss: 0.010209, 1 batch cost time 0.51
Train Epoch: 3 [260096/319902 (81%)] Loss: 0.026638, 1 batch cost time 0.51
Train Epoch: 3 [260608/319902 (81%)] Loss: 0.068461, 1 batch cost time 0.51
Train Epoch: 3 [261120/319902 (82%)] Loss: 0.033247, 1 batch cost time 0.51
Train Epoch: 3 [261632/319902 (82%)] Loss: 0.006982, 1 batch cost time 0.51
Train Epoch: 3 [262144/319902 (82%)] Loss: 0.035968, 1 batch cost time 0.51
Train Epoch: 3 [262656/319902 (82%)] Loss: 0.041163, 1 batch cost time 0.51
Train Epoch: 3 [263168/319902 (82%)] Loss: 0.039499, 1 batch cost time 0.51
Train Epoch: 3 [263680/319902 (82%)] Loss: 0.044675, 1 batch cost time 0.51
Train Epoch: 3 [264192/319902 (83%)] Loss: 0.014540, 1 batch cost time 0.51
Train Epoch: 3 [264704/319902 (83%)] Loss: 0.048044, 1 batch cost time 0.51
Train Epoch: 3 [265216/319902 (83%)] Loss: 0.034326, 1 batch cost time 0.51
Train Epoch: 3 [265728/319902 (83%)] Loss: 0.056237, 1 batch cost time 0.51
Train Epoch: 3 [266240/319902 (83%)] Loss: 0.038414, 1 batch cost time 0.51
Train Epoch: 3 [266752/319902 (83%)] Loss: 0.028397, 1 batch cost time 0.51
Train Epoch: 3 [267264/319902 (84%)] Loss: 0.035731, 1 batch cost time 0.51
Train Epoch: 3 [267776/319902 (84%)] Loss: 0.081831, 1 batch cost time 0.51
Train Epoch: 3 [268288/319902 (84%)] Loss: 0.054147, 1 batch cost time 0.51
Train Epoch: 3 [268800/319902 (84%)] Loss: 0.055729, 1 batch cost time 0.51
Train Epoch: 3 [269312/319902 (84%)] Loss: 0.029862, 1 batch cost time 0.51
Train Epoch: 3 [269824/319902 (84%)] Loss: 0.027405, 1 batch cost time 0.51
Train Epoch: 3 [270336/319902 (85%)] Loss: 0.063504, 1 batch cost time 0.51
Train Epoch: 3 [270848/319902 (85%)] Loss: 0.072005, 1 batch cost time 0.51
Train Epoch: 3 [271360/319902 (85%)] Loss: 0.020391, 1 batch cost time 0.51
Train Epoch: 3 [271872/319902 (85%)] Loss: 0.018838, 1 batch cost time 0.52
Train Epoch: 3 [272384/319902 (85%)] Loss: 0.042952, 1 batch cost time 0.51
Train Epoch: 3 [272896/319902 (85%)] Loss: 0.019696, 1 batch cost time 0.51
Train Epoch: 3 [273408/319902 (85%)] Loss: 0.015245, 1 batch cost time 0.51
Train Epoch: 3 [273920/319902 (86%)] Loss: 0.019675, 1 batch cost time 0.51
Train Epoch: 3 [274432/319902 (86%)] Loss: 0.049499, 1 batch cost time 0.51
Train Epoch: 3 [274944/319902 (86%)] Loss: 0.021688, 1 batch cost time 0.51
Train Epoch: 3 [275456/319902 (86%)] Loss: 0.035610, 1 batch cost time 0.51
Train Epoch: 3 [275968/319902 (86%)] Loss: 0.039648, 1 batch cost time 0.51
Train Epoch: 3 [276480/319902 (86%)] Loss: 0.019116, 1 batch cost time 0.51
Train Epoch: 3 [276992/319902 (87%)] Loss: 0.034298, 1 batch cost time 0.51
Train Epoch: 3 [277504/319902 (87%)] Loss: 0.024377, 1 batch cost time 0.51
Train Epoch: 3 [278016/319902 (87%)] Loss: 0.068734, 1 batch cost time 0.51
Train Epoch: 3 [278528/319902 (87%)] Loss: 0.048508, 1 batch cost time 0.51
Train Epoch: 3 [279040/319902 (87%)] Loss: 0.032568, 1 batch cost time 0.51
Train Epoch: 3 [279552/319902 (87%)] Loss: 0.009692, 1 batch cost time 0.51
Train Epoch: 3 [280064/319902 (88%)] Loss: 0.037956, 1 batch cost time 0.51
Train Epoch: 3 [280576/319902 (88%)] Loss: 0.046994, 1 batch cost time 0.51
Train Epoch: 3 [281088/319902 (88%)] Loss: 0.033643, 1 batch cost time 0.51
Train Epoch: 3 [281600/319902 (88%)] Loss: 0.100493, 1 batch cost time 0.51
Train Epoch: 3 [282112/319902 (88%)] Loss: 0.034707, 1 batch cost time 0.51
Train Epoch: 3 [282624/319902 (88%)] Loss: 0.048096, 1 batch cost time 0.51
Train Epoch: 3 [283136/319902 (89%)] Loss: 0.033962, 1 batch cost time 0.51
Train Epoch: 3 [283648/319902 (89%)] Loss: 0.045283, 1 batch cost time 0.51
Train Epoch: 3 [284160/319902 (89%)] Loss: 0.019727, 1 batch cost time 0.51
Train Epoch: 3 [284672/319902 (89%)] Loss: 0.070899, 1 batch cost time 0.51
Train Epoch: 3 [285184/319902 (89%)] Loss: 0.057173, 1 batch cost time 0.51
Train Epoch: 3 [285696/319902 (89%)] Loss: 0.046768, 1 batch cost time 0.51
Train Epoch: 3 [286208/319902 (89%)] Loss: 0.025325, 1 batch cost time 0.51
Train Epoch: 3 [286720/319902 (90%)] Loss: 0.028359, 1 batch cost time 0.51
Train Epoch: 3 [287232/319902 (90%)] Loss: 0.042110, 1 batch cost time 0.51
Train Epoch: 3 [287744/319902 (90%)] Loss: 0.053859, 1 batch cost time 0.51
Train Epoch: 3 [288256/319902 (90%)] Loss: 0.034427, 1 batch cost time 0.51
Train Epoch: 3 [288768/319902 (90%)] Loss: 0.055634, 1 batch cost time 0.51
Train Epoch: 3 [289280/319902 (90%)] Loss: 0.033061, 1 batch cost time 0.51
Train Epoch: 3 [289792/319902 (91%)] Loss: 0.030950, 1 batch cost time 0.51
Train Epoch: 3 [290304/319902 (91%)] Loss: 0.028563, 1 batch cost time 0.51
Train Epoch: 3 [290816/319902 (91%)] Loss: 0.055561, 1 batch cost time 0.51
Train Epoch: 3 [291328/319902 (91%)] Loss: 0.020689, 1 batch cost time 0.51
Train Epoch: 3 [291840/319902 (91%)] Loss: 0.032091, 1 batch cost time 0.51
Train Epoch: 3 [292352/319902 (91%)] Loss: 0.024313, 1 batch cost time 0.51
Train Epoch: 3 [292864/319902 (92%)] Loss: 0.022592, 1 batch cost time 0.51
Train Epoch: 3 [293376/319902 (92%)] Loss: 0.048724, 1 batch cost time 0.51
Train Epoch: 3 [293888/319902 (92%)] Loss: 0.043849, 1 batch cost time 0.51
Train Epoch: 3 [294400/319902 (92%)] Loss: 0.015270, 1 batch cost time 0.51
Train Epoch: 3 [294912/319902 (92%)] Loss: 0.037209, 1 batch cost time 0.51
Train Epoch: 3 [295424/319902 (92%)] Loss: 0.021398, 1 batch cost time 0.51
Train Epoch: 3 [295936/319902 (93%)] Loss: 0.048935, 1 batch cost time 0.51
Train Epoch: 3 [296448/319902 (93%)] Loss: 0.015946, 1 batch cost time 0.51
Train Epoch: 3 [296960/319902 (93%)] Loss: 0.023060, 1 batch cost time 0.51
Train Epoch: 3 [297472/319902 (93%)] Loss: 0.024598, 1 batch cost time 0.51
Train Epoch: 3 [297984/319902 (93%)] Loss: 0.057797, 1 batch cost time 0.51
Train Epoch: 3 [298496/319902 (93%)] Loss: 0.046872, 1 batch cost time 0.51
Train Epoch: 3 [299008/319902 (93%)] Loss: 0.035585, 1 batch cost time 0.51
Train Epoch: 3 [299520/319902 (94%)] Loss: 0.043361, 1 batch cost time 0.51
Train Epoch: 3 [300032/319902 (94%)] Loss: 0.033591, 1 batch cost time 0.51
Train Epoch: 3 [300544/319902 (94%)] Loss: 0.024113, 1 batch cost time 0.51
Train Epoch: 3 [301056/319902 (94%)] Loss: 0.014121, 1 batch cost time 0.51
Train Epoch: 3 [301568/319902 (94%)] Loss: 0.018569, 1 batch cost time 0.51
Train Epoch: 3 [302080/319902 (94%)] Loss: 0.027229, 1 batch cost time 0.51
Train Epoch: 3 [302592/319902 (95%)] Loss: 0.021827, 1 batch cost time 0.51
Train Epoch: 3 [303104/319902 (95%)] Loss: 0.029350, 1 batch cost time 0.51
Train Epoch: 3 [303616/319902 (95%)] Loss: 0.075958, 1 batch cost time 0.51
Train Epoch: 3 [304128/319902 (95%)] Loss: 0.044055, 1 batch cost time 0.51
Train Epoch: 3 [304640/319902 (95%)] Loss: 0.020437, 1 batch cost time 0.51
Train Epoch: 3 [305152/319902 (95%)] Loss: 0.030186, 1 batch cost time 0.51
Train Epoch: 3 [305664/319902 (96%)] Loss: 0.033065, 1 batch cost time 0.51
Train Epoch: 3 [306176/319902 (96%)] Loss: 0.024181, 1 batch cost time 0.51
Train Epoch: 3 [306688/319902 (96%)] Loss: 0.027881, 1 batch cost time 0.51
Train Epoch: 3 [307200/319902 (96%)] Loss: 0.059338, 1 batch cost time 0.51
Train Epoch: 3 [307712/319902 (96%)] Loss: 0.074348, 1 batch cost time 0.51
Train Epoch: 3 [308224/319902 (96%)] Loss: 0.027342, 1 batch cost time 0.51
Train Epoch: 3 [308736/319902 (97%)] Loss: 0.026613, 1 batch cost time 0.51
Train Epoch: 3 [309248/319902 (97%)] Loss: 0.058268, 1 batch cost time 0.51
Train Epoch: 3 [309760/319902 (97%)] Loss: 0.043226, 1 batch cost time 0.51
Train Epoch: 3 [310272/319902 (97%)] Loss: 0.038972, 1 batch cost time 0.51
Train Epoch: 3 [310784/319902 (97%)] Loss: 0.045468, 1 batch cost time 0.51
Train Epoch: 3 [311296/319902 (97%)] Loss: 0.063066, 1 batch cost time 0.51
Train Epoch: 3 [311808/319902 (97%)] Loss: 0.036238, 1 batch cost time 0.51
Train Epoch: 3 [312320/319902 (98%)] Loss: 0.063707, 1 batch cost time 0.51
Train Epoch: 3 [312832/319902 (98%)] Loss: 0.021733, 1 batch cost time 0.51
Train Epoch: 3 [313344/319902 (98%)] Loss: 0.016540, 1 batch cost time 0.51
Train Epoch: 3 [313856/319902 (98%)] Loss: 0.023790, 1 batch cost time 0.51
Train Epoch: 3 [314368/319902 (98%)] Loss: 0.021857, 1 batch cost time 0.51
Train Epoch: 3 [314880/319902 (98%)] Loss: 0.050994, 1 batch cost time 0.51
Train Epoch: 3 [315392/319902 (99%)] Loss: 0.016942, 1 batch cost time 0.51
Train Epoch: 3 [315904/319902 (99%)] Loss: 0.035168, 1 batch cost time 0.51
Train Epoch: 3 [316416/319902 (99%)] Loss: 0.026939, 1 batch cost time 0.52
Train Epoch: 3 [316928/319902 (99%)] Loss: 0.029850, 1 batch cost time 0.51
Train Epoch: 3 [317440/319902 (99%)] Loss: 0.048257, 1 batch cost time 0.51
Train Epoch: 3 [317952/319902 (99%)] Loss: 0.036841, 1 batch cost time 0.51
Train Epoch: 3 [318464/319902 (100%)] Loss: 0.055689, 1 batch cost time 0.51
Train Epoch: 3 [318976/319902 (100%)] Loss: 0.045222, 1 batch cost time 0.51
Train Epoch: 3 [319488/319902 (100%)] Loss: 0.027914, 1 batch cost time 0.51
training epoch cost 8043.260285615921 seconds
    epoch          : 3
    lr             : 0.0001
    loss           : 0.03585390316914259
    accuracy       : 0.9242478241296519
    f_measure      : 0.4836193412689012
    val_loss       : 0.028199896196989965
    val_accuracy   : 0.9365234375
    val_f_measure  : 0.5275465718694884
Saving current best: model_best.pth ...
Train Epoch: 4 [0/319902 (0%)] Loss: 0.053523, 1 batch cost time 0.52
Train Epoch: 4 [512/319902 (0%)] Loss: 0.044509, 1 batch cost time 0.51
Train Epoch: 4 [1024/319902 (0%)] Loss: 0.017973, 1 batch cost time 0.51
Train Epoch: 4 [1536/319902 (0%)] Loss: 0.037481, 1 batch cost time 0.51
Train Epoch: 4 [2048/319902 (1%)] Loss: 0.073699, 1 batch cost time 0.51
Train Epoch: 4 [2560/319902 (1%)] Loss: 0.036436, 1 batch cost time 0.51
Train Epoch: 4 [3072/319902 (1%)] Loss: 0.022965, 1 batch cost time 0.51
Train Epoch: 4 [3584/319902 (1%)] Loss: 0.031024, 1 batch cost time 0.51
Train Epoch: 4 [4096/319902 (1%)] Loss: 0.027678, 1 batch cost time 0.51
Train Epoch: 4 [4608/319902 (1%)] Loss: 0.026024, 1 batch cost time 0.51
Train Epoch: 4 [5120/319902 (2%)] Loss: 0.029618, 1 batch cost time 0.51
Train Epoch: 4 [5632/319902 (2%)] Loss: 0.035331, 1 batch cost time 0.51
Train Epoch: 4 [6144/319902 (2%)] Loss: 0.024506, 1 batch cost time 0.51
Train Epoch: 4 [6656/319902 (2%)] Loss: 0.030453, 1 batch cost time 0.51
Train Epoch: 4 [7168/319902 (2%)] Loss: 0.027977, 1 batch cost time 0.51
Train Epoch: 4 [7680/319902 (2%)] Loss: 0.025943, 1 batch cost time 0.51
Train Epoch: 4 [8192/319902 (3%)] Loss: 0.021521, 1 batch cost time 0.51
Train Epoch: 4 [8704/319902 (3%)] Loss: 0.030048, 1 batch cost time 0.51
Train Epoch: 4 [9216/319902 (3%)] Loss: 0.021107, 1 batch cost time 0.51
Train Epoch: 4 [9728/319902 (3%)] Loss: 0.071289, 1 batch cost time 0.51
Train Epoch: 4 [10240/319902 (3%)] Loss: 0.028266, 1 batch cost time 0.51
Train Epoch: 4 [10752/319902 (3%)] Loss: 0.033633, 1 batch cost time 0.51
Train Epoch: 4 [11264/319902 (4%)] Loss: 0.049061, 1 batch cost time 0.51
Train Epoch: 4 [11776/319902 (4%)] Loss: 0.023095, 1 batch cost time 0.51
Train Epoch: 4 [12288/319902 (4%)] Loss: 0.041046, 1 batch cost time 0.51
Train Epoch: 4 [12800/319902 (4%)] Loss: 0.039013, 1 batch cost time 0.51
Train Epoch: 4 [13312/319902 (4%)] Loss: 0.038289, 1 batch cost time 0.51
Train Epoch: 4 [13824/319902 (4%)] Loss: 0.035239, 1 batch cost time 0.51
Train Epoch: 4 [14336/319902 (4%)] Loss: 0.011565, 1 batch cost time 0.51
Train Epoch: 4 [14848/319902 (5%)] Loss: 0.036779, 1 batch cost time 0.51
Train Epoch: 4 [15360/319902 (5%)] Loss: 0.021430, 1 batch cost time 0.51
Train Epoch: 4 [15872/319902 (5%)] Loss: 0.034736, 1 batch cost time 0.51
Train Epoch: 4 [16384/319902 (5%)] Loss: 0.041727, 1 batch cost time 0.51
Train Epoch: 4 [16896/319902 (5%)] Loss: 0.039098, 1 batch cost time 0.51
Train Epoch: 4 [17408/319902 (5%)] Loss: 0.025284, 1 batch cost time 0.51
Train Epoch: 4 [17920/319902 (6%)] Loss: 0.018752, 1 batch cost time 0.51
Train Epoch: 4 [18432/319902 (6%)] Loss: 0.017574, 1 batch cost time 0.51
Train Epoch: 4 [18944/319902 (6%)] Loss: 0.045184, 1 batch cost time 0.51
Train Epoch: 4 [19456/319902 (6%)] Loss: 0.027148, 1 batch cost time 0.51
Train Epoch: 4 [19968/319902 (6%)] Loss: 0.027222, 1 batch cost time 0.51
Train Epoch: 4 [20480/319902 (6%)] Loss: 0.021465, 1 batch cost time 0.51
Train Epoch: 4 [20992/319902 (7%)] Loss: 0.034526, 1 batch cost time 0.51
Train Epoch: 4 [21504/319902 (7%)] Loss: 0.028273, 1 batch cost time 0.51
Train Epoch: 4 [22016/319902 (7%)] Loss: 0.052394, 1 batch cost time 0.51
Train Epoch: 4 [22528/319902 (7%)] Loss: 0.066869, 1 batch cost time 0.51
Train Epoch: 4 [23040/319902 (7%)] Loss: 0.021015, 1 batch cost time 0.51
Train Epoch: 4 [23552/319902 (7%)] Loss: 0.035516, 1 batch cost time 0.51
Train Epoch: 4 [24064/319902 (8%)] Loss: 0.048528, 1 batch cost time 0.51
Train Epoch: 4 [24576/319902 (8%)] Loss: 0.027261, 1 batch cost time 0.51
Train Epoch: 4 [25088/319902 (8%)] Loss: 0.038851, 1 batch cost time 0.51
Train Epoch: 4 [25600/319902 (8%)] Loss: 0.046467, 1 batch cost time 0.51
Train Epoch: 4 [26112/319902 (8%)] Loss: 0.053994, 1 batch cost time 0.51
Train Epoch: 4 [26624/319902 (8%)] Loss: 0.037413, 1 batch cost time 0.51
Train Epoch: 4 [27136/319902 (8%)] Loss: 0.039900, 1 batch cost time 0.51
Train Epoch: 4 [27648/319902 (9%)] Loss: 0.017123, 1 batch cost time 0.51
Train Epoch: 4 [28160/319902 (9%)] Loss: 0.066518, 1 batch cost time 0.51
Train Epoch: 4 [28672/319902 (9%)] Loss: 0.034377, 1 batch cost time 0.51
Train Epoch: 4 [29184/319902 (9%)] Loss: 0.023279, 1 batch cost time 0.51
Train Epoch: 4 [29696/319902 (9%)] Loss: 0.013294, 1 batch cost time 0.51
Train Epoch: 4 [30208/319902 (9%)] Loss: 0.048008, 1 batch cost time 0.51
Train Epoch: 4 [30720/319902 (10%)] Loss: 0.022142, 1 batch cost time 0.51
Train Epoch: 4 [31232/319902 (10%)] Loss: 0.029332, 1 batch cost time 0.51
Train Epoch: 4 [31744/319902 (10%)] Loss: 0.016411, 1 batch cost time 0.51
Train Epoch: 4 [32256/319902 (10%)] Loss: 0.030703, 1 batch cost time 0.51
Train Epoch: 4 [32768/319902 (10%)] Loss: 0.036238, 1 batch cost time 0.51
Train Epoch: 4 [33280/319902 (10%)] Loss: 0.050756, 1 batch cost time 0.51
Train Epoch: 4 [33792/319902 (11%)] Loss: 0.052767, 1 batch cost time 0.51
Train Epoch: 4 [34304/319902 (11%)] Loss: 0.041146, 1 batch cost time 0.51
Train Epoch: 4 [34816/319902 (11%)] Loss: 0.032981, 1 batch cost time 0.51
Train Epoch: 4 [35328/319902 (11%)] Loss: 0.062929, 1 batch cost time 0.51
Train Epoch: 4 [35840/319902 (11%)] Loss: 0.023935, 1 batch cost time 0.51
Train Epoch: 4 [36352/319902 (11%)] Loss: 0.052234, 1 batch cost time 0.51
Train Epoch: 4 [36864/319902 (12%)] Loss: 0.048567, 1 batch cost time 0.51
Train Epoch: 4 [37376/319902 (12%)] Loss: 0.030891, 1 batch cost time 0.51
Train Epoch: 4 [37888/319902 (12%)] Loss: 0.050147, 1 batch cost time 0.51
Train Epoch: 4 [38400/319902 (12%)] Loss: 0.011924, 1 batch cost time 0.51
Train Epoch: 4 [38912/319902 (12%)] Loss: 0.016694, 1 batch cost time 0.51
Train Epoch: 4 [39424/319902 (12%)] Loss: 0.053847, 1 batch cost time 0.51
Train Epoch: 4 [39936/319902 (12%)] Loss: 0.027110, 1 batch cost time 0.51
Train Epoch: 4 [40448/319902 (13%)] Loss: 0.047636, 1 batch cost time 0.51
Train Epoch: 4 [40960/319902 (13%)] Loss: 0.034754, 1 batch cost time 0.51
Train Epoch: 4 [41472/319902 (13%)] Loss: 0.026970, 1 batch cost time 0.51
Train Epoch: 4 [41984/319902 (13%)] Loss: 0.021061, 1 batch cost time 0.51
Train Epoch: 4 [42496/319902 (13%)] Loss: 0.035948, 1 batch cost time 0.51
Train Epoch: 4 [43008/319902 (13%)] Loss: 0.010892, 1 batch cost time 0.51
Train Epoch: 4 [43520/319902 (14%)] Loss: 0.015740, 1 batch cost time 0.51
Train Epoch: 4 [44032/319902 (14%)] Loss: 0.049511, 1 batch cost time 0.51
Train Epoch: 4 [44544/319902 (14%)] Loss: 0.058143, 1 batch cost time 0.51
Train Epoch: 4 [45056/319902 (14%)] Loss: 0.038458, 1 batch cost time 0.51
Train Epoch: 4 [45568/319902 (14%)] Loss: 0.030573, 1 batch cost time 0.51
Train Epoch: 4 [46080/319902 (14%)] Loss: 0.040152, 1 batch cost time 0.51
Train Epoch: 4 [46592/319902 (15%)] Loss: 0.061145, 1 batch cost time 0.51
Train Epoch: 4 [47104/319902 (15%)] Loss: 0.026918, 1 batch cost time 0.51
Train Epoch: 4 [47616/319902 (15%)] Loss: 0.028729, 1 batch cost time 0.51
Train Epoch: 4 [48128/319902 (15%)] Loss: 0.041115, 1 batch cost time 0.51
Train Epoch: 4 [48640/319902 (15%)] Loss: 0.032410, 1 batch cost time 0.51
Train Epoch: 4 [49152/319902 (15%)] Loss: 0.041115, 1 batch cost time 0.51
Train Epoch: 4 [49664/319902 (16%)] Loss: 0.053338, 1 batch cost time 0.51
Train Epoch: 4 [50176/319902 (16%)] Loss: 0.034469, 1 batch cost time 0.51
Train Epoch: 4 [50688/319902 (16%)] Loss: 0.008285, 1 batch cost time 0.51
Train Epoch: 4 [51200/319902 (16%)] Loss: 0.053752, 1 batch cost time 0.51
Train Epoch: 4 [51712/319902 (16%)] Loss: 0.035129, 1 batch cost time 0.51
Train Epoch: 4 [52224/319902 (16%)] Loss: 0.034643, 1 batch cost time 0.51
Train Epoch: 4 [52736/319902 (16%)] Loss: 0.043795, 1 batch cost time 0.51
Train Epoch: 4 [53248/319902 (17%)] Loss: 0.042420, 1 batch cost time 0.51
Train Epoch: 4 [53760/319902 (17%)] Loss: 0.032232, 1 batch cost time 0.51
Train Epoch: 4 [54272/319902 (17%)] Loss: 0.022639, 1 batch cost time 0.51
Train Epoch: 4 [54784/319902 (17%)] Loss: 0.046701, 1 batch cost time 0.51
Train Epoch: 4 [55296/319902 (17%)] Loss: 0.065344, 1 batch cost time 0.51
Train Epoch: 4 [55808/319902 (17%)] Loss: 0.026258, 1 batch cost time 0.51
Train Epoch: 4 [56320/319902 (18%)] Loss: 0.040828, 1 batch cost time 0.51
Train Epoch: 4 [56832/319902 (18%)] Loss: 0.030882, 1 batch cost time 0.51
Train Epoch: 4 [57344/319902 (18%)] Loss: 0.055029, 1 batch cost time 0.51
Train Epoch: 4 [57856/319902 (18%)] Loss: 0.037987, 1 batch cost time 0.51
Train Epoch: 4 [58368/319902 (18%)] Loss: 0.035166, 1 batch cost time 0.51
Train Epoch: 4 [58880/319902 (18%)] Loss: 0.018485, 1 batch cost time 0.51
Train Epoch: 4 [59392/319902 (19%)] Loss: 0.019194, 1 batch cost time 0.51
Train Epoch: 4 [59904/319902 (19%)] Loss: 0.018211, 1 batch cost time 0.51
Train Epoch: 4 [60416/319902 (19%)] Loss: 0.016983, 1 batch cost time 0.51
Train Epoch: 4 [60928/319902 (19%)] Loss: 0.016627, 1 batch cost time 0.51
Train Epoch: 4 [61440/319902 (19%)] Loss: 0.027723, 1 batch cost time 0.51
Train Epoch: 4 [61952/319902 (19%)] Loss: 0.040074, 1 batch cost time 0.51
Train Epoch: 4 [62464/319902 (20%)] Loss: 0.017918, 1 batch cost time 0.51
Train Epoch: 4 [62976/319902 (20%)] Loss: 0.035496, 1 batch cost time 0.51
Train Epoch: 4 [63488/319902 (20%)] Loss: 0.035127, 1 batch cost time 0.51
Train Epoch: 4 [64000/319902 (20%)] Loss: 0.035208, 1 batch cost time 0.51
Train Epoch: 4 [64512/319902 (20%)] Loss: 0.036584, 1 batch cost time 0.51
Train Epoch: 4 [65024/319902 (20%)] Loss: 0.032077, 1 batch cost time 0.51
Train Epoch: 4 [65536/319902 (20%)] Loss: 0.056495, 1 batch cost time 0.51
Train Epoch: 4 [66048/319902 (21%)] Loss: 0.031513, 1 batch cost time 0.51
Train Epoch: 4 [66560/319902 (21%)] Loss: 0.016277, 1 batch cost time 0.51
Train Epoch: 4 [67072/319902 (21%)] Loss: 0.036089, 1 batch cost time 0.51
Train Epoch: 4 [67584/319902 (21%)] Loss: 0.025567, 1 batch cost time 0.51
Train Epoch: 4 [68096/319902 (21%)] Loss: 0.059632, 1 batch cost time 0.51
Train Epoch: 4 [68608/319902 (21%)] Loss: 0.018549, 1 batch cost time 0.51
Train Epoch: 4 [69120/319902 (22%)] Loss: 0.047315, 1 batch cost time 0.51
Train Epoch: 4 [69632/319902 (22%)] Loss: 0.043582, 1 batch cost time 0.51
Train Epoch: 4 [70144/319902 (22%)] Loss: 0.037431, 1 batch cost time 0.51
Train Epoch: 4 [70656/319902 (22%)] Loss: 0.047829, 1 batch cost time 0.51
Train Epoch: 4 [71168/319902 (22%)] Loss: 0.034004, 1 batch cost time 0.51
Train Epoch: 4 [71680/319902 (22%)] Loss: 0.033101, 1 batch cost time 0.51
Train Epoch: 4 [72192/319902 (23%)] Loss: 0.043978, 1 batch cost time 0.51
Train Epoch: 4 [72704/319902 (23%)] Loss: 0.035629, 1 batch cost time 0.51
Train Epoch: 4 [73216/319902 (23%)] Loss: 0.012148, 1 batch cost time 0.51
Train Epoch: 4 [73728/319902 (23%)] Loss: 0.024170, 1 batch cost time 0.51
Train Epoch: 4 [74240/319902 (23%)] Loss: 0.017473, 1 batch cost time 0.51
Train Epoch: 4 [74752/319902 (23%)] Loss: 0.019900, 1 batch cost time 0.51
Train Epoch: 4 [75264/319902 (24%)] Loss: 0.026209, 1 batch cost time 0.51
Train Epoch: 4 [75776/319902 (24%)] Loss: 0.024985, 1 batch cost time 0.51
Train Epoch: 4 [76288/319902 (24%)] Loss: 0.039488, 1 batch cost time 0.51
Train Epoch: 4 [76800/319902 (24%)] Loss: 0.046474, 1 batch cost time 0.51
Train Epoch: 4 [77312/319902 (24%)] Loss: 0.053574, 1 batch cost time 0.51
Train Epoch: 4 [77824/319902 (24%)] Loss: 0.025162, 1 batch cost time 0.51
Train Epoch: 4 [78336/319902 (24%)] Loss: 0.022947, 1 batch cost time 0.51
Train Epoch: 4 [78848/319902 (25%)] Loss: 0.020459, 1 batch cost time 0.51
Train Epoch: 4 [79360/319902 (25%)] Loss: 0.035332, 1 batch cost time 0.51
Train Epoch: 4 [79872/319902 (25%)] Loss: 0.030814, 1 batch cost time 0.51
Train Epoch: 4 [80384/319902 (25%)] Loss: 0.036447, 1 batch cost time 0.51
Train Epoch: 4 [80896/319902 (25%)] Loss: 0.039557, 1 batch cost time 0.51
Train Epoch: 4 [81408/319902 (25%)] Loss: 0.039136, 1 batch cost time 0.51
Train Epoch: 4 [81920/319902 (26%)] Loss: 0.043938, 1 batch cost time 0.51
Train Epoch: 4 [82432/319902 (26%)] Loss: 0.024998, 1 batch cost time 0.51
Train Epoch: 4 [82944/319902 (26%)] Loss: 0.011657, 1 batch cost time 0.51
Train Epoch: 4 [83456/319902 (26%)] Loss: 0.050041, 1 batch cost time 0.51
Train Epoch: 4 [83968/319902 (26%)] Loss: 0.054402, 1 batch cost time 0.51
Train Epoch: 4 [84480/319902 (26%)] Loss: 0.019500, 1 batch cost time 0.51
Train Epoch: 4 [84992/319902 (27%)] Loss: 0.026316, 1 batch cost time 0.51
Train Epoch: 4 [85504/319902 (27%)] Loss: 0.040855, 1 batch cost time 0.51
Train Epoch: 4 [86016/319902 (27%)] Loss: 0.012945, 1 batch cost time 0.51
Train Epoch: 4 [86528/319902 (27%)] Loss: 0.048805, 1 batch cost time 0.51
Train Epoch: 4 [87040/319902 (27%)] Loss: 0.026647, 1 batch cost time 0.51
Train Epoch: 4 [87552/319902 (27%)] Loss: 0.012299, 1 batch cost time 0.51
Train Epoch: 4 [88064/319902 (28%)] Loss: 0.038515, 1 batch cost time 0.51
Train Epoch: 4 [88576/319902 (28%)] Loss: 0.011669, 1 batch cost time 0.51
Train Epoch: 4 [89088/319902 (28%)] Loss: 0.024347, 1 batch cost time 0.51
Train Epoch: 4 [89600/319902 (28%)] Loss: 0.059114, 1 batch cost time 0.51
Train Epoch: 4 [90112/319902 (28%)] Loss: 0.028459, 1 batch cost time 0.51
Train Epoch: 4 [90624/319902 (28%)] Loss: 0.023612, 1 batch cost time 0.51
Train Epoch: 4 [91136/319902 (28%)] Loss: 0.029931, 1 batch cost time 0.51
Train Epoch: 4 [91648/319902 (29%)] Loss: 0.022542, 1 batch cost time 0.51
Train Epoch: 4 [92160/319902 (29%)] Loss: 0.022514, 1 batch cost time 0.51
Train Epoch: 4 [92672/319902 (29%)] Loss: 0.029718, 1 batch cost time 0.51
Train Epoch: 4 [93184/319902 (29%)] Loss: 0.039585, 1 batch cost time 0.51
Train Epoch: 4 [93696/319902 (29%)] Loss: 0.030784, 1 batch cost time 0.51
Train Epoch: 4 [94208/319902 (29%)] Loss: 0.044875, 1 batch cost time 0.51
Train Epoch: 4 [94720/319902 (30%)] Loss: 0.026376, 1 batch cost time 0.51
Train Epoch: 4 [95232/319902 (30%)] Loss: 0.032914, 1 batch cost time 0.51
Train Epoch: 4 [95744/319902 (30%)] Loss: 0.027018, 1 batch cost time 0.51
Train Epoch: 4 [96256/319902 (30%)] Loss: 0.060260, 1 batch cost time 0.51
Train Epoch: 4 [96768/319902 (30%)] Loss: 0.031142, 1 batch cost time 0.51
Train Epoch: 4 [97280/319902 (30%)] Loss: 0.081607, 1 batch cost time 0.51
Train Epoch: 4 [97792/319902 (31%)] Loss: 0.029417, 1 batch cost time 0.51
Train Epoch: 4 [98304/319902 (31%)] Loss: 0.066798, 1 batch cost time 0.51
Train Epoch: 4 [98816/319902 (31%)] Loss: 0.014735, 1 batch cost time 0.51
Train Epoch: 4 [99328/319902 (31%)] Loss: 0.029514, 1 batch cost time 0.51
Train Epoch: 4 [99840/319902 (31%)] Loss: 0.069556, 1 batch cost time 0.51
Train Epoch: 4 [100352/319902 (31%)] Loss: 0.042712, 1 batch cost time 0.51
Train Epoch: 4 [100864/319902 (32%)] Loss: 0.016071, 1 batch cost time 0.51
Train Epoch: 4 [101376/319902 (32%)] Loss: 0.040831, 1 batch cost time 0.51
Train Epoch: 4 [101888/319902 (32%)] Loss: 0.039356, 1 batch cost time 0.51
Train Epoch: 4 [102400/319902 (32%)] Loss: 0.038844, 1 batch cost time 0.51
Train Epoch: 4 [102912/319902 (32%)] Loss: 0.041075, 1 batch cost time 0.51
Train Epoch: 4 [103424/319902 (32%)] Loss: 0.045090, 1 batch cost time 0.51
Train Epoch: 4 [103936/319902 (32%)] Loss: 0.034081, 1 batch cost time 0.51
Train Epoch: 4 [104448/319902 (33%)] Loss: 0.051792, 1 batch cost time 0.51
Train Epoch: 4 [104960/319902 (33%)] Loss: 0.023207, 1 batch cost time 0.51
Train Epoch: 4 [105472/319902 (33%)] Loss: 0.032289, 1 batch cost time 0.51
Train Epoch: 4 [105984/319902 (33%)] Loss: 0.030888, 1 batch cost time 0.51
Train Epoch: 4 [106496/319902 (33%)] Loss: 0.030658, 1 batch cost time 0.51
Train Epoch: 4 [107008/319902 (33%)] Loss: 0.060466, 1 batch cost time 0.51
Train Epoch: 4 [107520/319902 (34%)] Loss: 0.066624, 1 batch cost time 0.51
Train Epoch: 4 [108032/319902 (34%)] Loss: 0.044662, 1 batch cost time 0.51
Train Epoch: 4 [108544/319902 (34%)] Loss: 0.028430, 1 batch cost time 0.51
Train Epoch: 4 [109056/319902 (34%)] Loss: 0.025152, 1 batch cost time 0.51
Train Epoch: 4 [109568/319902 (34%)] Loss: 0.024372, 1 batch cost time 0.51
Train Epoch: 4 [110080/319902 (34%)] Loss: 0.017450, 1 batch cost time 0.51
Train Epoch: 4 [110592/319902 (35%)] Loss: 0.036737, 1 batch cost time 0.51
Train Epoch: 4 [111104/319902 (35%)] Loss: 0.061584, 1 batch cost time 0.51
Train Epoch: 4 [111616/319902 (35%)] Loss: 0.029299, 1 batch cost time 0.51
Train Epoch: 4 [112128/319902 (35%)] Loss: 0.042410, 1 batch cost time 0.51
Train Epoch: 4 [112640/319902 (35%)] Loss: 0.033268, 1 batch cost time 0.51
Train Epoch: 4 [113152/319902 (35%)] Loss: 0.039702, 1 batch cost time 0.51
Train Epoch: 4 [113664/319902 (36%)] Loss: 0.049036, 1 batch cost time 0.51
Train Epoch: 4 [114176/319902 (36%)] Loss: 0.024663, 1 batch cost time 0.51
Train Epoch: 4 [114688/319902 (36%)] Loss: 0.024592, 1 batch cost time 0.51
Train Epoch: 4 [115200/319902 (36%)] Loss: 0.037322, 1 batch cost time 0.51
Train Epoch: 4 [115712/319902 (36%)] Loss: 0.012932, 1 batch cost time 0.51
Train Epoch: 4 [116224/319902 (36%)] Loss: 0.050127, 1 batch cost time 0.51
Train Epoch: 4 [116736/319902 (36%)] Loss: 0.035504, 1 batch cost time 0.51
Train Epoch: 4 [117248/319902 (37%)] Loss: 0.066478, 1 batch cost time 0.51
Train Epoch: 4 [117760/319902 (37%)] Loss: 0.012022, 1 batch cost time 0.51
Train Epoch: 4 [118272/319902 (37%)] Loss: 0.042428, 1 batch cost time 0.51
Train Epoch: 4 [118784/319902 (37%)] Loss: 0.022653, 1 batch cost time 0.51
Train Epoch: 4 [119296/319902 (37%)] Loss: 0.053469, 1 batch cost time 0.51
Train Epoch: 4 [119808/319902 (37%)] Loss: 0.030210, 1 batch cost time 0.51
Train Epoch: 4 [120320/319902 (38%)] Loss: 0.032339, 1 batch cost time 0.51
Train Epoch: 4 [120832/319902 (38%)] Loss: 0.041457, 1 batch cost time 0.51
Train Epoch: 4 [121344/319902 (38%)] Loss: 0.038961, 1 batch cost time 0.51
Train Epoch: 4 [121856/319902 (38%)] Loss: 0.029053, 1 batch cost time 0.51
Train Epoch: 4 [122368/319902 (38%)] Loss: 0.046198, 1 batch cost time 0.51
Train Epoch: 4 [122880/319902 (38%)] Loss: 0.050338, 1 batch cost time 0.51
Train Epoch: 4 [123392/319902 (39%)] Loss: 0.035659, 1 batch cost time 0.51
Train Epoch: 4 [123904/319902 (39%)] Loss: 0.019370, 1 batch cost time 0.51
Train Epoch: 4 [124416/319902 (39%)] Loss: 0.032710, 1 batch cost time 0.51
Train Epoch: 4 [124928/319902 (39%)] Loss: 0.044621, 1 batch cost time 0.51
Train Epoch: 4 [125440/319902 (39%)] Loss: 0.037459, 1 batch cost time 0.51
Train Epoch: 4 [125952/319902 (39%)] Loss: 0.038072, 1 batch cost time 0.51
Train Epoch: 4 [126464/319902 (40%)] Loss: 0.021042, 1 batch cost time 0.51
Train Epoch: 4 [126976/319902 (40%)] Loss: 0.030836, 1 batch cost time 0.51
Train Epoch: 4 [127488/319902 (40%)] Loss: 0.025039, 1 batch cost time 0.51
Train Epoch: 4 [128000/319902 (40%)] Loss: 0.055925, 1 batch cost time 0.51
Train Epoch: 4 [128512/319902 (40%)] Loss: 0.025555, 1 batch cost time 0.51
Train Epoch: 4 [129024/319902 (40%)] Loss: 0.008977, 1 batch cost time 0.51
Train Epoch: 4 [129536/319902 (40%)] Loss: 0.023380, 1 batch cost time 0.51
Train Epoch: 4 [130048/319902 (41%)] Loss: 0.023275, 1 batch cost time 0.51
Train Epoch: 4 [130560/319902 (41%)] Loss: 0.021290, 1 batch cost time 0.51
Train Epoch: 4 [131072/319902 (41%)] Loss: 0.039992, 1 batch cost time 0.51
Train Epoch: 4 [131584/319902 (41%)] Loss: 0.050839, 1 batch cost time 0.51
Train Epoch: 4 [132096/319902 (41%)] Loss: 0.025173, 1 batch cost time 0.51
Train Epoch: 4 [132608/319902 (41%)] Loss: 0.013368, 1 batch cost time 0.51
Train Epoch: 4 [133120/319902 (42%)] Loss: 0.050095, 1 batch cost time 0.51
Train Epoch: 4 [133632/319902 (42%)] Loss: 0.021822, 1 batch cost time 0.51
Train Epoch: 4 [134144/319902 (42%)] Loss: 0.051599, 1 batch cost time 0.51
Train Epoch: 4 [134656/319902 (42%)] Loss: 0.028268, 1 batch cost time 0.51
Train Epoch: 4 [135168/319902 (42%)] Loss: 0.041113, 1 batch cost time 0.51
Train Epoch: 4 [135680/319902 (42%)] Loss: 0.027589, 1 batch cost time 0.51
Train Epoch: 4 [136192/319902 (43%)] Loss: 0.030309, 1 batch cost time 0.51
Train Epoch: 4 [136704/319902 (43%)] Loss: 0.054613, 1 batch cost time 0.51
Train Epoch: 4 [137216/319902 (43%)] Loss: 0.024674, 1 batch cost time 0.51
Train Epoch: 4 [137728/319902 (43%)] Loss: 0.023645, 1 batch cost time 0.51
Train Epoch: 4 [138240/319902 (43%)] Loss: 0.020655, 1 batch cost time 0.51
Train Epoch: 4 [138752/319902 (43%)] Loss: 0.048941, 1 batch cost time 0.51
Train Epoch: 4 [139264/319902 (44%)] Loss: 0.050230, 1 batch cost time 0.51
Train Epoch: 4 [139776/319902 (44%)] Loss: 0.031642, 1 batch cost time 0.51
Train Epoch: 4 [140288/319902 (44%)] Loss: 0.024646, 1 batch cost time 0.51
Train Epoch: 4 [140800/319902 (44%)] Loss: 0.031588, 1 batch cost time 0.51
Train Epoch: 4 [141312/319902 (44%)] Loss: 0.019626, 1 batch cost time 0.51
Train Epoch: 4 [141824/319902 (44%)] Loss: 0.016986, 1 batch cost time 0.51
Train Epoch: 4 [142336/319902 (44%)] Loss: 0.021205, 1 batch cost time 0.51
Train Epoch: 4 [142848/319902 (45%)] Loss: 0.046966, 1 batch cost time 0.51
Train Epoch: 4 [143360/319902 (45%)] Loss: 0.016802, 1 batch cost time 0.51
Train Epoch: 4 [143872/319902 (45%)] Loss: 0.025576, 1 batch cost time 0.51
Train Epoch: 4 [144384/319902 (45%)] Loss: 0.020910, 1 batch cost time 0.51
Train Epoch: 4 [144896/319902 (45%)] Loss: 0.034052, 1 batch cost time 0.51
Train Epoch: 4 [145408/319902 (45%)] Loss: 0.024732, 1 batch cost time 0.51
Train Epoch: 4 [145920/319902 (46%)] Loss: 0.026819, 1 batch cost time 0.51
Train Epoch: 4 [146432/319902 (46%)] Loss: 0.008643, 1 batch cost time 0.51
Train Epoch: 4 [146944/319902 (46%)] Loss: 0.047943, 1 batch cost time 0.51
Train Epoch: 4 [147456/319902 (46%)] Loss: 0.013364, 1 batch cost time 0.51
Train Epoch: 4 [147968/319902 (46%)] Loss: 0.031620, 1 batch cost time 0.51
Train Epoch: 4 [148480/319902 (46%)] Loss: 0.028723, 1 batch cost time 0.51
Train Epoch: 4 [148992/319902 (47%)] Loss: 0.039137, 1 batch cost time 0.51
Train Epoch: 4 [149504/319902 (47%)] Loss: 0.039428, 1 batch cost time 0.51
Train Epoch: 4 [150016/319902 (47%)] Loss: 0.033767, 1 batch cost time 0.51
Train Epoch: 4 [150528/319902 (47%)] Loss: 0.013840, 1 batch cost time 0.51
Train Epoch: 4 [151040/319902 (47%)] Loss: 0.047893, 1 batch cost time 0.51
Train Epoch: 4 [151552/319902 (47%)] Loss: 0.030028, 1 batch cost time 0.51
Train Epoch: 4 [152064/319902 (48%)] Loss: 0.043208, 1 batch cost time 0.51
Train Epoch: 4 [152576/319902 (48%)] Loss: 0.028571, 1 batch cost time 0.51
Train Epoch: 4 [153088/319902 (48%)] Loss: 0.038218, 1 batch cost time 0.51
Train Epoch: 4 [153600/319902 (48%)] Loss: 0.041992, 1 batch cost time 0.51
Train Epoch: 4 [154112/319902 (48%)] Loss: 0.056477, 1 batch cost time 0.51
Train Epoch: 4 [154624/319902 (48%)] Loss: 0.023446, 1 batch cost time 0.51
Train Epoch: 4 [155136/319902 (48%)] Loss: 0.019854, 1 batch cost time 0.51
Train Epoch: 4 [155648/319902 (49%)] Loss: 0.056722, 1 batch cost time 0.51
Train Epoch: 4 [156160/319902 (49%)] Loss: 0.032312, 1 batch cost time 0.51
Train Epoch: 4 [156672/319902 (49%)] Loss: 0.044706, 1 batch cost time 0.51
Train Epoch: 4 [157184/319902 (49%)] Loss: 0.033143, 1 batch cost time 0.51
Train Epoch: 4 [157696/319902 (49%)] Loss: 0.040019, 1 batch cost time 0.51
Train Epoch: 4 [158208/319902 (49%)] Loss: 0.041821, 1 batch cost time 0.51
Train Epoch: 4 [158720/319902 (50%)] Loss: 0.017686, 1 batch cost time 0.51
Train Epoch: 4 [159232/319902 (50%)] Loss: 0.043794, 1 batch cost time 0.51
Train Epoch: 4 [159744/319902 (50%)] Loss: 0.045069, 1 batch cost time 0.51
Train Epoch: 4 [160256/319902 (50%)] Loss: 0.029035, 1 batch cost time 0.51
Train Epoch: 4 [160768/319902 (50%)] Loss: 0.034251, 1 batch cost time 0.51
Train Epoch: 4 [161280/319902 (50%)] Loss: 0.071192, 1 batch cost time 0.51
Train Epoch: 4 [161792/319902 (51%)] Loss: 0.032850, 1 batch cost time 0.51
Train Epoch: 4 [162304/319902 (51%)] Loss: 0.018075, 1 batch cost time 0.51
Train Epoch: 4 [162816/319902 (51%)] Loss: 0.017770, 1 batch cost time 0.51
Train Epoch: 4 [163328/319902 (51%)] Loss: 0.080272, 1 batch cost time 0.51
Train Epoch: 4 [163840/319902 (51%)] Loss: 0.024615, 1 batch cost time 0.51
Train Epoch: 4 [164352/319902 (51%)] Loss: 0.040663, 1 batch cost time 0.51
Train Epoch: 4 [164864/319902 (52%)] Loss: 0.018800, 1 batch cost time 0.51
Train Epoch: 4 [165376/319902 (52%)] Loss: 0.075260, 1 batch cost time 0.51
Train Epoch: 4 [165888/319902 (52%)] Loss: 0.018520, 1 batch cost time 0.51
Train Epoch: 4 [166400/319902 (52%)] Loss: 0.011166, 1 batch cost time 0.51
Train Epoch: 4 [166912/319902 (52%)] Loss: 0.028834, 1 batch cost time 0.51
Train Epoch: 4 [167424/319902 (52%)] Loss: 0.030098, 1 batch cost time 0.51
Train Epoch: 4 [167936/319902 (52%)] Loss: 0.045556, 1 batch cost time 0.51
Train Epoch: 4 [168448/319902 (53%)] Loss: 0.075089, 1 batch cost time 0.51
Train Epoch: 4 [168960/319902 (53%)] Loss: 0.037087, 1 batch cost time 0.51
Train Epoch: 4 [169472/319902 (53%)] Loss: 0.034456, 1 batch cost time 0.51
Train Epoch: 4 [169984/319902 (53%)] Loss: 0.049891, 1 batch cost time 0.51
Train Epoch: 4 [170496/319902 (53%)] Loss: 0.027112, 1 batch cost time 0.51
Train Epoch: 4 [171008/319902 (53%)] Loss: 0.028488, 1 batch cost time 0.51
Train Epoch: 4 [171520/319902 (54%)] Loss: 0.021494, 1 batch cost time 0.51
Train Epoch: 4 [172032/319902 (54%)] Loss: 0.033797, 1 batch cost time 0.51
Train Epoch: 4 [172544/319902 (54%)] Loss: 0.016068, 1 batch cost time 0.51
Train Epoch: 4 [173056/319902 (54%)] Loss: 0.037163, 1 batch cost time 0.51
Train Epoch: 4 [173568/319902 (54%)] Loss: 0.014550, 1 batch cost time 0.51
Train Epoch: 4 [174080/319902 (54%)] Loss: 0.027277, 1 batch cost time 0.51
Train Epoch: 4 [174592/319902 (55%)] Loss: 0.047500, 1 batch cost time 0.51
Train Epoch: 4 [175104/319902 (55%)] Loss: 0.036902, 1 batch cost time 0.51
Train Epoch: 4 [175616/319902 (55%)] Loss: 0.022542, 1 batch cost time 0.51
Train Epoch: 4 [176128/319902 (55%)] Loss: 0.011449, 1 batch cost time 0.51
Train Epoch: 4 [176640/319902 (55%)] Loss: 0.041428, 1 batch cost time 0.51
Train Epoch: 4 [177152/319902 (55%)] Loss: 0.052263, 1 batch cost time 0.51
Train Epoch: 4 [177664/319902 (56%)] Loss: 0.031656, 1 batch cost time 0.51
Train Epoch: 4 [178176/319902 (56%)] Loss: 0.025355, 1 batch cost time 0.51
Train Epoch: 4 [178688/319902 (56%)] Loss: 0.052084, 1 batch cost time 0.51
Train Epoch: 4 [179200/319902 (56%)] Loss: 0.041463, 1 batch cost time 0.51
Train Epoch: 4 [179712/319902 (56%)] Loss: 0.100390, 1 batch cost time 0.51
Train Epoch: 4 [180224/319902 (56%)] Loss: 0.013292, 1 batch cost time 0.51
Train Epoch: 4 [180736/319902 (56%)] Loss: 0.034816, 1 batch cost time 0.51
Train Epoch: 4 [181248/319902 (57%)] Loss: 0.021481, 1 batch cost time 0.51
Train Epoch: 4 [181760/319902 (57%)] Loss: 0.017557, 1 batch cost time 0.51
Train Epoch: 4 [182272/319902 (57%)] Loss: 0.061633, 1 batch cost time 0.51
Train Epoch: 4 [182784/319902 (57%)] Loss: 0.038413, 1 batch cost time 0.51
Train Epoch: 4 [183296/319902 (57%)] Loss: 0.040623, 1 batch cost time 0.51
Train Epoch: 4 [183808/319902 (57%)] Loss: 0.033561, 1 batch cost time 0.51
Train Epoch: 4 [184320/319902 (58%)] Loss: 0.029856, 1 batch cost time 0.51
Train Epoch: 4 [184832/319902 (58%)] Loss: 0.039583, 1 batch cost time 0.51
Train Epoch: 4 [185344/319902 (58%)] Loss: 0.037012, 1 batch cost time 0.51
Train Epoch: 4 [185856/319902 (58%)] Loss: 0.032969, 1 batch cost time 0.51
Train Epoch: 4 [186368/319902 (58%)] Loss: 0.036852, 1 batch cost time 0.51
Train Epoch: 4 [186880/319902 (58%)] Loss: 0.012701, 1 batch cost time 0.51
Train Epoch: 4 [187392/319902 (59%)] Loss: 0.060078, 1 batch cost time 0.51
Train Epoch: 4 [187904/319902 (59%)] Loss: 0.024698, 1 batch cost time 0.51
Train Epoch: 4 [188416/319902 (59%)] Loss: 0.028178, 1 batch cost time 0.51
Train Epoch: 4 [188928/319902 (59%)] Loss: 0.012565, 1 batch cost time 0.51
Train Epoch: 4 [189440/319902 (59%)] Loss: 0.057938, 1 batch cost time 0.51
Train Epoch: 4 [189952/319902 (59%)] Loss: 0.021741, 1 batch cost time 0.51
Train Epoch: 4 [190464/319902 (60%)] Loss: 0.030866, 1 batch cost time 0.51
Train Epoch: 4 [190976/319902 (60%)] Loss: 0.061569, 1 batch cost time 0.51
Train Epoch: 4 [191488/319902 (60%)] Loss: 0.017903, 1 batch cost time 0.51
Train Epoch: 4 [192000/319902 (60%)] Loss: 0.029635, 1 batch cost time 0.51
Train Epoch: 4 [192512/319902 (60%)] Loss: 0.042168, 1 batch cost time 0.51
Train Epoch: 4 [193024/319902 (60%)] Loss: 0.041508, 1 batch cost time 0.51
Train Epoch: 4 [193536/319902 (60%)] Loss: 0.038050, 1 batch cost time 0.51
Train Epoch: 4 [194048/319902 (61%)] Loss: 0.039653, 1 batch cost time 0.51
Train Epoch: 4 [194560/319902 (61%)] Loss: 0.028542, 1 batch cost time 0.51
Train Epoch: 4 [195072/319902 (61%)] Loss: 0.018546, 1 batch cost time 0.51
Train Epoch: 4 [195584/319902 (61%)] Loss: 0.028647, 1 batch cost time 0.51
Train Epoch: 4 [196096/319902 (61%)] Loss: 0.048147, 1 batch cost time 0.51
Train Epoch: 4 [196608/319902 (61%)] Loss: 0.044880, 1 batch cost time 0.51
Train Epoch: 4 [197120/319902 (62%)] Loss: 0.039226, 1 batch cost time 0.51
Train Epoch: 4 [197632/319902 (62%)] Loss: 0.011138, 1 batch cost time 0.51
Train Epoch: 4 [198144/319902 (62%)] Loss: 0.021119, 1 batch cost time 0.51
Train Epoch: 4 [198656/319902 (62%)] Loss: 0.016841, 1 batch cost time 0.51
Train Epoch: 4 [199168/319902 (62%)] Loss: 0.015157, 1 batch cost time 0.51
Train Epoch: 4 [199680/319902 (62%)] Loss: 0.011721, 1 batch cost time 0.51
Train Epoch: 4 [200192/319902 (63%)] Loss: 0.020630, 1 batch cost time 0.51
Train Epoch: 4 [200704/319902 (63%)] Loss: 0.024913, 1 batch cost time 0.51
Train Epoch: 4 [201216/319902 (63%)] Loss: 0.018080, 1 batch cost time 0.51
Train Epoch: 4 [201728/319902 (63%)] Loss: 0.038842, 1 batch cost time 0.51
Train Epoch: 4 [202240/319902 (63%)] Loss: 0.051240, 1 batch cost time 0.51
Train Epoch: 4 [202752/319902 (63%)] Loss: 0.018884, 1 batch cost time 0.51
Train Epoch: 4 [203264/319902 (64%)] Loss: 0.048272, 1 batch cost time 0.51
Train Epoch: 4 [203776/319902 (64%)] Loss: 0.043839, 1 batch cost time 0.51
Train Epoch: 4 [204288/319902 (64%)] Loss: 0.036976, 1 batch cost time 0.51
Train Epoch: 4 [204800/319902 (64%)] Loss: 0.030337, 1 batch cost time 0.51
Train Epoch: 4 [205312/319902 (64%)] Loss: 0.060334, 1 batch cost time 0.51
Train Epoch: 4 [205824/319902 (64%)] Loss: 0.033478, 1 batch cost time 0.51
Train Epoch: 4 [206336/319902 (64%)] Loss: 0.032016, 1 batch cost time 0.51
Train Epoch: 4 [206848/319902 (65%)] Loss: 0.025894, 1 batch cost time 0.51
Train Epoch: 4 [207360/319902 (65%)] Loss: 0.032521, 1 batch cost time 0.51
Train Epoch: 4 [207872/319902 (65%)] Loss: 0.050574, 1 batch cost time 0.51
Train Epoch: 4 [208384/319902 (65%)] Loss: 0.032572, 1 batch cost time 0.51
Train Epoch: 4 [208896/319902 (65%)] Loss: 0.015433, 1 batch cost time 0.51
Train Epoch: 4 [209408/319902 (65%)] Loss: 0.058441, 1 batch cost time 0.51
Train Epoch: 4 [209920/319902 (66%)] Loss: 0.037658, 1 batch cost time 0.51
Train Epoch: 4 [210432/319902 (66%)] Loss: 0.025771, 1 batch cost time 0.51
Train Epoch: 4 [210944/319902 (66%)] Loss: 0.018578, 1 batch cost time 0.51
Train Epoch: 4 [211456/319902 (66%)] Loss: 0.007595, 1 batch cost time 0.51
Train Epoch: 4 [211968/319902 (66%)] Loss: 0.053144, 1 batch cost time 0.51
Train Epoch: 4 [212480/319902 (66%)] Loss: 0.041414, 1 batch cost time 0.51
Train Epoch: 4 [212992/319902 (67%)] Loss: 0.044758, 1 batch cost time 0.51
Train Epoch: 4 [213504/319902 (67%)] Loss: 0.041906, 1 batch cost time 0.51
Train Epoch: 4 [214016/319902 (67%)] Loss: 0.036629, 1 batch cost time 0.51
Train Epoch: 4 [214528/319902 (67%)] Loss: 0.030759, 1 batch cost time 0.51
Train Epoch: 4 [215040/319902 (67%)] Loss: 0.044025, 1 batch cost time 0.51
Train Epoch: 4 [215552/319902 (67%)] Loss: 0.014163, 1 batch cost time 0.51
Train Epoch: 4 [216064/319902 (68%)] Loss: 0.033200, 1 batch cost time 0.51
Train Epoch: 4 [216576/319902 (68%)] Loss: 0.043375, 1 batch cost time 0.51
Train Epoch: 4 [217088/319902 (68%)] Loss: 0.023792, 1 batch cost time 0.51
Train Epoch: 4 [217600/319902 (68%)] Loss: 0.027474, 1 batch cost time 0.51
Train Epoch: 4 [218112/319902 (68%)] Loss: 0.020541, 1 batch cost time 0.51
Train Epoch: 4 [218624/319902 (68%)] Loss: 0.017310, 1 batch cost time 0.51
Train Epoch: 4 [219136/319902 (69%)] Loss: 0.018037, 1 batch cost time 0.51
Train Epoch: 4 [219648/319902 (69%)] Loss: 0.014630, 1 batch cost time 0.51
Train Epoch: 4 [220160/319902 (69%)] Loss: 0.026647, 1 batch cost time 0.51
Train Epoch: 4 [220672/319902 (69%)] Loss: 0.032121, 1 batch cost time 0.51
Train Epoch: 4 [221184/319902 (69%)] Loss: 0.035689, 1 batch cost time 0.51
Train Epoch: 4 [221696/319902 (69%)] Loss: 0.027918, 1 batch cost time 0.51
Train Epoch: 4 [222208/319902 (69%)] Loss: 0.016904, 1 batch cost time 0.51
Train Epoch: 4 [222720/319902 (70%)] Loss: 0.024724, 1 batch cost time 0.51
Train Epoch: 4 [223232/319902 (70%)] Loss: 0.030916, 1 batch cost time 0.51
Train Epoch: 4 [223744/319902 (70%)] Loss: 0.025641, 1 batch cost time 0.51
Train Epoch: 4 [224256/319902 (70%)] Loss: 0.027965, 1 batch cost time 0.51
Train Epoch: 4 [224768/319902 (70%)] Loss: 0.017978, 1 batch cost time 0.51
Train Epoch: 4 [225280/319902 (70%)] Loss: 0.029251, 1 batch cost time 0.51
Train Epoch: 4 [225792/319902 (71%)] Loss: 0.032911, 1 batch cost time 0.51
Train Epoch: 4 [226304/319902 (71%)] Loss: 0.033551, 1 batch cost time 0.51
Train Epoch: 4 [226816/319902 (71%)] Loss: 0.039319, 1 batch cost time 0.51
Train Epoch: 4 [227328/319902 (71%)] Loss: 0.016836, 1 batch cost time 0.51
Train Epoch: 4 [227840/319902 (71%)] Loss: 0.013831, 1 batch cost time 0.51
Train Epoch: 4 [228352/319902 (71%)] Loss: 0.028326, 1 batch cost time 0.51
Train Epoch: 4 [228864/319902 (72%)] Loss: 0.037241, 1 batch cost time 0.51
Train Epoch: 4 [229376/319902 (72%)] Loss: 0.041137, 1 batch cost time 0.51
Train Epoch: 4 [229888/319902 (72%)] Loss: 0.027317, 1 batch cost time 0.51
Train Epoch: 4 [230400/319902 (72%)] Loss: 0.034506, 1 batch cost time 0.51
Train Epoch: 4 [230912/319902 (72%)] Loss: 0.021077, 1 batch cost time 0.51
Train Epoch: 4 [231424/319902 (72%)] Loss: 0.025380, 1 batch cost time 0.51
Train Epoch: 4 [231936/319902 (73%)] Loss: 0.018693, 1 batch cost time 0.51
Train Epoch: 4 [232448/319902 (73%)] Loss: 0.014837, 1 batch cost time 0.51
Train Epoch: 4 [232960/319902 (73%)] Loss: 0.047576, 1 batch cost time 0.51
Train Epoch: 4 [233472/319902 (73%)] Loss: 0.018004, 1 batch cost time 0.51
Train Epoch: 4 [233984/319902 (73%)] Loss: 0.037492, 1 batch cost time 0.51
Train Epoch: 4 [234496/319902 (73%)] Loss: 0.044632, 1 batch cost time 0.51
Train Epoch: 4 [235008/319902 (73%)] Loss: 0.028303, 1 batch cost time 0.51
Train Epoch: 4 [235520/319902 (74%)] Loss: 0.022364, 1 batch cost time 0.51
Train Epoch: 4 [236032/319902 (74%)] Loss: 0.010913, 1 batch cost time 0.51
Train Epoch: 4 [236544/319902 (74%)] Loss: 0.035303, 1 batch cost time 0.51
Train Epoch: 4 [237056/319902 (74%)] Loss: 0.025008, 1 batch cost time 0.51
Train Epoch: 4 [237568/319902 (74%)] Loss: 0.028937, 1 batch cost time 0.51
Train Epoch: 4 [238080/319902 (74%)] Loss: 0.050798, 1 batch cost time 0.51
Train Epoch: 4 [238592/319902 (75%)] Loss: 0.042072, 1 batch cost time 0.51
Train Epoch: 4 [239104/319902 (75%)] Loss: 0.021232, 1 batch cost time 0.51
Train Epoch: 4 [239616/319902 (75%)] Loss: 0.027862, 1 batch cost time 0.51
Train Epoch: 4 [240128/319902 (75%)] Loss: 0.021306, 1 batch cost time 0.51
Train Epoch: 4 [240640/319902 (75%)] Loss: 0.030722, 1 batch cost time 0.51
Train Epoch: 4 [241152/319902 (75%)] Loss: 0.043871, 1 batch cost time 0.51
Train Epoch: 4 [241664/319902 (76%)] Loss: 0.046986, 1 batch cost time 0.51
Train Epoch: 4 [242176/319902 (76%)] Loss: 0.034193, 1 batch cost time 0.51
Train Epoch: 4 [242688/319902 (76%)] Loss: 0.035095, 1 batch cost time 0.51
Train Epoch: 4 [243200/319902 (76%)] Loss: 0.058167, 1 batch cost time 0.51
Train Epoch: 4 [243712/319902 (76%)] Loss: 0.036381, 1 batch cost time 0.51
Train Epoch: 4 [244224/319902 (76%)] Loss: 0.030958, 1 batch cost time 0.51
Train Epoch: 4 [244736/319902 (77%)] Loss: 0.085790, 1 batch cost time 0.51
Train Epoch: 4 [245248/319902 (77%)] Loss: 0.051222, 1 batch cost time 0.51
Train Epoch: 4 [245760/319902 (77%)] Loss: 0.035812, 1 batch cost time 0.51
Train Epoch: 4 [246272/319902 (77%)] Loss: 0.032790, 1 batch cost time 0.51
Train Epoch: 4 [246784/319902 (77%)] Loss: 0.023063, 1 batch cost time 0.51
Train Epoch: 4 [247296/319902 (77%)] Loss: 0.012028, 1 batch cost time 0.51
Train Epoch: 4 [247808/319902 (77%)] Loss: 0.038543, 1 batch cost time 0.51
Train Epoch: 4 [248320/319902 (78%)] Loss: 0.023723, 1 batch cost time 0.51
Train Epoch: 4 [248832/319902 (78%)] Loss: 0.018402, 1 batch cost time 0.51
Train Epoch: 4 [249344/319902 (78%)] Loss: 0.042104, 1 batch cost time 0.51
Train Epoch: 4 [249856/319902 (78%)] Loss: 0.037393, 1 batch cost time 0.51
Train Epoch: 4 [250368/319902 (78%)] Loss: 0.015323, 1 batch cost time 0.51
Train Epoch: 4 [250880/319902 (78%)] Loss: 0.044673, 1 batch cost time 0.51
Train Epoch: 4 [251392/319902 (79%)] Loss: 0.026787, 1 batch cost time 0.51
Train Epoch: 4 [251904/319902 (79%)] Loss: 0.027346, 1 batch cost time 0.51
Train Epoch: 4 [252416/319902 (79%)] Loss: 0.016904, 1 batch cost time 0.51
Train Epoch: 4 [252928/319902 (79%)] Loss: 0.040977, 1 batch cost time 0.51
Train Epoch: 4 [253440/319902 (79%)] Loss: 0.015340, 1 batch cost time 0.51
Train Epoch: 4 [253952/319902 (79%)] Loss: 0.033993, 1 batch cost time 0.51
Train Epoch: 4 [254464/319902 (80%)] Loss: 0.044763, 1 batch cost time 0.51
Train Epoch: 4 [254976/319902 (80%)] Loss: 0.024050, 1 batch cost time 0.51
Train Epoch: 4 [255488/319902 (80%)] Loss: 0.050455, 1 batch cost time 0.51
Train Epoch: 4 [256000/319902 (80%)] Loss: 0.014531, 1 batch cost time 0.51
Train Epoch: 4 [256512/319902 (80%)] Loss: 0.041086, 1 batch cost time 0.51
Train Epoch: 4 [257024/319902 (80%)] Loss: 0.023169, 1 batch cost time 0.51
Train Epoch: 4 [257536/319902 (81%)] Loss: 0.026998, 1 batch cost time 0.51
Train Epoch: 4 [258048/319902 (81%)] Loss: 0.026766, 1 batch cost time 0.51
Train Epoch: 4 [258560/319902 (81%)] Loss: 0.026702, 1 batch cost time 0.51
Train Epoch: 4 [259072/319902 (81%)] Loss: 0.017564, 1 batch cost time 0.51
Train Epoch: 4 [259584/319902 (81%)] Loss: 0.023403, 1 batch cost time 0.51
Train Epoch: 4 [260096/319902 (81%)] Loss: 0.033120, 1 batch cost time 0.51
Train Epoch: 4 [260608/319902 (81%)] Loss: 0.018336, 1 batch cost time 0.51
Train Epoch: 4 [261120/319902 (82%)] Loss: 0.039185, 1 batch cost time 0.51
Train Epoch: 4 [261632/319902 (82%)] Loss: 0.035652, 1 batch cost time 0.51
Train Epoch: 4 [262144/319902 (82%)] Loss: 0.016965, 1 batch cost time 0.51
Train Epoch: 4 [262656/319902 (82%)] Loss: 0.028903, 1 batch cost time 0.51
Train Epoch: 4 [263168/319902 (82%)] Loss: 0.020907, 1 batch cost time 0.51
Train Epoch: 4 [263680/319902 (82%)] Loss: 0.031717, 1 batch cost time 0.51
Train Epoch: 4 [264192/319902 (83%)] Loss: 0.052933, 1 batch cost time 0.51
Train Epoch: 4 [264704/319902 (83%)] Loss: 0.022604, 1 batch cost time 0.51
Train Epoch: 4 [265216/319902 (83%)] Loss: 0.020890, 1 batch cost time 0.51
Train Epoch: 4 [265728/319902 (83%)] Loss: 0.015121, 1 batch cost time 0.51
Train Epoch: 4 [266240/319902 (83%)] Loss: 0.019092, 1 batch cost time 0.51
Train Epoch: 4 [266752/319902 (83%)] Loss: 0.026110, 1 batch cost time 0.51
Train Epoch: 4 [267264/319902 (84%)] Loss: 0.021260, 1 batch cost time 0.51
Train Epoch: 4 [267776/319902 (84%)] Loss: 0.030270, 1 batch cost time 0.51
Train Epoch: 4 [268288/319902 (84%)] Loss: 0.010524, 1 batch cost time 0.51
Train Epoch: 4 [268800/319902 (84%)] Loss: 0.030886, 1 batch cost time 0.51
Train Epoch: 4 [269312/319902 (84%)] Loss: 0.041025, 1 batch cost time 0.51
Train Epoch: 4 [269824/319902 (84%)] Loss: 0.069351, 1 batch cost time 0.51
Train Epoch: 4 [270336/319902 (85%)] Loss: 0.032487, 1 batch cost time 0.51
Train Epoch: 4 [270848/319902 (85%)] Loss: 0.050474, 1 batch cost time 0.51
Train Epoch: 4 [271360/319902 (85%)] Loss: 0.044776, 1 batch cost time 0.51
Train Epoch: 4 [271872/319902 (85%)] Loss: 0.027697, 1 batch cost time 0.51
Train Epoch: 4 [272384/319902 (85%)] Loss: 0.039851, 1 batch cost time 0.51
Train Epoch: 4 [272896/319902 (85%)] Loss: 0.017231, 1 batch cost time 0.51
Train Epoch: 4 [273408/319902 (85%)] Loss: 0.013910, 1 batch cost time 0.51
Train Epoch: 4 [273920/319902 (86%)] Loss: 0.033245, 1 batch cost time 0.51
Train Epoch: 4 [274432/319902 (86%)] Loss: 0.025958, 1 batch cost time 0.51
Train Epoch: 4 [274944/319902 (86%)] Loss: 0.031421, 1 batch cost time 0.51
Train Epoch: 4 [275456/319902 (86%)] Loss: 0.048931, 1 batch cost time 0.51
Train Epoch: 4 [275968/319902 (86%)] Loss: 0.019594, 1 batch cost time 0.51
Train Epoch: 4 [276480/319902 (86%)] Loss: 0.044727, 1 batch cost time 0.51
Train Epoch: 4 [276992/319902 (87%)] Loss: 0.019257, 1 batch cost time 0.51
Train Epoch: 4 [277504/319902 (87%)] Loss: 0.029430, 1 batch cost time 0.51
Train Epoch: 4 [278016/319902 (87%)] Loss: 0.009532, 1 batch cost time 0.51
Train Epoch: 4 [278528/319902 (87%)] Loss: 0.040331, 1 batch cost time 0.51
Train Epoch: 4 [279040/319902 (87%)] Loss: 0.028167, 1 batch cost time 0.51
Train Epoch: 4 [279552/319902 (87%)] Loss: 0.017704, 1 batch cost time 0.51
Train Epoch: 4 [280064/319902 (88%)] Loss: 0.019073, 1 batch cost time 0.51
Train Epoch: 4 [280576/319902 (88%)] Loss: 0.036552, 1 batch cost time 0.51
Train Epoch: 4 [281088/319902 (88%)] Loss: 0.030427, 1 batch cost time 0.51
Train Epoch: 4 [281600/319902 (88%)] Loss: 0.024002, 1 batch cost time 0.51
Train Epoch: 4 [282112/319902 (88%)] Loss: 0.039416, 1 batch cost time 0.51
Train Epoch: 4 [282624/319902 (88%)] Loss: 0.016563, 1 batch cost time 0.51
Train Epoch: 4 [283136/319902 (89%)] Loss: 0.028554, 1 batch cost time 0.51
Train Epoch: 4 [283648/319902 (89%)] Loss: 0.028718, 1 batch cost time 0.51
Train Epoch: 4 [284160/319902 (89%)] Loss: 0.017365, 1 batch cost time 0.51
Train Epoch: 4 [284672/319902 (89%)] Loss: 0.060641, 1 batch cost time 0.51
Train Epoch: 4 [285184/319902 (89%)] Loss: 0.037260, 1 batch cost time 0.51
Train Epoch: 4 [285696/319902 (89%)] Loss: 0.037817, 1 batch cost time 0.51
Train Epoch: 4 [286208/319902 (89%)] Loss: 0.033148, 1 batch cost time 0.51
Train Epoch: 4 [286720/319902 (90%)] Loss: 0.037598, 1 batch cost time 0.51
Train Epoch: 4 [287232/319902 (90%)] Loss: 0.034680, 1 batch cost time 0.51
Train Epoch: 4 [287744/319902 (90%)] Loss: 0.016628, 1 batch cost time 0.51
Train Epoch: 4 [288256/319902 (90%)] Loss: 0.039708, 1 batch cost time 0.51
Train Epoch: 4 [288768/319902 (90%)] Loss: 0.022721, 1 batch cost time 0.51
Train Epoch: 4 [289280/319902 (90%)] Loss: 0.014665, 1 batch cost time 0.51
Train Epoch: 4 [289792/319902 (91%)] Loss: 0.022905, 1 batch cost time 0.51
Train Epoch: 4 [290304/319902 (91%)] Loss: 0.040833, 1 batch cost time 0.51
Train Epoch: 4 [290816/319902 (91%)] Loss: 0.049290, 1 batch cost time 0.51
Train Epoch: 4 [291328/319902 (91%)] Loss: 0.017591, 1 batch cost time 0.51
Train Epoch: 4 [291840/319902 (91%)] Loss: 0.025382, 1 batch cost time 0.51
Train Epoch: 4 [292352/319902 (91%)] Loss: 0.021858, 1 batch cost time 0.51
Train Epoch: 4 [292864/319902 (92%)] Loss: 0.031755, 1 batch cost time 0.51
Train Epoch: 4 [293376/319902 (92%)] Loss: 0.016039, 1 batch cost time 0.51
Train Epoch: 4 [293888/319902 (92%)] Loss: 0.022117, 1 batch cost time 0.51
Train Epoch: 4 [294400/319902 (92%)] Loss: 0.019775, 1 batch cost time 0.51
Train Epoch: 4 [294912/319902 (92%)] Loss: 0.055583, 1 batch cost time 0.51
Train Epoch: 4 [295424/319902 (92%)] Loss: 0.032911, 1 batch cost time 0.51
Train Epoch: 4 [295936/319902 (93%)] Loss: 0.053130, 1 batch cost time 0.51
Train Epoch: 4 [296448/319902 (93%)] Loss: 0.061779, 1 batch cost time 0.51
Train Epoch: 4 [296960/319902 (93%)] Loss: 0.047227, 1 batch cost time 0.51
Train Epoch: 4 [297472/319902 (93%)] Loss: 0.042417, 1 batch cost time 0.51
Train Epoch: 4 [297984/319902 (93%)] Loss: 0.029097, 1 batch cost time 0.51
Train Epoch: 4 [298496/319902 (93%)] Loss: 0.021964, 1 batch cost time 0.51
Train Epoch: 4 [299008/319902 (93%)] Loss: 0.056422, 1 batch cost time 0.51
Train Epoch: 4 [299520/319902 (94%)] Loss: 0.033569, 1 batch cost time 0.51
Train Epoch: 4 [300032/319902 (94%)] Loss: 0.034247, 1 batch cost time 0.51
Train Epoch: 4 [300544/319902 (94%)] Loss: 0.042539, 1 batch cost time 0.51
Train Epoch: 4 [301056/319902 (94%)] Loss: 0.026253, 1 batch cost time 0.51
Train Epoch: 4 [301568/319902 (94%)] Loss: 0.040968, 1 batch cost time 0.51
Train Epoch: 4 [302080/319902 (94%)] Loss: 0.017628, 1 batch cost time 0.51
Train Epoch: 4 [302592/319902 (95%)] Loss: 0.030447, 1 batch cost time 0.51
Train Epoch: 4 [303104/319902 (95%)] Loss: 0.035154, 1 batch cost time 0.51
Train Epoch: 4 [303616/319902 (95%)] Loss: 0.052016, 1 batch cost time 0.51
Train Epoch: 4 [304128/319902 (95%)] Loss: 0.052155, 1 batch cost time 0.51
Train Epoch: 4 [304640/319902 (95%)] Loss: 0.059700, 1 batch cost time 0.51
Train Epoch: 4 [305152/319902 (95%)] Loss: 0.054760, 1 batch cost time 0.51
Train Epoch: 4 [305664/319902 (96%)] Loss: 0.026341, 1 batch cost time 0.51
Train Epoch: 4 [306176/319902 (96%)] Loss: 0.047032, 1 batch cost time 0.51
Train Epoch: 4 [306688/319902 (96%)] Loss: 0.017844, 1 batch cost time 0.51
Train Epoch: 4 [307200/319902 (96%)] Loss: 0.022860, 1 batch cost time 0.51
Train Epoch: 4 [307712/319902 (96%)] Loss: 0.040528, 1 batch cost time 0.51
Train Epoch: 4 [308224/319902 (96%)] Loss: 0.040057, 1 batch cost time 0.51
Train Epoch: 4 [308736/319902 (97%)] Loss: 0.040557, 1 batch cost time 0.51
Train Epoch: 4 [309248/319902 (97%)] Loss: 0.027807, 1 batch cost time 0.51
Train Epoch: 4 [309760/319902 (97%)] Loss: 0.014968, 1 batch cost time 0.51
Train Epoch: 4 [310272/319902 (97%)] Loss: 0.035546, 1 batch cost time 0.51
Train Epoch: 4 [310784/319902 (97%)] Loss: 0.032269, 1 batch cost time 0.51
Train Epoch: 4 [311296/319902 (97%)] Loss: 0.044131, 1 batch cost time 0.51
Train Epoch: 4 [311808/319902 (97%)] Loss: 0.021670, 1 batch cost time 0.51
Train Epoch: 4 [312320/319902 (98%)] Loss: 0.013462, 1 batch cost time 0.51
Train Epoch: 4 [312832/319902 (98%)] Loss: 0.056691, 1 batch cost time 0.51
Train Epoch: 4 [313344/319902 (98%)] Loss: 0.022342, 1 batch cost time 0.51
Train Epoch: 4 [313856/319902 (98%)] Loss: 0.047320, 1 batch cost time 0.51
Train Epoch: 4 [314368/319902 (98%)] Loss: 0.033709, 1 batch cost time 0.51
Train Epoch: 4 [314880/319902 (98%)] Loss: 0.034467, 1 batch cost time 0.51
Train Epoch: 4 [315392/319902 (99%)] Loss: 0.046140, 1 batch cost time 0.51
Train Epoch: 4 [315904/319902 (99%)] Loss: 0.033344, 1 batch cost time 0.51
Train Epoch: 4 [316416/319902 (99%)] Loss: 0.016811, 1 batch cost time 0.51
Train Epoch: 4 [316928/319902 (99%)] Loss: 0.026807, 1 batch cost time 0.51
Train Epoch: 4 [317440/319902 (99%)] Loss: 0.032418, 1 batch cost time 0.51
Train Epoch: 4 [317952/319902 (99%)] Loss: 0.052681, 1 batch cost time 0.51
Train Epoch: 4 [318464/319902 (100%)] Loss: 0.031034, 1 batch cost time 0.51
Train Epoch: 4 [318976/319902 (100%)] Loss: 0.032840, 1 batch cost time 0.51
Train Epoch: 4 [319488/319902 (100%)] Loss: 0.048993, 1 batch cost time 0.51
training epoch cost 7962.1581110954285 seconds
    epoch          : 4
    lr             : 0.0001
    loss           : 0.034175321761359956
    accuracy       : 0.927077080832333
    f_measure      : 0.508202792901671
    val_loss       : 0.028610118526557926
    val_accuracy   : 0.9373372395833334
    val_f_measure  : 0.4745010747354496
Saving current best: model_best.pth ...
Train Epoch: 5 [0/319902 (0%)] Loss: 0.030863, 1 batch cost time 0.53
Train Epoch: 5 [512/319902 (0%)] Loss: 0.025551, 1 batch cost time 0.51
Train Epoch: 5 [1024/319902 (0%)] Loss: 0.027446, 1 batch cost time 0.51
Train Epoch: 5 [1536/319902 (0%)] Loss: 0.018903, 1 batch cost time 0.51
Train Epoch: 5 [2048/319902 (1%)] Loss: 0.036457, 1 batch cost time 0.51
Train Epoch: 5 [2560/319902 (1%)] Loss: 0.023233, 1 batch cost time 0.51
Train Epoch: 5 [3072/319902 (1%)] Loss: 0.028906, 1 batch cost time 0.51
Train Epoch: 5 [3584/319902 (1%)] Loss: 0.024998, 1 batch cost time 0.51
Train Epoch: 5 [4096/319902 (1%)] Loss: 0.036953, 1 batch cost time 0.51
Train Epoch: 5 [4608/319902 (1%)] Loss: 0.026205, 1 batch cost time 0.51
Train Epoch: 5 [5120/319902 (2%)] Loss: 0.039457, 1 batch cost time 0.51
Train Epoch: 5 [5632/319902 (2%)] Loss: 0.017527, 1 batch cost time 0.51
Train Epoch: 5 [6144/319902 (2%)] Loss: 0.033542, 1 batch cost time 0.51
Train Epoch: 5 [6656/319902 (2%)] Loss: 0.020747, 1 batch cost time 0.51
Train Epoch: 5 [7168/319902 (2%)] Loss: 0.044483, 1 batch cost time 0.51
Train Epoch: 5 [7680/319902 (2%)] Loss: 0.052271, 1 batch cost time 0.51
Train Epoch: 5 [8192/319902 (3%)] Loss: 0.073828, 1 batch cost time 0.51
Train Epoch: 5 [8704/319902 (3%)] Loss: 0.031071, 1 batch cost time 0.51
Train Epoch: 5 [9216/319902 (3%)] Loss: 0.021754, 1 batch cost time 0.51
Train Epoch: 5 [9728/319902 (3%)] Loss: 0.034632, 1 batch cost time 0.51
Train Epoch: 5 [10240/319902 (3%)] Loss: 0.040300, 1 batch cost time 0.51
Train Epoch: 5 [10752/319902 (3%)] Loss: 0.045620, 1 batch cost time 0.51
Train Epoch: 5 [11264/319902 (4%)] Loss: 0.037001, 1 batch cost time 0.51
Train Epoch: 5 [11776/319902 (4%)] Loss: 0.030370, 1 batch cost time 0.51
Train Epoch: 5 [12288/319902 (4%)] Loss: 0.043706, 1 batch cost time 0.51
Train Epoch: 5 [12800/319902 (4%)] Loss: 0.018773, 1 batch cost time 0.51
Train Epoch: 5 [13312/319902 (4%)] Loss: 0.028426, 1 batch cost time 0.51
Train Epoch: 5 [13824/319902 (4%)] Loss: 0.019752, 1 batch cost time 0.51
Train Epoch: 5 [14336/319902 (4%)] Loss: 0.026589, 1 batch cost time 0.51
Train Epoch: 5 [14848/319902 (5%)] Loss: 0.042770, 1 batch cost time 0.51
Train Epoch: 5 [15360/319902 (5%)] Loss: 0.027683, 1 batch cost time 0.51
Train Epoch: 5 [15872/319902 (5%)] Loss: 0.033658, 1 batch cost time 0.51
Train Epoch: 5 [16384/319902 (5%)] Loss: 0.017948, 1 batch cost time 0.51
Train Epoch: 5 [16896/319902 (5%)] Loss: 0.023523, 1 batch cost time 0.51
Train Epoch: 5 [17408/319902 (5%)] Loss: 0.037946, 1 batch cost time 0.51
Train Epoch: 5 [17920/319902 (6%)] Loss: 0.041026, 1 batch cost time 0.51
Train Epoch: 5 [18432/319902 (6%)] Loss: 0.037475, 1 batch cost time 0.51
Train Epoch: 5 [18944/319902 (6%)] Loss: 0.022407, 1 batch cost time 0.51
Train Epoch: 5 [19456/319902 (6%)] Loss: 0.034257, 1 batch cost time 0.51
Train Epoch: 5 [19968/319902 (6%)] Loss: 0.035712, 1 batch cost time 0.51
Train Epoch: 5 [20480/319902 (6%)] Loss: 0.015685, 1 batch cost time 0.51
Train Epoch: 5 [20992/319902 (7%)] Loss: 0.026147, 1 batch cost time 0.51
Train Epoch: 5 [21504/319902 (7%)] Loss: 0.023084, 1 batch cost time 0.51
Train Epoch: 5 [22016/319902 (7%)] Loss: 0.041282, 1 batch cost time 0.51
Train Epoch: 5 [22528/319902 (7%)] Loss: 0.015733, 1 batch cost time 0.51
Train Epoch: 5 [23040/319902 (7%)] Loss: 0.025208, 1 batch cost time 0.51
Train Epoch: 5 [23552/319902 (7%)] Loss: 0.041440, 1 batch cost time 0.51
Train Epoch: 5 [24064/319902 (8%)] Loss: 0.017157, 1 batch cost time 0.51
Train Epoch: 5 [24576/319902 (8%)] Loss: 0.032556, 1 batch cost time 0.51
Train Epoch: 5 [25088/319902 (8%)] Loss: 0.040510, 1 batch cost time 0.51
Train Epoch: 5 [25600/319902 (8%)] Loss: 0.044346, 1 batch cost time 0.51
Train Epoch: 5 [26112/319902 (8%)] Loss: 0.020149, 1 batch cost time 0.51
Train Epoch: 5 [26624/319902 (8%)] Loss: 0.024007, 1 batch cost time 0.51
Train Epoch: 5 [27136/319902 (8%)] Loss: 0.026441, 1 batch cost time 0.51
Train Epoch: 5 [27648/319902 (9%)] Loss: 0.029632, 1 batch cost time 0.51
Train Epoch: 5 [28160/319902 (9%)] Loss: 0.046662, 1 batch cost time 0.51
Train Epoch: 5 [28672/319902 (9%)] Loss: 0.015955, 1 batch cost time 0.51
Train Epoch: 5 [29184/319902 (9%)] Loss: 0.038316, 1 batch cost time 0.51
Train Epoch: 5 [29696/319902 (9%)] Loss: 0.034215, 1 batch cost time 0.51
Train Epoch: 5 [30208/319902 (9%)] Loss: 0.027163, 1 batch cost time 0.51
Train Epoch: 5 [30720/319902 (10%)] Loss: 0.051774, 1 batch cost time 0.51
Train Epoch: 5 [31232/319902 (10%)] Loss: 0.024637, 1 batch cost time 0.51
Train Epoch: 5 [31744/319902 (10%)] Loss: 0.017350, 1 batch cost time 0.51
Train Epoch: 5 [32256/319902 (10%)] Loss: 0.013569, 1 batch cost time 0.51
Train Epoch: 5 [32768/319902 (10%)] Loss: 0.034854, 1 batch cost time 0.51
Train Epoch: 5 [33280/319902 (10%)] Loss: 0.034299, 1 batch cost time 0.51
Train Epoch: 5 [33792/319902 (11%)] Loss: 0.043987, 1 batch cost time 0.51
Train Epoch: 5 [34304/319902 (11%)] Loss: 0.035490, 1 batch cost time 0.51
Train Epoch: 5 [34816/319902 (11%)] Loss: 0.021931, 1 batch cost time 0.51
Train Epoch: 5 [35328/319902 (11%)] Loss: 0.027376, 1 batch cost time 0.51
Train Epoch: 5 [35840/319902 (11%)] Loss: 0.065826, 1 batch cost time 0.51
Train Epoch: 5 [36352/319902 (11%)] Loss: 0.029558, 1 batch cost time 0.51
Train Epoch: 5 [36864/319902 (12%)] Loss: 0.043403, 1 batch cost time 0.51
Train Epoch: 5 [37376/319902 (12%)] Loss: 0.024765, 1 batch cost time 0.51
Train Epoch: 5 [37888/319902 (12%)] Loss: 0.032415, 1 batch cost time 0.51
Train Epoch: 5 [38400/319902 (12%)] Loss: 0.023645, 1 batch cost time 0.51
Train Epoch: 5 [38912/319902 (12%)] Loss: 0.010441, 1 batch cost time 0.51
Train Epoch: 5 [39424/319902 (12%)] Loss: 0.038362, 1 batch cost time 0.51
Train Epoch: 5 [39936/319902 (12%)] Loss: 0.026094, 1 batch cost time 0.51
Train Epoch: 5 [40448/319902 (13%)] Loss: 0.027984, 1 batch cost time 0.51
Train Epoch: 5 [40960/319902 (13%)] Loss: 0.022388, 1 batch cost time 0.51
Train Epoch: 5 [41472/319902 (13%)] Loss: 0.023674, 1 batch cost time 0.51
Train Epoch: 5 [41984/319902 (13%)] Loss: 0.030416, 1 batch cost time 0.51
Train Epoch: 5 [42496/319902 (13%)] Loss: 0.039266, 1 batch cost time 0.51
Train Epoch: 5 [43008/319902 (13%)] Loss: 0.027940, 1 batch cost time 0.51
Train Epoch: 5 [43520/319902 (14%)] Loss: 0.031513, 1 batch cost time 0.51
Train Epoch: 5 [44032/319902 (14%)] Loss: 0.014552, 1 batch cost time 0.51
Train Epoch: 5 [44544/319902 (14%)] Loss: 0.028504, 1 batch cost time 0.51
Train Epoch: 5 [45056/319902 (14%)] Loss: 0.029002, 1 batch cost time 0.51
Train Epoch: 5 [45568/319902 (14%)] Loss: 0.020293, 1 batch cost time 0.51
Train Epoch: 5 [46080/319902 (14%)] Loss: 0.022609, 1 batch cost time 0.51
Train Epoch: 5 [46592/319902 (15%)] Loss: 0.019796, 1 batch cost time 0.51
Train Epoch: 5 [47104/319902 (15%)] Loss: 0.032999, 1 batch cost time 0.51
Train Epoch: 5 [47616/319902 (15%)] Loss: 0.046419, 1 batch cost time 0.51
Train Epoch: 5 [48128/319902 (15%)] Loss: 0.017942, 1 batch cost time 0.51
Train Epoch: 5 [48640/319902 (15%)] Loss: 0.062378, 1 batch cost time 0.51
Train Epoch: 5 [49152/319902 (15%)] Loss: 0.058687, 1 batch cost time 0.51
Train Epoch: 5 [49664/319902 (16%)] Loss: 0.032464, 1 batch cost time 0.51
Train Epoch: 5 [50176/319902 (16%)] Loss: 0.017976, 1 batch cost time 0.51
Train Epoch: 5 [50688/319902 (16%)] Loss: 0.061179, 1 batch cost time 0.51
Train Epoch: 5 [51200/319902 (16%)] Loss: 0.025709, 1 batch cost time 0.51
Train Epoch: 5 [51712/319902 (16%)] Loss: 0.032800, 1 batch cost time 0.51
Train Epoch: 5 [52224/319902 (16%)] Loss: 0.043753, 1 batch cost time 0.51
Train Epoch: 5 [52736/319902 (16%)] Loss: 0.016868, 1 batch cost time 0.51
Train Epoch: 5 [53248/319902 (17%)] Loss: 0.039866, 1 batch cost time 0.51
Train Epoch: 5 [53760/319902 (17%)] Loss: 0.024742, 1 batch cost time 0.51
Train Epoch: 5 [54272/319902 (17%)] Loss: 0.039828, 1 batch cost time 0.51
Train Epoch: 5 [54784/319902 (17%)] Loss: 0.062612, 1 batch cost time 0.51
Train Epoch: 5 [55296/319902 (17%)] Loss: 0.028241, 1 batch cost time 0.51
Train Epoch: 5 [55808/319902 (17%)] Loss: 0.036469, 1 batch cost time 0.51
Train Epoch: 5 [56320/319902 (18%)] Loss: 0.023199, 1 batch cost time 0.51
Train Epoch: 5 [56832/319902 (18%)] Loss: 0.032180, 1 batch cost time 0.51
Train Epoch: 5 [57344/319902 (18%)] Loss: 0.027912, 1 batch cost time 0.51
Train Epoch: 5 [57856/319902 (18%)] Loss: 0.036137, 1 batch cost time 0.51
Train Epoch: 5 [58368/319902 (18%)] Loss: 0.026768, 1 batch cost time 0.51
Train Epoch: 5 [58880/319902 (18%)] Loss: 0.014782, 1 batch cost time 0.51
Train Epoch: 5 [59392/319902 (19%)] Loss: 0.053368, 1 batch cost time 0.51
Train Epoch: 5 [59904/319902 (19%)] Loss: 0.008143, 1 batch cost time 0.51
Train Epoch: 5 [60416/319902 (19%)] Loss: 0.015314, 1 batch cost time 0.51
Train Epoch: 5 [60928/319902 (19%)] Loss: 0.059785, 1 batch cost time 0.51
Train Epoch: 5 [61440/319902 (19%)] Loss: 0.073882, 1 batch cost time 0.51
Train Epoch: 5 [61952/319902 (19%)] Loss: 0.024450, 1 batch cost time 0.51
Train Epoch: 5 [62464/319902 (20%)] Loss: 0.068847, 1 batch cost time 0.51
Train Epoch: 5 [62976/319902 (20%)] Loss: 0.030803, 1 batch cost time 0.51
Train Epoch: 5 [63488/319902 (20%)] Loss: 0.006723, 1 batch cost time 0.51
Train Epoch: 5 [64000/319902 (20%)] Loss: 0.047047, 1 batch cost time 0.51
Train Epoch: 5 [64512/319902 (20%)] Loss: 0.036084, 1 batch cost time 0.51
Train Epoch: 5 [65024/319902 (20%)] Loss: 0.016059, 1 batch cost time 0.51
Train Epoch: 5 [65536/319902 (20%)] Loss: 0.041587, 1 batch cost time 0.51
Train Epoch: 5 [66048/319902 (21%)] Loss: 0.055668, 1 batch cost time 0.51
Train Epoch: 5 [66560/319902 (21%)] Loss: 0.025839, 1 batch cost time 0.51
Train Epoch: 5 [67072/319902 (21%)] Loss: 0.040892, 1 batch cost time 0.51
Train Epoch: 5 [67584/319902 (21%)] Loss: 0.041956, 1 batch cost time 0.51
Train Epoch: 5 [68096/319902 (21%)] Loss: 0.017137, 1 batch cost time 0.51
Train Epoch: 5 [68608/319902 (21%)] Loss: 0.028140, 1 batch cost time 0.51
Train Epoch: 5 [69120/319902 (22%)] Loss: 0.042114, 1 batch cost time 0.51
Train Epoch: 5 [69632/319902 (22%)] Loss: 0.029967, 1 batch cost time 0.51
Train Epoch: 5 [70144/319902 (22%)] Loss: 0.044815, 1 batch cost time 0.51
Train Epoch: 5 [70656/319902 (22%)] Loss: 0.024943, 1 batch cost time 0.51
Train Epoch: 5 [71168/319902 (22%)] Loss: 0.025898, 1 batch cost time 0.51
Train Epoch: 5 [71680/319902 (22%)] Loss: 0.059411, 1 batch cost time 0.51
Train Epoch: 5 [72192/319902 (23%)] Loss: 0.024376, 1 batch cost time 0.51
Train Epoch: 5 [72704/319902 (23%)] Loss: 0.025388, 1 batch cost time 0.51
Train Epoch: 5 [73216/319902 (23%)] Loss: 0.015121, 1 batch cost time 0.51
Train Epoch: 5 [73728/319902 (23%)] Loss: 0.046292, 1 batch cost time 0.51
Train Epoch: 5 [74240/319902 (23%)] Loss: 0.068007, 1 batch cost time 0.51
Train Epoch: 5 [74752/319902 (23%)] Loss: 0.039301, 1 batch cost time 0.51
Train Epoch: 5 [75264/319902 (24%)] Loss: 0.018064, 1 batch cost time 0.51
Train Epoch: 5 [75776/319902 (24%)] Loss: 0.033614, 1 batch cost time 0.51
Train Epoch: 5 [76288/319902 (24%)] Loss: 0.038994, 1 batch cost time 0.51
Train Epoch: 5 [76800/319902 (24%)] Loss: 0.017724, 1 batch cost time 0.51
Train Epoch: 5 [77312/319902 (24%)] Loss: 0.017733, 1 batch cost time 0.51
Train Epoch: 5 [77824/319902 (24%)] Loss: 0.017764, 1 batch cost time 0.51
Train Epoch: 5 [78336/319902 (24%)] Loss: 0.074882, 1 batch cost time 0.51
Train Epoch: 5 [78848/319902 (25%)] Loss: 0.024685, 1 batch cost time 0.51
Train Epoch: 5 [79360/319902 (25%)] Loss: 0.026528, 1 batch cost time 0.51
Train Epoch: 5 [79872/319902 (25%)] Loss: 0.036403, 1 batch cost time 0.51
Train Epoch: 5 [80384/319902 (25%)] Loss: 0.018809, 1 batch cost time 0.51
Train Epoch: 5 [80896/319902 (25%)] Loss: 0.069799, 1 batch cost time 0.51
Train Epoch: 5 [81408/319902 (25%)] Loss: 0.020353, 1 batch cost time 0.51
Train Epoch: 5 [81920/319902 (26%)] Loss: 0.037296, 1 batch cost time 0.51
Train Epoch: 5 [82432/319902 (26%)] Loss: 0.017810, 1 batch cost time 0.51
Train Epoch: 5 [82944/319902 (26%)] Loss: 0.018985, 1 batch cost time 0.51
Train Epoch: 5 [83456/319902 (26%)] Loss: 0.020970, 1 batch cost time 0.51
Train Epoch: 5 [83968/319902 (26%)] Loss: 0.017670, 1 batch cost time 0.51
Train Epoch: 5 [84480/319902 (26%)] Loss: 0.026511, 1 batch cost time 0.51
Train Epoch: 5 [84992/319902 (27%)] Loss: 0.033238, 1 batch cost time 0.51
Train Epoch: 5 [85504/319902 (27%)] Loss: 0.021661, 1 batch cost time 0.51
Train Epoch: 5 [86016/319902 (27%)] Loss: 0.022983, 1 batch cost time 0.51
Train Epoch: 5 [86528/319902 (27%)] Loss: 0.047246, 1 batch cost time 0.51
Train Epoch: 5 [87040/319902 (27%)] Loss: 0.023182, 1 batch cost time 0.51
Train Epoch: 5 [87552/319902 (27%)] Loss: 0.016222, 1 batch cost time 0.51
Train Epoch: 5 [88064/319902 (28%)] Loss: 0.022919, 1 batch cost time 0.51
Train Epoch: 5 [88576/319902 (28%)] Loss: 0.056628, 1 batch cost time 0.51
Train Epoch: 5 [89088/319902 (28%)] Loss: 0.021239, 1 batch cost time 0.51
Train Epoch: 5 [89600/319902 (28%)] Loss: 0.021038, 1 batch cost time 0.51
Train Epoch: 5 [90112/319902 (28%)] Loss: 0.040393, 1 batch cost time 0.51
Train Epoch: 5 [90624/319902 (28%)] Loss: 0.049681, 1 batch cost time 0.51
Train Epoch: 5 [91136/319902 (28%)] Loss: 0.056879, 1 batch cost time 0.51
Train Epoch: 5 [91648/319902 (29%)] Loss: 0.031517, 1 batch cost time 0.51
Train Epoch: 5 [92160/319902 (29%)] Loss: 0.011579, 1 batch cost time 0.51
Train Epoch: 5 [92672/319902 (29%)] Loss: 0.027468, 1 batch cost time 0.51
Train Epoch: 5 [93184/319902 (29%)] Loss: 0.043029, 1 batch cost time 0.51
Train Epoch: 5 [93696/319902 (29%)] Loss: 0.054361, 1 batch cost time 0.51
Train Epoch: 5 [94208/319902 (29%)] Loss: 0.030512, 1 batch cost time 0.51
Train Epoch: 5 [94720/319902 (30%)] Loss: 0.049840, 1 batch cost time 0.51
Train Epoch: 5 [95232/319902 (30%)] Loss: 0.033712, 1 batch cost time 0.51
Train Epoch: 5 [95744/319902 (30%)] Loss: 0.021694, 1 batch cost time 0.51
Train Epoch: 5 [96256/319902 (30%)] Loss: 0.022314, 1 batch cost time 0.51
Train Epoch: 5 [96768/319902 (30%)] Loss: 0.052990, 1 batch cost time 0.51
Train Epoch: 5 [97280/319902 (30%)] Loss: 0.025516, 1 batch cost time 0.51
Train Epoch: 5 [97792/319902 (31%)] Loss: 0.018581, 1 batch cost time 0.51
Train Epoch: 5 [98304/319902 (31%)] Loss: 0.039237, 1 batch cost time 0.51
Train Epoch: 5 [98816/319902 (31%)] Loss: 0.060643, 1 batch cost time 0.51
Train Epoch: 5 [99328/319902 (31%)] Loss: 0.040477, 1 batch cost time 0.51
Train Epoch: 5 [99840/319902 (31%)] Loss: 0.026012, 1 batch cost time 0.51
Train Epoch: 5 [100352/319902 (31%)] Loss: 0.027223, 1 batch cost time 0.51
Train Epoch: 5 [100864/319902 (32%)] Loss: 0.036845, 1 batch cost time 0.51
Train Epoch: 5 [101376/319902 (32%)] Loss: 0.043068, 1 batch cost time 0.51
Train Epoch: 5 [101888/319902 (32%)] Loss: 0.016900, 1 batch cost time 0.51
Train Epoch: 5 [102400/319902 (32%)] Loss: 0.061192, 1 batch cost time 0.51
Train Epoch: 5 [102912/319902 (32%)] Loss: 0.064266, 1 batch cost time 0.51
Train Epoch: 5 [103424/319902 (32%)] Loss: 0.033597, 1 batch cost time 0.51
Train Epoch: 5 [103936/319902 (32%)] Loss: 0.035736, 1 batch cost time 0.51
Train Epoch: 5 [104448/319902 (33%)] Loss: 0.022016, 1 batch cost time 0.51
Train Epoch: 5 [104960/319902 (33%)] Loss: 0.025305, 1 batch cost time 0.51
Train Epoch: 5 [105472/319902 (33%)] Loss: 0.040219, 1 batch cost time 0.51
Train Epoch: 5 [105984/319902 (33%)] Loss: 0.022915, 1 batch cost time 0.51
Train Epoch: 5 [106496/319902 (33%)] Loss: 0.025333, 1 batch cost time 0.51
Train Epoch: 5 [107008/319902 (33%)] Loss: 0.016440, 1 batch cost time 0.51
Train Epoch: 5 [107520/319902 (34%)] Loss: 0.010949, 1 batch cost time 0.51
Train Epoch: 5 [108032/319902 (34%)] Loss: 0.029860, 1 batch cost time 0.51
Train Epoch: 5 [108544/319902 (34%)] Loss: 0.043122, 1 batch cost time 0.51
Train Epoch: 5 [109056/319902 (34%)] Loss: 0.032493, 1 batch cost time 0.51
Train Epoch: 5 [109568/319902 (34%)] Loss: 0.056054, 1 batch cost time 0.51
Train Epoch: 5 [110080/319902 (34%)] Loss: 0.041783, 1 batch cost time 0.51
Train Epoch: 5 [110592/319902 (35%)] Loss: 0.037243, 1 batch cost time 0.51
Train Epoch: 5 [111104/319902 (35%)] Loss: 0.029019, 1 batch cost time 0.51
Train Epoch: 5 [111616/319902 (35%)] Loss: 0.019353, 1 batch cost time 0.51
Train Epoch: 5 [112128/319902 (35%)] Loss: 0.013181, 1 batch cost time 0.51
Train Epoch: 5 [112640/319902 (35%)] Loss: 0.018661, 1 batch cost time 0.51
Train Epoch: 5 [113152/319902 (35%)] Loss: 0.026019, 1 batch cost time 0.51
Train Epoch: 5 [113664/319902 (36%)] Loss: 0.024142, 1 batch cost time 0.51
Train Epoch: 5 [114176/319902 (36%)] Loss: 0.017435, 1 batch cost time 0.51
Train Epoch: 5 [114688/319902 (36%)] Loss: 0.022451, 1 batch cost time 0.51
Train Epoch: 5 [115200/319902 (36%)] Loss: 0.031464, 1 batch cost time 0.51
Train Epoch: 5 [115712/319902 (36%)] Loss: 0.007245, 1 batch cost time 0.51
Train Epoch: 5 [116224/319902 (36%)] Loss: 0.026433, 1 batch cost time 0.51
Train Epoch: 5 [116736/319902 (36%)] Loss: 0.007731, 1 batch cost time 0.51
Train Epoch: 5 [117248/319902 (37%)] Loss: 0.019348, 1 batch cost time 0.51
Train Epoch: 5 [117760/319902 (37%)] Loss: 0.035463, 1 batch cost time 0.51
Train Epoch: 5 [118272/319902 (37%)] Loss: 0.036251, 1 batch cost time 0.51
Train Epoch: 5 [118784/319902 (37%)] Loss: 0.019833, 1 batch cost time 0.51
Train Epoch: 5 [119296/319902 (37%)] Loss: 0.050303, 1 batch cost time 0.51
Train Epoch: 5 [119808/319902 (37%)] Loss: 0.052888, 1 batch cost time 0.51
Train Epoch: 5 [120320/319902 (38%)] Loss: 0.022409, 1 batch cost time 0.51
Train Epoch: 5 [120832/319902 (38%)] Loss: 0.013012, 1 batch cost time 0.51
Train Epoch: 5 [121344/319902 (38%)] Loss: 0.030495, 1 batch cost time 0.51
Train Epoch: 5 [121856/319902 (38%)] Loss: 0.046547, 1 batch cost time 0.51
Train Epoch: 5 [122368/319902 (38%)] Loss: 0.015172, 1 batch cost time 0.51
Train Epoch: 5 [122880/319902 (38%)] Loss: 0.026937, 1 batch cost time 0.51
Train Epoch: 5 [123392/319902 (39%)] Loss: 0.018288, 1 batch cost time 0.51
Train Epoch: 5 [123904/319902 (39%)] Loss: 0.025663, 1 batch cost time 0.51
Train Epoch: 5 [124416/319902 (39%)] Loss: 0.023479, 1 batch cost time 0.51
Train Epoch: 5 [124928/319902 (39%)] Loss: 0.043814, 1 batch cost time 0.51
Train Epoch: 5 [125440/319902 (39%)] Loss: 0.033430, 1 batch cost time 0.51
Train Epoch: 5 [125952/319902 (39%)] Loss: 0.019942, 1 batch cost time 0.51
Train Epoch: 5 [126464/319902 (40%)] Loss: 0.024066, 1 batch cost time 0.51
Train Epoch: 5 [126976/319902 (40%)] Loss: 0.023077, 1 batch cost time 0.51
Train Epoch: 5 [127488/319902 (40%)] Loss: 0.017692, 1 batch cost time 0.51
Train Epoch: 5 [128000/319902 (40%)] Loss: 0.056618, 1 batch cost time 0.51
Train Epoch: 5 [128512/319902 (40%)] Loss: 0.057076, 1 batch cost time 0.51
Train Epoch: 5 [129024/319902 (40%)] Loss: 0.013058, 1 batch cost time 0.51
Train Epoch: 5 [129536/319902 (40%)] Loss: 0.037061, 1 batch cost time 0.51
Train Epoch: 5 [130048/319902 (41%)] Loss: 0.055565, 1 batch cost time 0.51
Train Epoch: 5 [130560/319902 (41%)] Loss: 0.058236, 1 batch cost time 0.51
Train Epoch: 5 [131072/319902 (41%)] Loss: 0.031079, 1 batch cost time 0.51
Train Epoch: 5 [131584/319902 (41%)] Loss: 0.023758, 1 batch cost time 0.51
Train Epoch: 5 [132096/319902 (41%)] Loss: 0.040226, 1 batch cost time 0.51
Train Epoch: 5 [132608/319902 (41%)] Loss: 0.006308, 1 batch cost time 0.51
Train Epoch: 5 [133120/319902 (42%)] Loss: 0.024033, 1 batch cost time 0.51
Train Epoch: 5 [133632/319902 (42%)] Loss: 0.016039, 1 batch cost time 0.51
Train Epoch: 5 [134144/319902 (42%)] Loss: 0.035537, 1 batch cost time 0.51
Train Epoch: 5 [134656/319902 (42%)] Loss: 0.033239, 1 batch cost time 0.51
Train Epoch: 5 [135168/319902 (42%)] Loss: 0.023461, 1 batch cost time 0.51
Train Epoch: 5 [135680/319902 (42%)] Loss: 0.054864, 1 batch cost time 0.51
Train Epoch: 5 [136192/319902 (43%)] Loss: 0.057548, 1 batch cost time 0.51
Train Epoch: 5 [136704/319902 (43%)] Loss: 0.036194, 1 batch cost time 0.51
Train Epoch: 5 [137216/319902 (43%)] Loss: 0.026882, 1 batch cost time 0.51
Train Epoch: 5 [137728/319902 (43%)] Loss: 0.026456, 1 batch cost time 0.51
Train Epoch: 5 [138240/319902 (43%)] Loss: 0.044396, 1 batch cost time 0.51
Train Epoch: 5 [138752/319902 (43%)] Loss: 0.059513, 1 batch cost time 0.51
Train Epoch: 5 [139264/319902 (44%)] Loss: 0.046502, 1 batch cost time 0.51
Train Epoch: 5 [139776/319902 (44%)] Loss: 0.020835, 1 batch cost time 0.51
Train Epoch: 5 [140288/319902 (44%)] Loss: 0.021680, 1 batch cost time 0.51
Train Epoch: 5 [140800/319902 (44%)] Loss: 0.034651, 1 batch cost time 0.51
Train Epoch: 5 [141312/319902 (44%)] Loss: 0.055106, 1 batch cost time 0.51
Train Epoch: 5 [141824/319902 (44%)] Loss: 0.046685, 1 batch cost time 0.51
Train Epoch: 5 [142336/319902 (44%)] Loss: 0.026200, 1 batch cost time 0.51
Train Epoch: 5 [142848/319902 (45%)] Loss: 0.016120, 1 batch cost time 0.51
Train Epoch: 5 [143360/319902 (45%)] Loss: 0.024966, 1 batch cost time 0.51
Train Epoch: 5 [143872/319902 (45%)] Loss: 0.034373, 1 batch cost time 0.51
Train Epoch: 5 [144384/319902 (45%)] Loss: 0.015993, 1 batch cost time 0.51
Train Epoch: 5 [144896/319902 (45%)] Loss: 0.025959, 1 batch cost time 0.51
Train Epoch: 5 [145408/319902 (45%)] Loss: 0.043389, 1 batch cost time 0.51
Train Epoch: 5 [145920/319902 (46%)] Loss: 0.028824, 1 batch cost time 0.51
Train Epoch: 5 [146432/319902 (46%)] Loss: 0.023512, 1 batch cost time 0.51
Train Epoch: 5 [146944/319902 (46%)] Loss: 0.013795, 1 batch cost time 0.51
Train Epoch: 5 [147456/319902 (46%)] Loss: 0.049621, 1 batch cost time 0.51
Train Epoch: 5 [147968/319902 (46%)] Loss: 0.035690, 1 batch cost time 0.51
Train Epoch: 5 [148480/319902 (46%)] Loss: 0.038077, 1 batch cost time 0.51
Train Epoch: 5 [148992/319902 (47%)] Loss: 0.033612, 1 batch cost time 0.51
Train Epoch: 5 [149504/319902 (47%)] Loss: 0.016499, 1 batch cost time 0.51
Train Epoch: 5 [150016/319902 (47%)] Loss: 0.027904, 1 batch cost time 0.51
Train Epoch: 5 [150528/319902 (47%)] Loss: 0.048794, 1 batch cost time 0.51
Train Epoch: 5 [151040/319902 (47%)] Loss: 0.020544, 1 batch cost time 0.51
Train Epoch: 5 [151552/319902 (47%)] Loss: 0.029154, 1 batch cost time 0.51
Train Epoch: 5 [152064/319902 (48%)] Loss: 0.021269, 1 batch cost time 0.51
Train Epoch: 5 [152576/319902 (48%)] Loss: 0.036446, 1 batch cost time 0.51
Train Epoch: 5 [153088/319902 (48%)] Loss: 0.048402, 1 batch cost time 0.51
Train Epoch: 5 [153600/319902 (48%)] Loss: 0.017194, 1 batch cost time 0.51
Train Epoch: 5 [154112/319902 (48%)] Loss: 0.036640, 1 batch cost time 0.51
Train Epoch: 5 [154624/319902 (48%)] Loss: 0.025702, 1 batch cost time 0.51
Train Epoch: 5 [155136/319902 (48%)] Loss: 0.019482, 1 batch cost time 0.51
Train Epoch: 5 [155648/319902 (49%)] Loss: 0.027597, 1 batch cost time 0.51
Train Epoch: 5 [156160/319902 (49%)] Loss: 0.025628, 1 batch cost time 0.51
Train Epoch: 5 [156672/319902 (49%)] Loss: 0.038960, 1 batch cost time 0.51
Train Epoch: 5 [157184/319902 (49%)] Loss: 0.040212, 1 batch cost time 0.51
Train Epoch: 5 [157696/319902 (49%)] Loss: 0.024483, 1 batch cost time 0.51
Train Epoch: 5 [158208/319902 (49%)] Loss: 0.029529, 1 batch cost time 0.51
Train Epoch: 5 [158720/319902 (50%)] Loss: 0.039511, 1 batch cost time 0.51
Train Epoch: 5 [159232/319902 (50%)] Loss: 0.025337, 1 batch cost time 0.51
Train Epoch: 5 [159744/319902 (50%)] Loss: 0.026630, 1 batch cost time 0.51
Train Epoch: 5 [160256/319902 (50%)] Loss: 0.026785, 1 batch cost time 0.51
Train Epoch: 5 [160768/319902 (50%)] Loss: 0.046707, 1 batch cost time 0.51
Train Epoch: 5 [161280/319902 (50%)] Loss: 0.040686, 1 batch cost time 0.51
Train Epoch: 5 [161792/319902 (51%)] Loss: 0.027105, 1 batch cost time 0.51
Train Epoch: 5 [162304/319902 (51%)] Loss: 0.048837, 1 batch cost time 0.51
Train Epoch: 5 [162816/319902 (51%)] Loss: 0.013585, 1 batch cost time 0.51
Train Epoch: 5 [163328/319902 (51%)] Loss: 0.052901, 1 batch cost time 0.51
Train Epoch: 5 [163840/319902 (51%)] Loss: 0.075753, 1 batch cost time 0.51
Train Epoch: 5 [164352/319902 (51%)] Loss: 0.052440, 1 batch cost time 0.51
Train Epoch: 5 [164864/319902 (52%)] Loss: 0.019747, 1 batch cost time 0.51
Train Epoch: 5 [165376/319902 (52%)] Loss: 0.026301, 1 batch cost time 0.51
Train Epoch: 5 [165888/319902 (52%)] Loss: 0.020375, 1 batch cost time 0.51
Train Epoch: 5 [166400/319902 (52%)] Loss: 0.019630, 1 batch cost time 0.51
Train Epoch: 5 [166912/319902 (52%)] Loss: 0.042151, 1 batch cost time 0.51
Train Epoch: 5 [167424/319902 (52%)] Loss: 0.042452, 1 batch cost time 0.51
Train Epoch: 5 [167936/319902 (52%)] Loss: 0.023481, 1 batch cost time 0.51
Train Epoch: 5 [168448/319902 (53%)] Loss: 0.043485, 1 batch cost time 0.51
Train Epoch: 5 [168960/319902 (53%)] Loss: 0.023774, 1 batch cost time 0.51
Train Epoch: 5 [169472/319902 (53%)] Loss: 0.037026, 1 batch cost time 0.51
Train Epoch: 5 [169984/319902 (53%)] Loss: 0.012026, 1 batch cost time 0.51
Train Epoch: 5 [170496/319902 (53%)] Loss: 0.047922, 1 batch cost time 0.51
Train Epoch: 5 [171008/319902 (53%)] Loss: 0.026949, 1 batch cost time 0.51
Train Epoch: 5 [171520/319902 (54%)] Loss: 0.061415, 1 batch cost time 0.51
Train Epoch: 5 [172032/319902 (54%)] Loss: 0.025608, 1 batch cost time 0.51
Train Epoch: 5 [172544/319902 (54%)] Loss: 0.028500, 1 batch cost time 0.51
Train Epoch: 5 [173056/319902 (54%)] Loss: 0.008488, 1 batch cost time 0.51
Train Epoch: 5 [173568/319902 (54%)] Loss: 0.015506, 1 batch cost time 0.51
Train Epoch: 5 [174080/319902 (54%)] Loss: 0.027882, 1 batch cost time 0.51
Train Epoch: 5 [174592/319902 (55%)] Loss: 0.008516, 1 batch cost time 0.51
Train Epoch: 5 [175104/319902 (55%)] Loss: 0.026864, 1 batch cost time 0.51
Train Epoch: 5 [175616/319902 (55%)] Loss: 0.043324, 1 batch cost time 0.51
Train Epoch: 5 [176128/319902 (55%)] Loss: 0.044772, 1 batch cost time 0.51
Train Epoch: 5 [176640/319902 (55%)] Loss: 0.032435, 1 batch cost time 0.51
Train Epoch: 5 [177152/319902 (55%)] Loss: 0.041162, 1 batch cost time 0.51
Train Epoch: 5 [177664/319902 (56%)] Loss: 0.027288, 1 batch cost time 0.51
Train Epoch: 5 [178176/319902 (56%)] Loss: 0.066476, 1 batch cost time 0.51
Train Epoch: 5 [178688/319902 (56%)] Loss: 0.047357, 1 batch cost time 0.51
Train Epoch: 5 [179200/319902 (56%)] Loss: 0.054467, 1 batch cost time 0.51
Train Epoch: 5 [179712/319902 (56%)] Loss: 0.036738, 1 batch cost time 0.51
Train Epoch: 5 [180224/319902 (56%)] Loss: 0.040465, 1 batch cost time 0.51
Train Epoch: 5 [180736/319902 (56%)] Loss: 0.016514, 1 batch cost time 0.51
Train Epoch: 5 [181248/319902 (57%)] Loss: 0.032956, 1 batch cost time 0.51
Train Epoch: 5 [181760/319902 (57%)] Loss: 0.033255, 1 batch cost time 0.51
Train Epoch: 5 [182272/319902 (57%)] Loss: 0.033336, 1 batch cost time 0.51
Train Epoch: 5 [182784/319902 (57%)] Loss: 0.025281, 1 batch cost time 0.51
Train Epoch: 5 [183296/319902 (57%)] Loss: 0.017444, 1 batch cost time 0.51
Train Epoch: 5 [183808/319902 (57%)] Loss: 0.027742, 1 batch cost time 0.51
Train Epoch: 5 [184320/319902 (58%)] Loss: 0.043744, 1 batch cost time 0.51
Train Epoch: 5 [184832/319902 (58%)] Loss: 0.023920, 1 batch cost time 0.51
Train Epoch: 5 [185344/319902 (58%)] Loss: 0.044950, 1 batch cost time 0.51
Train Epoch: 5 [185856/319902 (58%)] Loss: 0.050838, 1 batch cost time 0.51
Train Epoch: 5 [186368/319902 (58%)] Loss: 0.026796, 1 batch cost time 0.51
Train Epoch: 5 [186880/319902 (58%)] Loss: 0.017935, 1 batch cost time 0.51
Train Epoch: 5 [187392/319902 (59%)] Loss: 0.012793, 1 batch cost time 0.51
Train Epoch: 5 [187904/319902 (59%)] Loss: 0.026551, 1 batch cost time 0.51
Train Epoch: 5 [188416/319902 (59%)] Loss: 0.012661, 1 batch cost time 0.51
Train Epoch: 5 [188928/319902 (59%)] Loss: 0.018224, 1 batch cost time 0.51
Train Epoch: 5 [189440/319902 (59%)] Loss: 0.024734, 1 batch cost time 0.51
Train Epoch: 5 [189952/319902 (59%)] Loss: 0.035177, 1 batch cost time 0.51
Train Epoch: 5 [190464/319902 (60%)] Loss: 0.041075, 1 batch cost time 0.51
Train Epoch: 5 [190976/319902 (60%)] Loss: 0.018882, 1 batch cost time 0.51
Train Epoch: 5 [191488/319902 (60%)] Loss: 0.034776, 1 batch cost time 0.51
Train Epoch: 5 [192000/319902 (60%)] Loss: 0.050158, 1 batch cost time 0.51
Train Epoch: 5 [192512/319902 (60%)] Loss: 0.063803, 1 batch cost time 0.51
Train Epoch: 5 [193024/319902 (60%)] Loss: 0.044075, 1 batch cost time 0.51
Train Epoch: 5 [193536/319902 (60%)] Loss: 0.033911, 1 batch cost time 0.51
Train Epoch: 5 [194048/319902 (61%)] Loss: 0.052833, 1 batch cost time 0.51
Train Epoch: 5 [194560/319902 (61%)] Loss: 0.053883, 1 batch cost time 0.51
Train Epoch: 5 [195072/319902 (61%)] Loss: 0.033200, 1 batch cost time 0.51
Train Epoch: 5 [195584/319902 (61%)] Loss: 0.040033, 1 batch cost time 0.51
Train Epoch: 5 [196096/319902 (61%)] Loss: 0.012434, 1 batch cost time 0.51
Train Epoch: 5 [196608/319902 (61%)] Loss: 0.039624, 1 batch cost time 0.51
Train Epoch: 5 [197120/319902 (62%)] Loss: 0.029762, 1 batch cost time 0.51
Train Epoch: 5 [197632/319902 (62%)] Loss: 0.024834, 1 batch cost time 0.51
Train Epoch: 5 [198144/319902 (62%)] Loss: 0.025629, 1 batch cost time 0.51
Train Epoch: 5 [198656/319902 (62%)] Loss: 0.036136, 1 batch cost time 0.51
Train Epoch: 5 [199168/319902 (62%)] Loss: 0.035450, 1 batch cost time 0.51
Train Epoch: 5 [199680/319902 (62%)] Loss: 0.009760, 1 batch cost time 0.51
Train Epoch: 5 [200192/319902 (63%)] Loss: 0.018267, 1 batch cost time 0.51
Train Epoch: 5 [200704/319902 (63%)] Loss: 0.015288, 1 batch cost time 0.51
Train Epoch: 5 [201216/319902 (63%)] Loss: 0.041231, 1 batch cost time 0.51
Train Epoch: 5 [201728/319902 (63%)] Loss: 0.024421, 1 batch cost time 0.51
Train Epoch: 5 [202240/319902 (63%)] Loss: 0.023964, 1 batch cost time 0.51
Train Epoch: 5 [202752/319902 (63%)] Loss: 0.028908, 1 batch cost time 0.51
Train Epoch: 5 [203264/319902 (64%)] Loss: 0.025946, 1 batch cost time 0.51
Train Epoch: 5 [203776/319902 (64%)] Loss: 0.025460, 1 batch cost time 0.51
Train Epoch: 5 [204288/319902 (64%)] Loss: 0.040965, 1 batch cost time 0.51
Train Epoch: 5 [204800/319902 (64%)] Loss: 0.029594, 1 batch cost time 0.51
Train Epoch: 5 [205312/319902 (64%)] Loss: 0.008637, 1 batch cost time 0.51
Train Epoch: 5 [205824/319902 (64%)] Loss: 0.041783, 1 batch cost time 0.51
Train Epoch: 5 [206336/319902 (64%)] Loss: 0.032748, 1 batch cost time 0.51
Train Epoch: 5 [206848/319902 (65%)] Loss: 0.029763, 1 batch cost time 0.51
Train Epoch: 5 [207360/319902 (65%)] Loss: 0.039766, 1 batch cost time 0.51
Train Epoch: 5 [207872/319902 (65%)] Loss: 0.032607, 1 batch cost time 0.51
Train Epoch: 5 [208384/319902 (65%)] Loss: 0.048955, 1 batch cost time 0.51
Train Epoch: 5 [208896/319902 (65%)] Loss: 0.069995, 1 batch cost time 0.51
Train Epoch: 5 [209408/319902 (65%)] Loss: 0.058996, 1 batch cost time 0.51
Train Epoch: 5 [209920/319902 (66%)] Loss: 0.014604, 1 batch cost time 0.51
Train Epoch: 5 [210432/319902 (66%)] Loss: 0.027280, 1 batch cost time 0.51
Train Epoch: 5 [210944/319902 (66%)] Loss: 0.041540, 1 batch cost time 0.51
Train Epoch: 5 [211456/319902 (66%)] Loss: 0.018215, 1 batch cost time 0.51
Train Epoch: 5 [211968/319902 (66%)] Loss: 0.031833, 1 batch cost time 0.51
Train Epoch: 5 [212480/319902 (66%)] Loss: 0.039057, 1 batch cost time 0.51
Train Epoch: 5 [212992/319902 (67%)] Loss: 0.039575, 1 batch cost time 0.51
Train Epoch: 5 [213504/319902 (67%)] Loss: 0.031933, 1 batch cost time 0.51
Train Epoch: 5 [214016/319902 (67%)] Loss: 0.026059, 1 batch cost time 0.51
Train Epoch: 5 [214528/319902 (67%)] Loss: 0.052039, 1 batch cost time 0.51
Train Epoch: 5 [215040/319902 (67%)] Loss: 0.030864, 1 batch cost time 0.51
Train Epoch: 5 [215552/319902 (67%)] Loss: 0.027307, 1 batch cost time 0.51
Train Epoch: 5 [216064/319902 (68%)] Loss: 0.031965, 1 batch cost time 0.51
Train Epoch: 5 [216576/319902 (68%)] Loss: 0.018801, 1 batch cost time 0.51
Train Epoch: 5 [217088/319902 (68%)] Loss: 0.019958, 1 batch cost time 0.51
Train Epoch: 5 [217600/319902 (68%)] Loss: 0.028765, 1 batch cost time 0.51
Train Epoch: 5 [218112/319902 (68%)] Loss: 0.023249, 1 batch cost time 0.51
Train Epoch: 5 [218624/319902 (68%)] Loss: 0.020264, 1 batch cost time 0.51
Train Epoch: 5 [219136/319902 (69%)] Loss: 0.034769, 1 batch cost time 0.51
Train Epoch: 5 [219648/319902 (69%)] Loss: 0.066413, 1 batch cost time 0.51
Train Epoch: 5 [220160/319902 (69%)] Loss: 0.017946, 1 batch cost time 0.51
Train Epoch: 5 [220672/319902 (69%)] Loss: 0.025039, 1 batch cost time 0.51
Train Epoch: 5 [221184/319902 (69%)] Loss: 0.018202, 1 batch cost time 0.51
Train Epoch: 5 [221696/319902 (69%)] Loss: 0.014429, 1 batch cost time 0.51
Train Epoch: 5 [222208/319902 (69%)] Loss: 0.025254, 1 batch cost time 0.51
Train Epoch: 5 [222720/319902 (70%)] Loss: 0.039785, 1 batch cost time 0.51
Train Epoch: 5 [223232/319902 (70%)] Loss: 0.022368, 1 batch cost time 0.51
Train Epoch: 5 [223744/319902 (70%)] Loss: 0.016279, 1 batch cost time 0.51
Train Epoch: 5 [224256/319902 (70%)] Loss: 0.042739, 1 batch cost time 0.51
Train Epoch: 5 [224768/319902 (70%)] Loss: 0.028889, 1 batch cost time 0.51
Train Epoch: 5 [225280/319902 (70%)] Loss: 0.020882, 1 batch cost time 0.51
Train Epoch: 5 [225792/319902 (71%)] Loss: 0.021705, 1 batch cost time 0.51
Train Epoch: 5 [226304/319902 (71%)] Loss: 0.049664, 1 batch cost time 0.51
Train Epoch: 5 [226816/319902 (71%)] Loss: 0.029605, 1 batch cost time 0.51
Train Epoch: 5 [227328/319902 (71%)] Loss: 0.026843, 1 batch cost time 0.51
Train Epoch: 5 [227840/319902 (71%)] Loss: 0.023077, 1 batch cost time 0.51
Train Epoch: 5 [228352/319902 (71%)] Loss: 0.024629, 1 batch cost time 0.51
Train Epoch: 5 [228864/319902 (72%)] Loss: 0.023184, 1 batch cost time 0.51
Train Epoch: 5 [229376/319902 (72%)] Loss: 0.028044, 1 batch cost time 0.51
Train Epoch: 5 [229888/319902 (72%)] Loss: 0.056136, 1 batch cost time 0.51
Train Epoch: 5 [230400/319902 (72%)] Loss: 0.037055, 1 batch cost time 0.51
Train Epoch: 5 [230912/319902 (72%)] Loss: 0.020510, 1 batch cost time 0.51
Train Epoch: 5 [231424/319902 (72%)] Loss: 0.107431, 1 batch cost time 0.51
Train Epoch: 5 [231936/319902 (73%)] Loss: 0.032092, 1 batch cost time 0.51
Train Epoch: 5 [232448/319902 (73%)] Loss: 0.038915, 1 batch cost time 0.51
Train Epoch: 5 [232960/319902 (73%)] Loss: 0.044321, 1 batch cost time 0.51
Train Epoch: 5 [233472/319902 (73%)] Loss: 0.030485, 1 batch cost time 0.51
Train Epoch: 5 [233984/319902 (73%)] Loss: 0.032398, 1 batch cost time 0.51
Train Epoch: 5 [234496/319902 (73%)] Loss: 0.028193, 1 batch cost time 0.51
Train Epoch: 5 [235008/319902 (73%)] Loss: 0.038296, 1 batch cost time 0.51
Train Epoch: 5 [235520/319902 (74%)] Loss: 0.039649, 1 batch cost time 0.51
Train Epoch: 5 [236032/319902 (74%)] Loss: 0.059982, 1 batch cost time 0.51
Train Epoch: 5 [236544/319902 (74%)] Loss: 0.083879, 1 batch cost time 0.51
Train Epoch: 5 [237056/319902 (74%)] Loss: 0.024286, 1 batch cost time 0.51
Train Epoch: 5 [237568/319902 (74%)] Loss: 0.032639, 1 batch cost time 0.51
Train Epoch: 5 [238080/319902 (74%)] Loss: 0.027506, 1 batch cost time 0.51
Train Epoch: 5 [238592/319902 (75%)] Loss: 0.063150, 1 batch cost time 0.51
Train Epoch: 5 [239104/319902 (75%)] Loss: 0.027072, 1 batch cost time 0.51
Train Epoch: 5 [239616/319902 (75%)] Loss: 0.038865, 1 batch cost time 0.51
Train Epoch: 5 [240128/319902 (75%)] Loss: 0.054768, 1 batch cost time 0.51
Train Epoch: 5 [240640/319902 (75%)] Loss: 0.050485, 1 batch cost time 0.51
Train Epoch: 5 [241152/319902 (75%)] Loss: 0.020081, 1 batch cost time 0.51
Train Epoch: 5 [241664/319902 (76%)] Loss: 0.033715, 1 batch cost time 0.51
Train Epoch: 5 [242176/319902 (76%)] Loss: 0.049496, 1 batch cost time 0.51
Train Epoch: 5 [242688/319902 (76%)] Loss: 0.031736, 1 batch cost time 0.51
Train Epoch: 5 [243200/319902 (76%)] Loss: 0.026967, 1 batch cost time 0.51
Train Epoch: 5 [243712/319902 (76%)] Loss: 0.019362, 1 batch cost time 0.51
Train Epoch: 5 [244224/319902 (76%)] Loss: 0.020246, 1 batch cost time 0.51
Train Epoch: 5 [244736/319902 (77%)] Loss: 0.048502, 1 batch cost time 0.51
Train Epoch: 5 [245248/319902 (77%)] Loss: 0.015770, 1 batch cost time 0.51
Train Epoch: 5 [245760/319902 (77%)] Loss: 0.014927, 1 batch cost time 0.51
Train Epoch: 5 [246272/319902 (77%)] Loss: 0.025786, 1 batch cost time 0.51
Train Epoch: 5 [246784/319902 (77%)] Loss: 0.036873, 1 batch cost time 0.51
Train Epoch: 5 [247296/319902 (77%)] Loss: 0.050539, 1 batch cost time 0.51
Train Epoch: 5 [247808/319902 (77%)] Loss: 0.032629, 1 batch cost time 0.51
Train Epoch: 5 [248320/319902 (78%)] Loss: 0.018538, 1 batch cost time 0.51
Train Epoch: 5 [248832/319902 (78%)] Loss: 0.051841, 1 batch cost time 0.51
Train Epoch: 5 [249344/319902 (78%)] Loss: 0.043098, 1 batch cost time 0.51
Train Epoch: 5 [249856/319902 (78%)] Loss: 0.047922, 1 batch cost time 0.51
Train Epoch: 5 [250368/319902 (78%)] Loss: 0.044136, 1 batch cost time 0.51
Train Epoch: 5 [250880/319902 (78%)] Loss: 0.042642, 1 batch cost time 0.51
Train Epoch: 5 [251392/319902 (79%)] Loss: 0.019833, 1 batch cost time 0.51
Train Epoch: 5 [251904/319902 (79%)] Loss: 0.042010, 1 batch cost time 0.51
Train Epoch: 5 [252416/319902 (79%)] Loss: 0.032162, 1 batch cost time 0.51
Train Epoch: 5 [252928/319902 (79%)] Loss: 0.038601, 1 batch cost time 0.51
Train Epoch: 5 [253440/319902 (79%)] Loss: 0.059625, 1 batch cost time 0.51
Train Epoch: 5 [253952/319902 (79%)] Loss: 0.035344, 1 batch cost time 0.51
Train Epoch: 5 [254464/319902 (80%)] Loss: 0.027889, 1 batch cost time 0.51
Train Epoch: 5 [254976/319902 (80%)] Loss: 0.010615, 1 batch cost time 0.51
Train Epoch: 5 [255488/319902 (80%)] Loss: 0.046533, 1 batch cost time 0.51
Train Epoch: 5 [256000/319902 (80%)] Loss: 0.047883, 1 batch cost time 0.51
Train Epoch: 5 [256512/319902 (80%)] Loss: 0.027553, 1 batch cost time 0.51
Train Epoch: 5 [257024/319902 (80%)] Loss: 0.029879, 1 batch cost time 0.51
Train Epoch: 5 [257536/319902 (81%)] Loss: 0.021146, 1 batch cost time 0.51
Train Epoch: 5 [258048/319902 (81%)] Loss: 0.032267, 1 batch cost time 0.51
Train Epoch: 5 [258560/319902 (81%)] Loss: 0.041281, 1 batch cost time 0.51
Train Epoch: 5 [259072/319902 (81%)] Loss: 0.028577, 1 batch cost time 0.51
Train Epoch: 5 [259584/319902 (81%)] Loss: 0.026399, 1 batch cost time 0.51
Train Epoch: 5 [260096/319902 (81%)] Loss: 0.022110, 1 batch cost time 0.51
Train Epoch: 5 [260608/319902 (81%)] Loss: 0.041726, 1 batch cost time 0.51
Train Epoch: 5 [261120/319902 (82%)] Loss: 0.017132, 1 batch cost time 0.51
Train Epoch: 5 [261632/319902 (82%)] Loss: 0.061076, 1 batch cost time 0.51
Train Epoch: 5 [262144/319902 (82%)] Loss: 0.045357, 1 batch cost time 0.51
Train Epoch: 5 [262656/319902 (82%)] Loss: 0.037722, 1 batch cost time 0.51
Train Epoch: 5 [263168/319902 (82%)] Loss: 0.025426, 1 batch cost time 0.51
Train Epoch: 5 [263680/319902 (82%)] Loss: 0.033060, 1 batch cost time 0.51
Train Epoch: 5 [264192/319902 (83%)] Loss: 0.027652, 1 batch cost time 0.51
Train Epoch: 5 [264704/319902 (83%)] Loss: 0.025536, 1 batch cost time 0.51
Train Epoch: 5 [265216/319902 (83%)] Loss: 0.033118, 1 batch cost time 0.51
Train Epoch: 5 [265728/319902 (83%)] Loss: 0.064174, 1 batch cost time 0.51
Train Epoch: 5 [266240/319902 (83%)] Loss: 0.022816, 1 batch cost time 0.51
Train Epoch: 5 [266752/319902 (83%)] Loss: 0.024960, 1 batch cost time 0.51
Train Epoch: 5 [267264/319902 (84%)] Loss: 0.053550, 1 batch cost time 0.51
Train Epoch: 5 [267776/319902 (84%)] Loss: 0.028657, 1 batch cost time 0.51
Train Epoch: 5 [268288/319902 (84%)] Loss: 0.045412, 1 batch cost time 0.51
Train Epoch: 5 [268800/319902 (84%)] Loss: 0.038972, 1 batch cost time 0.51
Train Epoch: 5 [269312/319902 (84%)] Loss: 0.045066, 1 batch cost time 0.51
Train Epoch: 5 [269824/319902 (84%)] Loss: 0.013075, 1 batch cost time 0.51
Train Epoch: 5 [270336/319902 (85%)] Loss: 0.032178, 1 batch cost time 0.51
Train Epoch: 5 [270848/319902 (85%)] Loss: 0.030563, 1 batch cost time 0.51
Train Epoch: 5 [271360/319902 (85%)] Loss: 0.025635, 1 batch cost time 0.51
Train Epoch: 5 [271872/319902 (85%)] Loss: 0.026490, 1 batch cost time 0.51
Train Epoch: 5 [272384/319902 (85%)] Loss: 0.017474, 1 batch cost time 0.51
Train Epoch: 5 [272896/319902 (85%)] Loss: 0.030837, 1 batch cost time 0.51
Train Epoch: 5 [273408/319902 (85%)] Loss: 0.032339, 1 batch cost time 0.51
Train Epoch: 5 [273920/319902 (86%)] Loss: 0.032284, 1 batch cost time 0.51
Train Epoch: 5 [274432/319902 (86%)] Loss: 0.039119, 1 batch cost time 0.51
Train Epoch: 5 [274944/319902 (86%)] Loss: 0.024735, 1 batch cost time 0.51
Train Epoch: 5 [275456/319902 (86%)] Loss: 0.033577, 1 batch cost time 0.51
Train Epoch: 5 [275968/319902 (86%)] Loss: 0.049272, 1 batch cost time 0.51
Train Epoch: 5 [276480/319902 (86%)] Loss: 0.047613, 1 batch cost time 0.51
Train Epoch: 5 [276992/319902 (87%)] Loss: 0.013540, 1 batch cost time 0.51
Train Epoch: 5 [277504/319902 (87%)] Loss: 0.031841, 1 batch cost time 0.51
Train Epoch: 5 [278016/319902 (87%)] Loss: 0.024316, 1 batch cost time 0.51
Train Epoch: 5 [278528/319902 (87%)] Loss: 0.044209, 1 batch cost time 0.51
Train Epoch: 5 [279040/319902 (87%)] Loss: 0.011013, 1 batch cost time 0.51
Train Epoch: 5 [279552/319902 (87%)] Loss: 0.041596, 1 batch cost time 0.51
Train Epoch: 5 [280064/319902 (88%)] Loss: 0.025871, 1 batch cost time 0.51
Train Epoch: 5 [280576/319902 (88%)] Loss: 0.034009, 1 batch cost time 0.51
Train Epoch: 5 [281088/319902 (88%)] Loss: 0.056366, 1 batch cost time 0.51
Train Epoch: 5 [281600/319902 (88%)] Loss: 0.018608, 1 batch cost time 0.51
Train Epoch: 5 [282112/319902 (88%)] Loss: 0.040511, 1 batch cost time 0.51
Train Epoch: 5 [282624/319902 (88%)] Loss: 0.020254, 1 batch cost time 0.51
Train Epoch: 5 [283136/319902 (89%)] Loss: 0.037142, 1 batch cost time 0.51
Train Epoch: 5 [283648/319902 (89%)] Loss: 0.023762, 1 batch cost time 0.51
Train Epoch: 5 [284160/319902 (89%)] Loss: 0.036691, 1 batch cost time 0.51
Train Epoch: 5 [284672/319902 (89%)] Loss: 0.034570, 1 batch cost time 0.51
Train Epoch: 5 [285184/319902 (89%)] Loss: 0.047765, 1 batch cost time 0.51
Train Epoch: 5 [285696/319902 (89%)] Loss: 0.053799, 1 batch cost time 0.51
Train Epoch: 5 [286208/319902 (89%)] Loss: 0.033607, 1 batch cost time 0.51
Train Epoch: 5 [286720/319902 (90%)] Loss: 0.088010, 1 batch cost time 0.51
Train Epoch: 5 [287232/319902 (90%)] Loss: 0.043900, 1 batch cost time 0.51
Train Epoch: 5 [287744/319902 (90%)] Loss: 0.037509, 1 batch cost time 0.51
Train Epoch: 5 [288256/319902 (90%)] Loss: 0.024456, 1 batch cost time 0.51
Train Epoch: 5 [288768/319902 (90%)] Loss: 0.059526, 1 batch cost time 0.51
Train Epoch: 5 [289280/319902 (90%)] Loss: 0.050426, 1 batch cost time 0.51
Train Epoch: 5 [289792/319902 (91%)] Loss: 0.012820, 1 batch cost time 0.51
Train Epoch: 5 [290304/319902 (91%)] Loss: 0.021427, 1 batch cost time 0.51
Train Epoch: 5 [290816/319902 (91%)] Loss: 0.030453, 1 batch cost time 0.51
Train Epoch: 5 [291328/319902 (91%)] Loss: 0.029598, 1 batch cost time 0.51
Train Epoch: 5 [291840/319902 (91%)] Loss: 0.035774, 1 batch cost time 0.51
Train Epoch: 5 [292352/319902 (91%)] Loss: 0.051521, 1 batch cost time 0.51
Train Epoch: 5 [292864/319902 (92%)] Loss: 0.027967, 1 batch cost time 0.51
Train Epoch: 5 [293376/319902 (92%)] Loss: 0.024442, 1 batch cost time 0.51
Train Epoch: 5 [293888/319902 (92%)] Loss: 0.054797, 1 batch cost time 0.51
Train Epoch: 5 [294400/319902 (92%)] Loss: 0.035781, 1 batch cost time 0.51
Train Epoch: 5 [294912/319902 (92%)] Loss: 0.045160, 1 batch cost time 0.51
Train Epoch: 5 [295424/319902 (92%)] Loss: 0.029730, 1 batch cost time 0.51
Train Epoch: 5 [295936/319902 (93%)] Loss: 0.019524, 1 batch cost time 0.51
Train Epoch: 5 [296448/319902 (93%)] Loss: 0.031107, 1 batch cost time 0.51
Train Epoch: 5 [296960/319902 (93%)] Loss: 0.035267, 1 batch cost time 0.51
Train Epoch: 5 [297472/319902 (93%)] Loss: 0.031766, 1 batch cost time 0.51
Train Epoch: 5 [297984/319902 (93%)] Loss: 0.032037, 1 batch cost time 0.51
Train Epoch: 5 [298496/319902 (93%)] Loss: 0.030818, 1 batch cost time 0.51
Train Epoch: 5 [299008/319902 (93%)] Loss: 0.025079, 1 batch cost time 0.51
Train Epoch: 5 [299520/319902 (94%)] Loss: 0.023972, 1 batch cost time 0.51
Train Epoch: 5 [300032/319902 (94%)] Loss: 0.035685, 1 batch cost time 0.51
Train Epoch: 5 [300544/319902 (94%)] Loss: 0.018171, 1 batch cost time 0.51
Train Epoch: 5 [301056/319902 (94%)] Loss: 0.031049, 1 batch cost time 0.51
Train Epoch: 5 [301568/319902 (94%)] Loss: 0.040665, 1 batch cost time 0.51
Train Epoch: 5 [302080/319902 (94%)] Loss: 0.038682, 1 batch cost time 0.51
Train Epoch: 5 [302592/319902 (95%)] Loss: 0.022672, 1 batch cost time 0.51
Train Epoch: 5 [303104/319902 (95%)] Loss: 0.024424, 1 batch cost time 0.51
Train Epoch: 5 [303616/319902 (95%)] Loss: 0.017680, 1 batch cost time 0.51
Train Epoch: 5 [304128/319902 (95%)] Loss: 0.014040, 1 batch cost time 0.51
Train Epoch: 5 [304640/319902 (95%)] Loss: 0.027755, 1 batch cost time 0.51
Train Epoch: 5 [305152/319902 (95%)] Loss: 0.014091, 1 batch cost time 0.51
Train Epoch: 5 [305664/319902 (96%)] Loss: 0.049909, 1 batch cost time 0.51
Train Epoch: 5 [306176/319902 (96%)] Loss: 0.017448, 1 batch cost time 0.51
Train Epoch: 5 [306688/319902 (96%)] Loss: 0.056559, 1 batch cost time 0.51
Train Epoch: 5 [307200/319902 (96%)] Loss: 0.033221, 1 batch cost time 0.51
Train Epoch: 5 [307712/319902 (96%)] Loss: 0.026203, 1 batch cost time 0.51
Train Epoch: 5 [308224/319902 (96%)] Loss: 0.033748, 1 batch cost time 0.51
Train Epoch: 5 [308736/319902 (97%)] Loss: 0.021749, 1 batch cost time 0.51
Train Epoch: 5 [309248/319902 (97%)] Loss: 0.024084, 1 batch cost time 0.51
Train Epoch: 5 [309760/319902 (97%)] Loss: 0.045879, 1 batch cost time 0.51
Train Epoch: 5 [310272/319902 (97%)] Loss: 0.038236, 1 batch cost time 0.51
Train Epoch: 5 [310784/319902 (97%)] Loss: 0.018836, 1 batch cost time 0.51
Train Epoch: 5 [311296/319902 (97%)] Loss: 0.025479, 1 batch cost time 0.51
Train Epoch: 5 [311808/319902 (97%)] Loss: 0.037670, 1 batch cost time 0.51
Train Epoch: 5 [312320/319902 (98%)] Loss: 0.037010, 1 batch cost time 0.51
Train Epoch: 5 [312832/319902 (98%)] Loss: 0.024878, 1 batch cost time 0.51
Train Epoch: 5 [313344/319902 (98%)] Loss: 0.039283, 1 batch cost time 0.51
Train Epoch: 5 [313856/319902 (98%)] Loss: 0.011324, 1 batch cost time 0.51
Train Epoch: 5 [314368/319902 (98%)] Loss: 0.025137, 1 batch cost time 0.51
Train Epoch: 5 [314880/319902 (98%)] Loss: 0.029236, 1 batch cost time 0.51
Train Epoch: 5 [315392/319902 (99%)] Loss: 0.025298, 1 batch cost time 0.51
Train Epoch: 5 [315904/319902 (99%)] Loss: 0.046332, 1 batch cost time 0.51
Train Epoch: 5 [316416/319902 (99%)] Loss: 0.021359, 1 batch cost time 0.51
Train Epoch: 5 [316928/319902 (99%)] Loss: 0.069972, 1 batch cost time 0.51
Train Epoch: 5 [317440/319902 (99%)] Loss: 0.039496, 1 batch cost time 0.51
Train Epoch: 5 [317952/319902 (99%)] Loss: 0.053959, 1 batch cost time 0.51
Train Epoch: 5 [318464/319902 (100%)] Loss: 0.024998, 1 batch cost time 0.51
Train Epoch: 5 [318976/319902 (100%)] Loss: 0.015066, 1 batch cost time 0.51
Train Epoch: 5 [319488/319902 (100%)] Loss: 0.048371, 1 batch cost time 0.51
training epoch cost 7989.552459716797 seconds
    epoch          : 5
    lr             : 0.0001
    loss           : 0.03293288884037474
    accuracy       : 0.9289590836334534
    f_measure      : 0.5249673284475599
    val_loss       : 0.025754425177486457
    val_accuracy   : 0.9420572916666666
    val_f_measure  : 0.537457768408289
Saving current best: model_best.pth ...
Train Epoch: 6 [0/319902 (0%)] Loss: 0.018824, 1 batch cost time 0.53
Train Epoch: 6 [512/319902 (0%)] Loss: 0.032801, 1 batch cost time 0.51
Train Epoch: 6 [1024/319902 (0%)] Loss: 0.027599, 1 batch cost time 0.51
Train Epoch: 6 [1536/319902 (0%)] Loss: 0.060729, 1 batch cost time 0.51
Train Epoch: 6 [2048/319902 (1%)] Loss: 0.016549, 1 batch cost time 0.51
Train Epoch: 6 [2560/319902 (1%)] Loss: 0.026413, 1 batch cost time 0.51
Train Epoch: 6 [3072/319902 (1%)] Loss: 0.039335, 1 batch cost time 0.51
Train Epoch: 6 [3584/319902 (1%)] Loss: 0.027721, 1 batch cost time 0.51
Train Epoch: 6 [4096/319902 (1%)] Loss: 0.009868, 1 batch cost time 0.51
Train Epoch: 6 [4608/319902 (1%)] Loss: 0.016053, 1 batch cost time 0.51
Train Epoch: 6 [5120/319902 (2%)] Loss: 0.044352, 1 batch cost time 0.51
Train Epoch: 6 [5632/319902 (2%)] Loss: 0.055376, 1 batch cost time 0.51
Train Epoch: 6 [6144/319902 (2%)] Loss: 0.021864, 1 batch cost time 0.51
Train Epoch: 6 [6656/319902 (2%)] Loss: 0.020806, 1 batch cost time 0.51
Train Epoch: 6 [7168/319902 (2%)] Loss: 0.033285, 1 batch cost time 0.51
Train Epoch: 6 [7680/319902 (2%)] Loss: 0.017215, 1 batch cost time 0.51
Train Epoch: 6 [8192/319902 (3%)] Loss: 0.035388, 1 batch cost time 0.51
Train Epoch: 6 [8704/319902 (3%)] Loss: 0.035725, 1 batch cost time 0.51
Train Epoch: 6 [9216/319902 (3%)] Loss: 0.053836, 1 batch cost time 0.51
Train Epoch: 6 [9728/319902 (3%)] Loss: 0.014846, 1 batch cost time 0.51
Train Epoch: 6 [10240/319902 (3%)] Loss: 0.047965, 1 batch cost time 0.51
Train Epoch: 6 [10752/319902 (3%)] Loss: 0.058298, 1 batch cost time 0.51
Train Epoch: 6 [11264/319902 (4%)] Loss: 0.013016, 1 batch cost time 0.51
Train Epoch: 6 [11776/319902 (4%)] Loss: 0.036287, 1 batch cost time 0.51
Train Epoch: 6 [12288/319902 (4%)] Loss: 0.035261, 1 batch cost time 0.51
Train Epoch: 6 [12800/319902 (4%)] Loss: 0.029277, 1 batch cost time 0.51
Train Epoch: 6 [13312/319902 (4%)] Loss: 0.037599, 1 batch cost time 0.51
Train Epoch: 6 [13824/319902 (4%)] Loss: 0.028087, 1 batch cost time 0.51
Train Epoch: 6 [14336/319902 (4%)] Loss: 0.062174, 1 batch cost time 0.51
Train Epoch: 6 [14848/319902 (5%)] Loss: 0.034442, 1 batch cost time 0.51
Train Epoch: 6 [15360/319902 (5%)] Loss: 0.060278, 1 batch cost time 0.51
Train Epoch: 6 [15872/319902 (5%)] Loss: 0.026152, 1 batch cost time 0.51
Train Epoch: 6 [16384/319902 (5%)] Loss: 0.043554, 1 batch cost time 0.51
Train Epoch: 6 [16896/319902 (5%)] Loss: 0.045409, 1 batch cost time 0.51
Train Epoch: 6 [17408/319902 (5%)] Loss: 0.039308, 1 batch cost time 0.51
Train Epoch: 6 [17920/319902 (6%)] Loss: 0.036359, 1 batch cost time 0.51
Train Epoch: 6 [18432/319902 (6%)] Loss: 0.074610, 1 batch cost time 0.51
Train Epoch: 6 [18944/319902 (6%)] Loss: 0.026537, 1 batch cost time 0.51
Train Epoch: 6 [19456/319902 (6%)] Loss: 0.019204, 1 batch cost time 0.51
Train Epoch: 6 [19968/319902 (6%)] Loss: 0.012782, 1 batch cost time 0.51
Train Epoch: 6 [20480/319902 (6%)] Loss: 0.007865, 1 batch cost time 0.51
Train Epoch: 6 [20992/319902 (7%)] Loss: 0.024753, 1 batch cost time 0.51
Train Epoch: 6 [21504/319902 (7%)] Loss: 0.011772, 1 batch cost time 0.51
Train Epoch: 6 [22016/319902 (7%)] Loss: 0.014816, 1 batch cost time 0.51
Train Epoch: 6 [22528/319902 (7%)] Loss: 0.035057, 1 batch cost time 0.51
Train Epoch: 6 [23040/319902 (7%)] Loss: 0.026252, 1 batch cost time 0.51
Train Epoch: 6 [23552/319902 (7%)] Loss: 0.025947, 1 batch cost time 0.51
Train Epoch: 6 [24064/319902 (8%)] Loss: 0.019773, 1 batch cost time 0.51
Train Epoch: 6 [24576/319902 (8%)] Loss: 0.010967, 1 batch cost time 0.51
Train Epoch: 6 [25088/319902 (8%)] Loss: 0.053321, 1 batch cost time 0.51
Train Epoch: 6 [25600/319902 (8%)] Loss: 0.007212, 1 batch cost time 0.51
Train Epoch: 6 [26112/319902 (8%)] Loss: 0.030438, 1 batch cost time 0.51
Train Epoch: 6 [26624/319902 (8%)] Loss: 0.016712, 1 batch cost time 0.51
Train Epoch: 6 [27136/319902 (8%)] Loss: 0.029201, 1 batch cost time 0.51
Train Epoch: 6 [27648/319902 (9%)] Loss: 0.023408, 1 batch cost time 0.51
Train Epoch: 6 [28160/319902 (9%)] Loss: 0.026907, 1 batch cost time 0.51
Train Epoch: 6 [28672/319902 (9%)] Loss: 0.025970, 1 batch cost time 0.51
Train Epoch: 6 [29184/319902 (9%)] Loss: 0.038839, 1 batch cost time 0.51
Train Epoch: 6 [29696/319902 (9%)] Loss: 0.033688, 1 batch cost time 0.51
Train Epoch: 6 [30208/319902 (9%)] Loss: 0.022584, 1 batch cost time 0.51
Train Epoch: 6 [30720/319902 (10%)] Loss: 0.040414, 1 batch cost time 0.51
Train Epoch: 6 [31232/319902 (10%)] Loss: 0.041478, 1 batch cost time 0.51
Train Epoch: 6 [31744/319902 (10%)] Loss: 0.021813, 1 batch cost time 0.51
Train Epoch: 6 [32256/319902 (10%)] Loss: 0.025235, 1 batch cost time 0.51
Train Epoch: 6 [32768/319902 (10%)] Loss: 0.016621, 1 batch cost time 0.51
Train Epoch: 6 [33280/319902 (10%)] Loss: 0.008053, 1 batch cost time 0.51
Train Epoch: 6 [33792/319902 (11%)] Loss: 0.035131, 1 batch cost time 0.51
Train Epoch: 6 [34304/319902 (11%)] Loss: 0.024954, 1 batch cost time 0.51
Train Epoch: 6 [34816/319902 (11%)] Loss: 0.028701, 1 batch cost time 0.51
Train Epoch: 6 [35328/319902 (11%)] Loss: 0.045257, 1 batch cost time 0.51
Train Epoch: 6 [35840/319902 (11%)] Loss: 0.012762, 1 batch cost time 0.51
Train Epoch: 6 [36352/319902 (11%)] Loss: 0.059503, 1 batch cost time 0.51
Train Epoch: 6 [36864/319902 (12%)] Loss: 0.021378, 1 batch cost time 0.51
Train Epoch: 6 [37376/319902 (12%)] Loss: 0.027965, 1 batch cost time 0.51
Train Epoch: 6 [37888/319902 (12%)] Loss: 0.040329, 1 batch cost time 0.51
Train Epoch: 6 [38400/319902 (12%)] Loss: 0.023805, 1 batch cost time 0.51
Train Epoch: 6 [38912/319902 (12%)] Loss: 0.025849, 1 batch cost time 0.51
Train Epoch: 6 [39424/319902 (12%)] Loss: 0.020742, 1 batch cost time 0.51
Train Epoch: 6 [39936/319902 (12%)] Loss: 0.024060, 1 batch cost time 0.51
Train Epoch: 6 [40448/319902 (13%)] Loss: 0.028076, 1 batch cost time 0.51
Train Epoch: 6 [40960/319902 (13%)] Loss: 0.073644, 1 batch cost time 0.51
Train Epoch: 6 [41472/319902 (13%)] Loss: 0.048258, 1 batch cost time 0.51
Train Epoch: 6 [41984/319902 (13%)] Loss: 0.012497, 1 batch cost time 0.51
Train Epoch: 6 [42496/319902 (13%)] Loss: 0.025364, 1 batch cost time 0.51
Train Epoch: 6 [43008/319902 (13%)] Loss: 0.024443, 1 batch cost time 0.51
Train Epoch: 6 [43520/319902 (14%)] Loss: 0.043906, 1 batch cost time 0.51
Train Epoch: 6 [44032/319902 (14%)] Loss: 0.038966, 1 batch cost time 0.51
Train Epoch: 6 [44544/319902 (14%)] Loss: 0.035437, 1 batch cost time 0.51
Train Epoch: 6 [45056/319902 (14%)] Loss: 0.025904, 1 batch cost time 0.51
Train Epoch: 6 [45568/319902 (14%)] Loss: 0.025094, 1 batch cost time 0.51
Train Epoch: 6 [46080/319902 (14%)] Loss: 0.032337, 1 batch cost time 0.51
Train Epoch: 6 [46592/319902 (15%)] Loss: 0.043201, 1 batch cost time 0.51
Train Epoch: 6 [47104/319902 (15%)] Loss: 0.036245, 1 batch cost time 0.51
Train Epoch: 6 [47616/319902 (15%)] Loss: 0.034282, 1 batch cost time 0.51
Train Epoch: 6 [48128/319902 (15%)] Loss: 0.061599, 1 batch cost time 0.51
Train Epoch: 6 [48640/319902 (15%)] Loss: 0.018067, 1 batch cost time 0.51
Train Epoch: 6 [49152/319902 (15%)] Loss: 0.061665, 1 batch cost time 0.51
Train Epoch: 6 [49664/319902 (16%)] Loss: 0.061032, 1 batch cost time 0.51
Train Epoch: 6 [50176/319902 (16%)] Loss: 0.019730, 1 batch cost time 0.51
Train Epoch: 6 [50688/319902 (16%)] Loss: 0.031220, 1 batch cost time 0.51
Train Epoch: 6 [51200/319902 (16%)] Loss: 0.010907, 1 batch cost time 0.51
Train Epoch: 6 [51712/319902 (16%)] Loss: 0.042566, 1 batch cost time 0.51
Train Epoch: 6 [52224/319902 (16%)] Loss: 0.016977, 1 batch cost time 0.51
Train Epoch: 6 [52736/319902 (16%)] Loss: 0.055208, 1 batch cost time 0.51
Train Epoch: 6 [53248/319902 (17%)] Loss: 0.034896, 1 batch cost time 0.51
Train Epoch: 6 [53760/319902 (17%)] Loss: 0.029195, 1 batch cost time 0.51
Train Epoch: 6 [54272/319902 (17%)] Loss: 0.010556, 1 batch cost time 0.51
Train Epoch: 6 [54784/319902 (17%)] Loss: 0.024092, 1 batch cost time 0.51
Train Epoch: 6 [55296/319902 (17%)] Loss: 0.029338, 1 batch cost time 0.51
Train Epoch: 6 [55808/319902 (17%)] Loss: 0.038366, 1 batch cost time 0.51
Train Epoch: 6 [56320/319902 (18%)] Loss: 0.023928, 1 batch cost time 0.51
Train Epoch: 6 [56832/319902 (18%)] Loss: 0.030508, 1 batch cost time 0.51
Train Epoch: 6 [57344/319902 (18%)] Loss: 0.040760, 1 batch cost time 0.51
Train Epoch: 6 [57856/319902 (18%)] Loss: 0.031762, 1 batch cost time 0.51
Train Epoch: 6 [58368/319902 (18%)] Loss: 0.040019, 1 batch cost time 0.51
Train Epoch: 6 [58880/319902 (18%)] Loss: 0.024673, 1 batch cost time 0.51
Train Epoch: 6 [59392/319902 (19%)] Loss: 0.022735, 1 batch cost time 0.51
Train Epoch: 6 [59904/319902 (19%)] Loss: 0.038213, 1 batch cost time 0.51
Train Epoch: 6 [60416/319902 (19%)] Loss: 0.024887, 1 batch cost time 0.51
Train Epoch: 6 [60928/319902 (19%)] Loss: 0.014366, 1 batch cost time 0.51
Train Epoch: 6 [61440/319902 (19%)] Loss: 0.037167, 1 batch cost time 0.51
Train Epoch: 6 [61952/319902 (19%)] Loss: 0.042332, 1 batch cost time 0.51
Train Epoch: 6 [62464/319902 (20%)] Loss: 0.015873, 1 batch cost time 0.51
Train Epoch: 6 [62976/319902 (20%)] Loss: 0.058329, 1 batch cost time 0.51
Train Epoch: 6 [63488/319902 (20%)] Loss: 0.015431, 1 batch cost time 0.51
Train Epoch: 6 [64000/319902 (20%)] Loss: 0.017047, 1 batch cost time 0.51
Train Epoch: 6 [64512/319902 (20%)] Loss: 0.024787, 1 batch cost time 0.51
Train Epoch: 6 [65024/319902 (20%)] Loss: 0.027246, 1 batch cost time 0.51
Train Epoch: 6 [65536/319902 (20%)] Loss: 0.033052, 1 batch cost time 0.51
Train Epoch: 6 [66048/319902 (21%)] Loss: 0.037607, 1 batch cost time 0.51
Train Epoch: 6 [66560/319902 (21%)] Loss: 0.032306, 1 batch cost time 0.51
Train Epoch: 6 [67072/319902 (21%)] Loss: 0.034073, 1 batch cost time 0.51
Train Epoch: 6 [67584/319902 (21%)] Loss: 0.045903, 1 batch cost time 0.51
Train Epoch: 6 [68096/319902 (21%)] Loss: 0.039451, 1 batch cost time 0.51
Train Epoch: 6 [68608/319902 (21%)] Loss: 0.030992, 1 batch cost time 0.51
Train Epoch: 6 [69120/319902 (22%)] Loss: 0.035759, 1 batch cost time 0.51
Train Epoch: 6 [69632/319902 (22%)] Loss: 0.028358, 1 batch cost time 0.51
Train Epoch: 6 [70144/319902 (22%)] Loss: 0.028849, 1 batch cost time 0.51
Train Epoch: 6 [70656/319902 (22%)] Loss: 0.023578, 1 batch cost time 0.51
Train Epoch: 6 [71168/319902 (22%)] Loss: 0.044288, 1 batch cost time 0.51
Train Epoch: 6 [71680/319902 (22%)] Loss: 0.015533, 1 batch cost time 0.51
Train Epoch: 6 [72192/319902 (23%)] Loss: 0.023838, 1 batch cost time 0.51
Train Epoch: 6 [72704/319902 (23%)] Loss: 0.019815, 1 batch cost time 0.51
Train Epoch: 6 [73216/319902 (23%)] Loss: 0.073732, 1 batch cost time 0.51
Train Epoch: 6 [73728/319902 (23%)] Loss: 0.034454, 1 batch cost time 0.51
Train Epoch: 6 [74240/319902 (23%)] Loss: 0.026869, 1 batch cost time 0.51
Train Epoch: 6 [74752/319902 (23%)] Loss: 0.014362, 1 batch cost time 0.51
Train Epoch: 6 [75264/319902 (24%)] Loss: 0.022335, 1 batch cost time 0.51
Train Epoch: 6 [75776/319902 (24%)] Loss: 0.023041, 1 batch cost time 0.51
Train Epoch: 6 [76288/319902 (24%)] Loss: 0.019129, 1 batch cost time 0.51
Train Epoch: 6 [76800/319902 (24%)] Loss: 0.032176, 1 batch cost time 0.51
Train Epoch: 6 [77312/319902 (24%)] Loss: 0.030818, 1 batch cost time 0.51
Train Epoch: 6 [77824/319902 (24%)] Loss: 0.045473, 1 batch cost time 0.51
Train Epoch: 6 [78336/319902 (24%)] Loss: 0.052850, 1 batch cost time 0.51
Train Epoch: 6 [78848/319902 (25%)] Loss: 0.019793, 1 batch cost time 0.51
Train Epoch: 6 [79360/319902 (25%)] Loss: 0.028258, 1 batch cost time 0.51
Train Epoch: 6 [79872/319902 (25%)] Loss: 0.039244, 1 batch cost time 0.51
Train Epoch: 6 [80384/319902 (25%)] Loss: 0.032301, 1 batch cost time 0.51
Train Epoch: 6 [80896/319902 (25%)] Loss: 0.062718, 1 batch cost time 0.51
Train Epoch: 6 [81408/319902 (25%)] Loss: 0.030006, 1 batch cost time 0.51
Train Epoch: 6 [81920/319902 (26%)] Loss: 0.045845, 1 batch cost time 0.51
Train Epoch: 6 [82432/319902 (26%)] Loss: 0.042123, 1 batch cost time 0.51
Train Epoch: 6 [82944/319902 (26%)] Loss: 0.034258, 1 batch cost time 0.51
Train Epoch: 6 [83456/319902 (26%)] Loss: 0.021420, 1 batch cost time 0.51
Train Epoch: 6 [83968/319902 (26%)] Loss: 0.037707, 1 batch cost time 0.51
Train Epoch: 6 [84480/319902 (26%)] Loss: 0.049182, 1 batch cost time 0.51
Train Epoch: 6 [84992/319902 (27%)] Loss: 0.037451, 1 batch cost time 0.51
Train Epoch: 6 [85504/319902 (27%)] Loss: 0.026567, 1 batch cost time 0.51
Train Epoch: 6 [86016/319902 (27%)] Loss: 0.036677, 1 batch cost time 0.51
Train Epoch: 6 [86528/319902 (27%)] Loss: 0.054321, 1 batch cost time 0.51
Train Epoch: 6 [87040/319902 (27%)] Loss: 0.011761, 1 batch cost time 0.51
Train Epoch: 6 [87552/319902 (27%)] Loss: 0.018237, 1 batch cost time 0.51
Train Epoch: 6 [88064/319902 (28%)] Loss: 0.037777, 1 batch cost time 0.51
Train Epoch: 6 [88576/319902 (28%)] Loss: 0.038473, 1 batch cost time 0.51
Train Epoch: 6 [89088/319902 (28%)] Loss: 0.047205, 1 batch cost time 0.51
Train Epoch: 6 [89600/319902 (28%)] Loss: 0.029344, 1 batch cost time 0.51
Train Epoch: 6 [90112/319902 (28%)] Loss: 0.044705, 1 batch cost time 0.51
Train Epoch: 6 [90624/319902 (28%)] Loss: 0.025565, 1 batch cost time 0.51
Train Epoch: 6 [91136/319902 (28%)] Loss: 0.052820, 1 batch cost time 0.51
Train Epoch: 6 [91648/319902 (29%)] Loss: 0.055468, 1 batch cost time 0.51
Train Epoch: 6 [92160/319902 (29%)] Loss: 0.020649, 1 batch cost time 0.51
Train Epoch: 6 [92672/319902 (29%)] Loss: 0.027495, 1 batch cost time 0.51
Train Epoch: 6 [93184/319902 (29%)] Loss: 0.041353, 1 batch cost time 0.51
Train Epoch: 6 [93696/319902 (29%)] Loss: 0.019933, 1 batch cost time 0.51
Train Epoch: 6 [94208/319902 (29%)] Loss: 0.055147, 1 batch cost time 0.51
Train Epoch: 6 [94720/319902 (30%)] Loss: 0.018602, 1 batch cost time 0.51
Train Epoch: 6 [95232/319902 (30%)] Loss: 0.035506, 1 batch cost time 0.51
Train Epoch: 6 [95744/319902 (30%)] Loss: 0.032826, 1 batch cost time 0.51
Train Epoch: 6 [96256/319902 (30%)] Loss: 0.022077, 1 batch cost time 0.51
Train Epoch: 6 [96768/319902 (30%)] Loss: 0.044437, 1 batch cost time 0.51
Train Epoch: 6 [97280/319902 (30%)] Loss: 0.031014, 1 batch cost time 0.51
Train Epoch: 6 [97792/319902 (31%)] Loss: 0.036616, 1 batch cost time 0.51
Train Epoch: 6 [98304/319902 (31%)] Loss: 0.018507, 1 batch cost time 0.51
Train Epoch: 6 [98816/319902 (31%)] Loss: 0.026161, 1 batch cost time 0.51
Train Epoch: 6 [99328/319902 (31%)] Loss: 0.061745, 1 batch cost time 0.51
Train Epoch: 6 [99840/319902 (31%)] Loss: 0.041915, 1 batch cost time 0.51
Train Epoch: 6 [100352/319902 (31%)] Loss: 0.019640, 1 batch cost time 0.51
Train Epoch: 6 [100864/319902 (32%)] Loss: 0.033830, 1 batch cost time 0.51
Train Epoch: 6 [101376/319902 (32%)] Loss: 0.038507, 1 batch cost time 0.51
Train Epoch: 6 [101888/319902 (32%)] Loss: 0.035510, 1 batch cost time 0.51
Train Epoch: 6 [102400/319902 (32%)] Loss: 0.019496, 1 batch cost time 0.51
Train Epoch: 6 [102912/319902 (32%)] Loss: 0.022742, 1 batch cost time 0.51
Train Epoch: 6 [103424/319902 (32%)] Loss: 0.007255, 1 batch cost time 0.51
Train Epoch: 6 [103936/319902 (32%)] Loss: 0.026298, 1 batch cost time 0.51
Train Epoch: 6 [104448/319902 (33%)] Loss: 0.019872, 1 batch cost time 0.51
Train Epoch: 6 [104960/319902 (33%)] Loss: 0.025405, 1 batch cost time 0.51
Train Epoch: 6 [105472/319902 (33%)] Loss: 0.038014, 1 batch cost time 0.51
Train Epoch: 6 [105984/319902 (33%)] Loss: 0.020215, 1 batch cost time 0.51
Train Epoch: 6 [106496/319902 (33%)] Loss: 0.029576, 1 batch cost time 0.51
Train Epoch: 6 [107008/319902 (33%)] Loss: 0.034807, 1 batch cost time 0.51
Train Epoch: 6 [107520/319902 (34%)] Loss: 0.035762, 1 batch cost time 0.51
Train Epoch: 6 [108032/319902 (34%)] Loss: 0.018961, 1 batch cost time 0.51
Train Epoch: 6 [108544/319902 (34%)] Loss: 0.049770, 1 batch cost time 0.51
Train Epoch: 6 [109056/319902 (34%)] Loss: 0.048285, 1 batch cost time 0.51
Train Epoch: 6 [109568/319902 (34%)] Loss: 0.028255, 1 batch cost time 0.51
Train Epoch: 6 [110080/319902 (34%)] Loss: 0.023884, 1 batch cost time 0.51
Train Epoch: 6 [110592/319902 (35%)] Loss: 0.032515, 1 batch cost time 0.51
Train Epoch: 6 [111104/319902 (35%)] Loss: 0.039263, 1 batch cost time 0.51
Train Epoch: 6 [111616/319902 (35%)] Loss: 0.027491, 1 batch cost time 0.51
Train Epoch: 6 [112128/319902 (35%)] Loss: 0.030019, 1 batch cost time 0.51
Train Epoch: 6 [112640/319902 (35%)] Loss: 0.033136, 1 batch cost time 0.51
Train Epoch: 6 [113152/319902 (35%)] Loss: 0.030480, 1 batch cost time 0.51
Train Epoch: 6 [113664/319902 (36%)] Loss: 0.025133, 1 batch cost time 0.51
Train Epoch: 6 [114176/319902 (36%)] Loss: 0.016147, 1 batch cost time 0.51
Train Epoch: 6 [114688/319902 (36%)] Loss: 0.015247, 1 batch cost time 0.51
Train Epoch: 6 [115200/319902 (36%)] Loss: 0.045659, 1 batch cost time 0.51
Train Epoch: 6 [115712/319902 (36%)] Loss: 0.025101, 1 batch cost time 0.51
Train Epoch: 6 [116224/319902 (36%)] Loss: 0.031440, 1 batch cost time 0.51
Train Epoch: 6 [116736/319902 (36%)] Loss: 0.041819, 1 batch cost time 0.51
Train Epoch: 6 [117248/319902 (37%)] Loss: 0.022496, 1 batch cost time 0.51
Train Epoch: 6 [117760/319902 (37%)] Loss: 0.043128, 1 batch cost time 0.51
Train Epoch: 6 [118272/319902 (37%)] Loss: 0.038995, 1 batch cost time 0.51
Train Epoch: 6 [118784/319902 (37%)] Loss: 0.031098, 1 batch cost time 0.51
Train Epoch: 6 [119296/319902 (37%)] Loss: 0.045741, 1 batch cost time 0.51
Train Epoch: 6 [119808/319902 (37%)] Loss: 0.026007, 1 batch cost time 0.51
Train Epoch: 6 [120320/319902 (38%)] Loss: 0.030721, 1 batch cost time 0.51
Train Epoch: 6 [120832/319902 (38%)] Loss: 0.033746, 1 batch cost time 0.51
Train Epoch: 6 [121344/319902 (38%)] Loss: 0.030558, 1 batch cost time 0.51
Train Epoch: 6 [121856/319902 (38%)] Loss: 0.020958, 1 batch cost time 0.51
Train Epoch: 6 [122368/319902 (38%)] Loss: 0.034086, 1 batch cost time 0.51
Train Epoch: 6 [122880/319902 (38%)] Loss: 0.012783, 1 batch cost time 0.51
Train Epoch: 6 [123392/319902 (39%)] Loss: 0.031364, 1 batch cost time 0.51
Train Epoch: 6 [123904/319902 (39%)] Loss: 0.023934, 1 batch cost time 0.51
Train Epoch: 6 [124416/319902 (39%)] Loss: 0.047947, 1 batch cost time 0.51
Train Epoch: 6 [124928/319902 (39%)] Loss: 0.048214, 1 batch cost time 0.51
Train Epoch: 6 [125440/319902 (39%)] Loss: 0.026659, 1 batch cost time 0.51
Train Epoch: 6 [125952/319902 (39%)] Loss: 0.020878, 1 batch cost time 0.51
Train Epoch: 6 [126464/319902 (40%)] Loss: 0.030805, 1 batch cost time 0.51
Train Epoch: 6 [126976/319902 (40%)] Loss: 0.023720, 1 batch cost time 0.51
Train Epoch: 6 [127488/319902 (40%)] Loss: 0.017845, 1 batch cost time 0.51
Train Epoch: 6 [128000/319902 (40%)] Loss: 0.024691, 1 batch cost time 0.51
Train Epoch: 6 [128512/319902 (40%)] Loss: 0.023313, 1 batch cost time 0.51
Train Epoch: 6 [129024/319902 (40%)] Loss: 0.035508, 1 batch cost time 0.51
Train Epoch: 6 [129536/319902 (40%)] Loss: 0.035195, 1 batch cost time 0.51
Train Epoch: 6 [130048/319902 (41%)] Loss: 0.025461, 1 batch cost time 0.51
Train Epoch: 6 [130560/319902 (41%)] Loss: 0.061961, 1 batch cost time 0.51
Train Epoch: 6 [131072/319902 (41%)] Loss: 0.042315, 1 batch cost time 0.51
Train Epoch: 6 [131584/319902 (41%)] Loss: 0.041990, 1 batch cost time 0.51
Train Epoch: 6 [132096/319902 (41%)] Loss: 0.027912, 1 batch cost time 0.51
Train Epoch: 6 [132608/319902 (41%)] Loss: 0.017692, 1 batch cost time 0.51
Train Epoch: 6 [133120/319902 (42%)] Loss: 0.021371, 1 batch cost time 0.51
Train Epoch: 6 [133632/319902 (42%)] Loss: 0.039060, 1 batch cost time 0.51
Train Epoch: 6 [134144/319902 (42%)] Loss: 0.018726, 1 batch cost time 0.51
Train Epoch: 6 [134656/319902 (42%)] Loss: 0.033151, 1 batch cost time 0.51
Train Epoch: 6 [135168/319902 (42%)] Loss: 0.015623, 1 batch cost time 0.51
Train Epoch: 6 [135680/319902 (42%)] Loss: 0.069093, 1 batch cost time 0.51
Train Epoch: 6 [136192/319902 (43%)] Loss: 0.023727, 1 batch cost time 0.51
Train Epoch: 6 [136704/319902 (43%)] Loss: 0.037376, 1 batch cost time 0.51
Train Epoch: 6 [137216/319902 (43%)] Loss: 0.016257, 1 batch cost time 0.51
Train Epoch: 6 [137728/319902 (43%)] Loss: 0.031377, 1 batch cost time 0.51
Train Epoch: 6 [138240/319902 (43%)] Loss: 0.005943, 1 batch cost time 0.51
Train Epoch: 6 [138752/319902 (43%)] Loss: 0.020066, 1 batch cost time 0.51
Train Epoch: 6 [139264/319902 (44%)] Loss: 0.049598, 1 batch cost time 0.51
Train Epoch: 6 [139776/319902 (44%)] Loss: 0.033415, 1 batch cost time 0.51
Train Epoch: 6 [140288/319902 (44%)] Loss: 0.030616, 1 batch cost time 0.51
Train Epoch: 6 [140800/319902 (44%)] Loss: 0.029763, 1 batch cost time 0.51
Train Epoch: 6 [141312/319902 (44%)] Loss: 0.010028, 1 batch cost time 0.51
Train Epoch: 6 [141824/319902 (44%)] Loss: 0.041973, 1 batch cost time 0.51
Train Epoch: 6 [142336/319902 (44%)] Loss: 0.029127, 1 batch cost time 0.51
Train Epoch: 6 [142848/319902 (45%)] Loss: 0.020500, 1 batch cost time 0.51
Train Epoch: 6 [143360/319902 (45%)] Loss: 0.035225, 1 batch cost time 0.51
Train Epoch: 6 [143872/319902 (45%)] Loss: 0.022179, 1 batch cost time 0.51
Train Epoch: 6 [144384/319902 (45%)] Loss: 0.017303, 1 batch cost time 0.51
Train Epoch: 6 [144896/319902 (45%)] Loss: 0.047172, 1 batch cost time 0.51
Train Epoch: 6 [145408/319902 (45%)] Loss: 0.017319, 1 batch cost time 0.51
Train Epoch: 6 [145920/319902 (46%)] Loss: 0.026072, 1 batch cost time 0.51
Train Epoch: 6 [146432/319902 (46%)] Loss: 0.041601, 1 batch cost time 0.51
Train Epoch: 6 [146944/319902 (46%)] Loss: 0.018204, 1 batch cost time 0.51
Train Epoch: 6 [147456/319902 (46%)] Loss: 0.044737, 1 batch cost time 0.51
Train Epoch: 6 [147968/319902 (46%)] Loss: 0.022441, 1 batch cost time 0.51
Train Epoch: 6 [148480/319902 (46%)] Loss: 0.014764, 1 batch cost time 0.51
Train Epoch: 6 [148992/319902 (47%)] Loss: 0.036286, 1 batch cost time 0.51
Train Epoch: 6 [149504/319902 (47%)] Loss: 0.022360, 1 batch cost time 0.51
Train Epoch: 6 [150016/319902 (47%)] Loss: 0.033121, 1 batch cost time 0.51
Train Epoch: 6 [150528/319902 (47%)] Loss: 0.055073, 1 batch cost time 0.51
Train Epoch: 6 [151040/319902 (47%)] Loss: 0.040263, 1 batch cost time 0.51
Train Epoch: 6 [151552/319902 (47%)] Loss: 0.029006, 1 batch cost time 0.51
Train Epoch: 6 [152064/319902 (48%)] Loss: 0.045923, 1 batch cost time 0.51
Train Epoch: 6 [152576/319902 (48%)] Loss: 0.055853, 1 batch cost time 0.51
Train Epoch: 6 [153088/319902 (48%)] Loss: 0.045591, 1 batch cost time 0.51
Train Epoch: 6 [153600/319902 (48%)] Loss: 0.025643, 1 batch cost time 0.51
Train Epoch: 6 [154112/319902 (48%)] Loss: 0.017601, 1 batch cost time 0.51
Train Epoch: 6 [154624/319902 (48%)] Loss: 0.044374, 1 batch cost time 0.51
Train Epoch: 6 [155136/319902 (48%)] Loss: 0.030043, 1 batch cost time 0.51
Train Epoch: 6 [155648/319902 (49%)] Loss: 0.018046, 1 batch cost time 0.51
Train Epoch: 6 [156160/319902 (49%)] Loss: 0.047362, 1 batch cost time 0.51
Train Epoch: 6 [156672/319902 (49%)] Loss: 0.014584, 1 batch cost time 0.51
Train Epoch: 6 [157184/319902 (49%)] Loss: 0.019888, 1 batch cost time 0.51
Train Epoch: 6 [157696/319902 (49%)] Loss: 0.018680, 1 batch cost time 0.51
Train Epoch: 6 [158208/319902 (49%)] Loss: 0.027195, 1 batch cost time 0.51
Train Epoch: 6 [158720/319902 (50%)] Loss: 0.029838, 1 batch cost time 0.51
Train Epoch: 6 [159232/319902 (50%)] Loss: 0.015070, 1 batch cost time 0.51
Train Epoch: 6 [159744/319902 (50%)] Loss: 0.044527, 1 batch cost time 0.51
Train Epoch: 6 [160256/319902 (50%)] Loss: 0.007723, 1 batch cost time 0.51
Train Epoch: 6 [160768/319902 (50%)] Loss: 0.027569, 1 batch cost time 0.51
Train Epoch: 6 [161280/319902 (50%)] Loss: 0.031077, 1 batch cost time 0.51
Train Epoch: 6 [161792/319902 (51%)] Loss: 0.031043, 1 batch cost time 0.51
Train Epoch: 6 [162304/319902 (51%)] Loss: 0.032365, 1 batch cost time 0.51
Train Epoch: 6 [162816/319902 (51%)] Loss: 0.028330, 1 batch cost time 0.51
Train Epoch: 6 [163328/319902 (51%)] Loss: 0.031882, 1 batch cost time 0.51
Train Epoch: 6 [163840/319902 (51%)] Loss: 0.061537, 1 batch cost time 0.51
Train Epoch: 6 [164352/319902 (51%)] Loss: 0.035698, 1 batch cost time 0.51
Train Epoch: 6 [164864/319902 (52%)] Loss: 0.043843, 1 batch cost time 0.51
Train Epoch: 6 [165376/319902 (52%)] Loss: 0.035606, 1 batch cost time 0.51
Train Epoch: 6 [165888/319902 (52%)] Loss: 0.021237, 1 batch cost time 0.51
Train Epoch: 6 [166400/319902 (52%)] Loss: 0.016779, 1 batch cost time 0.51
Train Epoch: 6 [166912/319902 (52%)] Loss: 0.018908, 1 batch cost time 0.51
Train Epoch: 6 [167424/319902 (52%)] Loss: 0.021985, 1 batch cost time 0.51
Train Epoch: 6 [167936/319902 (52%)] Loss: 0.025307, 1 batch cost time 0.51
Train Epoch: 6 [168448/319902 (53%)] Loss: 0.042606, 1 batch cost time 0.51
Train Epoch: 6 [168960/319902 (53%)] Loss: 0.018017, 1 batch cost time 0.51
Train Epoch: 6 [169472/319902 (53%)] Loss: 0.046466, 1 batch cost time 0.51
Train Epoch: 6 [169984/319902 (53%)] Loss: 0.028697, 1 batch cost time 0.51
Train Epoch: 6 [170496/319902 (53%)] Loss: 0.031137, 1 batch cost time 0.51
Train Epoch: 6 [171008/319902 (53%)] Loss: 0.030855, 1 batch cost time 0.51
Train Epoch: 6 [171520/319902 (54%)] Loss: 0.023539, 1 batch cost time 0.51
Train Epoch: 6 [172032/319902 (54%)] Loss: 0.026309, 1 batch cost time 0.51
Train Epoch: 6 [172544/319902 (54%)] Loss: 0.043322, 1 batch cost time 0.51
Train Epoch: 6 [173056/319902 (54%)] Loss: 0.021805, 1 batch cost time 0.51
Train Epoch: 6 [173568/319902 (54%)] Loss: 0.023532, 1 batch cost time 0.51
Train Epoch: 6 [174080/319902 (54%)] Loss: 0.067622, 1 batch cost time 0.51
Train Epoch: 6 [174592/319902 (55%)] Loss: 0.015234, 1 batch cost time 0.51
Train Epoch: 6 [175104/319902 (55%)] Loss: 0.035900, 1 batch cost time 0.51
Train Epoch: 6 [175616/319902 (55%)] Loss: 0.018834, 1 batch cost time 0.51
Train Epoch: 6 [176128/319902 (55%)] Loss: 0.021448, 1 batch cost time 0.51
Train Epoch: 6 [176640/319902 (55%)] Loss: 0.026059, 1 batch cost time 0.51
Train Epoch: 6 [177152/319902 (55%)] Loss: 0.021633, 1 batch cost time 0.51
Train Epoch: 6 [177664/319902 (56%)] Loss: 0.027687, 1 batch cost time 0.51
Train Epoch: 6 [178176/319902 (56%)] Loss: 0.025868, 1 batch cost time 0.51
Train Epoch: 6 [178688/319902 (56%)] Loss: 0.011242, 1 batch cost time 0.51
Train Epoch: 6 [179200/319902 (56%)] Loss: 0.030273, 1 batch cost time 0.51
Train Epoch: 6 [179712/319902 (56%)] Loss: 0.032796, 1 batch cost time 0.51
Train Epoch: 6 [180224/319902 (56%)] Loss: 0.053261, 1 batch cost time 0.51
Train Epoch: 6 [180736/319902 (56%)] Loss: 0.038828, 1 batch cost time 0.51
Train Epoch: 6 [181248/319902 (57%)] Loss: 0.043164, 1 batch cost time 0.51
Train Epoch: 6 [181760/319902 (57%)] Loss: 0.023794, 1 batch cost time 0.51
Train Epoch: 6 [182272/319902 (57%)] Loss: 0.024699, 1 batch cost time 0.51
Train Epoch: 6 [182784/319902 (57%)] Loss: 0.040672, 1 batch cost time 0.51
Train Epoch: 6 [183296/319902 (57%)] Loss: 0.042934, 1 batch cost time 0.51
Train Epoch: 6 [183808/319902 (57%)] Loss: 0.039690, 1 batch cost time 0.51
Train Epoch: 6 [184320/319902 (58%)] Loss: 0.020967, 1 batch cost time 0.51
Train Epoch: 6 [184832/319902 (58%)] Loss: 0.033188, 1 batch cost time 0.51
Train Epoch: 6 [185344/319902 (58%)] Loss: 0.025041, 1 batch cost time 0.51
Train Epoch: 6 [185856/319902 (58%)] Loss: 0.053990, 1 batch cost time 0.51
Train Epoch: 6 [186368/319902 (58%)] Loss: 0.028185, 1 batch cost time 0.51
Train Epoch: 6 [186880/319902 (58%)] Loss: 0.042687, 1 batch cost time 0.51
Train Epoch: 6 [187392/319902 (59%)] Loss: 0.027774, 1 batch cost time 0.51
Train Epoch: 6 [187904/319902 (59%)] Loss: 0.042149, 1 batch cost time 0.51
Train Epoch: 6 [188416/319902 (59%)] Loss: 0.024069, 1 batch cost time 0.51
Train Epoch: 6 [188928/319902 (59%)] Loss: 0.037683, 1 batch cost time 0.51
Train Epoch: 6 [189440/319902 (59%)] Loss: 0.033702, 1 batch cost time 0.51
Train Epoch: 6 [189952/319902 (59%)] Loss: 0.011697, 1 batch cost time 0.51
Train Epoch: 6 [190464/319902 (60%)] Loss: 0.036964, 1 batch cost time 0.51
Train Epoch: 6 [190976/319902 (60%)] Loss: 0.031706, 1 batch cost time 0.51
Train Epoch: 6 [191488/319902 (60%)] Loss: 0.038398, 1 batch cost time 0.51
Train Epoch: 6 [192000/319902 (60%)] Loss: 0.049041, 1 batch cost time 0.51
Train Epoch: 6 [192512/319902 (60%)] Loss: 0.027710, 1 batch cost time 0.51
Train Epoch: 6 [193024/319902 (60%)] Loss: 0.039655, 1 batch cost time 0.51
Train Epoch: 6 [193536/319902 (60%)] Loss: 0.029200, 1 batch cost time 0.51
Train Epoch: 6 [194048/319902 (61%)] Loss: 0.017008, 1 batch cost time 0.51
Train Epoch: 6 [194560/319902 (61%)] Loss: 0.038723, 1 batch cost time 0.51
Train Epoch: 6 [195072/319902 (61%)] Loss: 0.016355, 1 batch cost time 0.51
Train Epoch: 6 [195584/319902 (61%)] Loss: 0.027950, 1 batch cost time 0.51
Train Epoch: 6 [196096/319902 (61%)] Loss: 0.039614, 1 batch cost time 0.51
Train Epoch: 6 [196608/319902 (61%)] Loss: 0.022229, 1 batch cost time 0.51
Train Epoch: 6 [197120/319902 (62%)] Loss: 0.049707, 1 batch cost time 0.51
Train Epoch: 6 [197632/319902 (62%)] Loss: 0.031679, 1 batch cost time 0.51
Train Epoch: 6 [198144/319902 (62%)] Loss: 0.036944, 1 batch cost time 0.51
Train Epoch: 6 [198656/319902 (62%)] Loss: 0.035975, 1 batch cost time 0.51
Train Epoch: 6 [199168/319902 (62%)] Loss: 0.030492, 1 batch cost time 0.51
Train Epoch: 6 [199680/319902 (62%)] Loss: 0.055140, 1 batch cost time 0.51
Train Epoch: 6 [200192/319902 (63%)] Loss: 0.025488, 1 batch cost time 0.51
Train Epoch: 6 [200704/319902 (63%)] Loss: 0.048036, 1 batch cost time 0.51
Train Epoch: 6 [201216/319902 (63%)] Loss: 0.031510, 1 batch cost time 0.51
Train Epoch: 6 [201728/319902 (63%)] Loss: 0.039057, 1 batch cost time 0.51
Train Epoch: 6 [202240/319902 (63%)] Loss: 0.016129, 1 batch cost time 0.51
Train Epoch: 6 [202752/319902 (63%)] Loss: 0.043089, 1 batch cost time 0.51
Train Epoch: 6 [203264/319902 (64%)] Loss: 0.040373, 1 batch cost time 0.51
Train Epoch: 6 [203776/319902 (64%)] Loss: 0.027987, 1 batch cost time 0.51
Train Epoch: 6 [204288/319902 (64%)] Loss: 0.040298, 1 batch cost time 0.51
Train Epoch: 6 [204800/319902 (64%)] Loss: 0.033891, 1 batch cost time 0.51
Train Epoch: 6 [205312/319902 (64%)] Loss: 0.019614, 1 batch cost time 0.51
Train Epoch: 6 [205824/319902 (64%)] Loss: 0.038506, 1 batch cost time 0.51
Train Epoch: 6 [206336/319902 (64%)] Loss: 0.014027, 1 batch cost time 0.51
Train Epoch: 6 [206848/319902 (65%)] Loss: 0.029581, 1 batch cost time 0.51
Train Epoch: 6 [207360/319902 (65%)] Loss: 0.020469, 1 batch cost time 0.51
Train Epoch: 6 [207872/319902 (65%)] Loss: 0.023194, 1 batch cost time 0.51
Train Epoch: 6 [208384/319902 (65%)] Loss: 0.043882, 1 batch cost time 0.51
Train Epoch: 6 [208896/319902 (65%)] Loss: 0.014438, 1 batch cost time 0.51
Train Epoch: 6 [209408/319902 (65%)] Loss: 0.019585, 1 batch cost time 0.51
Train Epoch: 6 [209920/319902 (66%)] Loss: 0.034574, 1 batch cost time 0.51
Train Epoch: 6 [210432/319902 (66%)] Loss: 0.022073, 1 batch cost time 0.51
Train Epoch: 6 [210944/319902 (66%)] Loss: 0.009258, 1 batch cost time 0.51
Train Epoch: 6 [211456/319902 (66%)] Loss: 0.038060, 1 batch cost time 0.51
Train Epoch: 6 [211968/319902 (66%)] Loss: 0.010659, 1 batch cost time 0.51
Train Epoch: 6 [212480/319902 (66%)] Loss: 0.031610, 1 batch cost time 0.51
Train Epoch: 6 [212992/319902 (67%)] Loss: 0.022179, 1 batch cost time 0.51
Train Epoch: 6 [213504/319902 (67%)] Loss: 0.031715, 1 batch cost time 0.51
Train Epoch: 6 [214016/319902 (67%)] Loss: 0.028705, 1 batch cost time 0.51
Train Epoch: 6 [214528/319902 (67%)] Loss: 0.027801, 1 batch cost time 0.51
Train Epoch: 6 [215040/319902 (67%)] Loss: 0.064756, 1 batch cost time 0.51
Train Epoch: 6 [215552/319902 (67%)] Loss: 0.053024, 1 batch cost time 0.51
Train Epoch: 6 [216064/319902 (68%)] Loss: 0.031568, 1 batch cost time 0.51
Train Epoch: 6 [216576/319902 (68%)] Loss: 0.034252, 1 batch cost time 0.51
Train Epoch: 6 [217088/319902 (68%)] Loss: 0.017653, 1 batch cost time 0.51
Train Epoch: 6 [217600/319902 (68%)] Loss: 0.031029, 1 batch cost time 0.51
Train Epoch: 6 [218112/319902 (68%)] Loss: 0.018588, 1 batch cost time 0.51
Train Epoch: 6 [218624/319902 (68%)] Loss: 0.049241, 1 batch cost time 0.51
Train Epoch: 6 [219136/319902 (69%)] Loss: 0.051932, 1 batch cost time 0.51
Train Epoch: 6 [219648/319902 (69%)] Loss: 0.054060, 1 batch cost time 0.51
Train Epoch: 6 [220160/319902 (69%)] Loss: 0.020456, 1 batch cost time 0.51
Train Epoch: 6 [220672/319902 (69%)] Loss: 0.040985, 1 batch cost time 0.51
Train Epoch: 6 [221184/319902 (69%)] Loss: 0.033283, 1 batch cost time 0.51
Train Epoch: 6 [221696/319902 (69%)] Loss: 0.020510, 1 batch cost time 0.51
Train Epoch: 6 [222208/319902 (69%)] Loss: 0.025676, 1 batch cost time 0.51
Train Epoch: 6 [222720/319902 (70%)] Loss: 0.031397, 1 batch cost time 0.51
Train Epoch: 6 [223232/319902 (70%)] Loss: 0.042028, 1 batch cost time 0.51
Train Epoch: 6 [223744/319902 (70%)] Loss: 0.045449, 1 batch cost time 0.51
Train Epoch: 6 [224256/319902 (70%)] Loss: 0.031949, 1 batch cost time 0.51
Train Epoch: 6 [224768/319902 (70%)] Loss: 0.048579, 1 batch cost time 0.51
Train Epoch: 6 [225280/319902 (70%)] Loss: 0.056353, 1 batch cost time 0.51
Train Epoch: 6 [225792/319902 (71%)] Loss: 0.025886, 1 batch cost time 0.51
Train Epoch: 6 [226304/319902 (71%)] Loss: 0.018491, 1 batch cost time 0.51
Train Epoch: 6 [226816/319902 (71%)] Loss: 0.020829, 1 batch cost time 0.51
Train Epoch: 6 [227328/319902 (71%)] Loss: 0.026746, 1 batch cost time 0.51
Train Epoch: 6 [227840/319902 (71%)] Loss: 0.048543, 1 batch cost time 0.51
Train Epoch: 6 [228352/319902 (71%)] Loss: 0.039195, 1 batch cost time 0.51
Train Epoch: 6 [228864/319902 (72%)] Loss: 0.016621, 1 batch cost time 0.51
Train Epoch: 6 [229376/319902 (72%)] Loss: 0.018937, 1 batch cost time 0.51
Train Epoch: 6 [229888/319902 (72%)] Loss: 0.020760, 1 batch cost time 0.51
Train Epoch: 6 [230400/319902 (72%)] Loss: 0.031986, 1 batch cost time 0.51
Train Epoch: 6 [230912/319902 (72%)] Loss: 0.036376, 1 batch cost time 0.51
Train Epoch: 6 [231424/319902 (72%)] Loss: 0.032090, 1 batch cost time 0.51
Train Epoch: 6 [231936/319902 (73%)] Loss: 0.032986, 1 batch cost time 0.51
Train Epoch: 6 [232448/319902 (73%)] Loss: 0.050371, 1 batch cost time 0.51
Train Epoch: 6 [232960/319902 (73%)] Loss: 0.015648, 1 batch cost time 0.51
Train Epoch: 6 [233472/319902 (73%)] Loss: 0.019955, 1 batch cost time 0.51
Train Epoch: 6 [233984/319902 (73%)] Loss: 0.011873, 1 batch cost time 0.51
Train Epoch: 6 [234496/319902 (73%)] Loss: 0.016166, 1 batch cost time 0.51
Train Epoch: 6 [235008/319902 (73%)] Loss: 0.029693, 1 batch cost time 0.51
Train Epoch: 6 [235520/319902 (74%)] Loss: 0.032104, 1 batch cost time 0.51
Train Epoch: 6 [236032/319902 (74%)] Loss: 0.051552, 1 batch cost time 0.51
Train Epoch: 6 [236544/319902 (74%)] Loss: 0.055815, 1 batch cost time 0.51
Train Epoch: 6 [237056/319902 (74%)] Loss: 0.025124, 1 batch cost time 0.51
Train Epoch: 6 [237568/319902 (74%)] Loss: 0.042089, 1 batch cost time 0.51
Train Epoch: 6 [238080/319902 (74%)] Loss: 0.020261, 1 batch cost time 0.51
Train Epoch: 6 [238592/319902 (75%)] Loss: 0.027253, 1 batch cost time 0.51
Train Epoch: 6 [239104/319902 (75%)] Loss: 0.067021, 1 batch cost time 0.51
Train Epoch: 6 [239616/319902 (75%)] Loss: 0.030880, 1 batch cost time 0.51
Train Epoch: 6 [240128/319902 (75%)] Loss: 0.033236, 1 batch cost time 0.51
Train Epoch: 6 [240640/319902 (75%)] Loss: 0.028032, 1 batch cost time 0.51
Train Epoch: 6 [241152/319902 (75%)] Loss: 0.020570, 1 batch cost time 0.51
Train Epoch: 6 [241664/319902 (76%)] Loss: 0.010673, 1 batch cost time 0.51
Train Epoch: 6 [242176/319902 (76%)] Loss: 0.013295, 1 batch cost time 0.51
Train Epoch: 6 [242688/319902 (76%)] Loss: 0.040961, 1 batch cost time 0.51
Train Epoch: 6 [243200/319902 (76%)] Loss: 0.023222, 1 batch cost time 0.51
Train Epoch: 6 [243712/319902 (76%)] Loss: 0.053851, 1 batch cost time 0.51
Train Epoch: 6 [244224/319902 (76%)] Loss: 0.022783, 1 batch cost time 0.51
Train Epoch: 6 [244736/319902 (77%)] Loss: 0.026295, 1 batch cost time 0.51
Train Epoch: 6 [245248/319902 (77%)] Loss: 0.013102, 1 batch cost time 0.51
Train Epoch: 6 [245760/319902 (77%)] Loss: 0.051544, 1 batch cost time 0.51
Train Epoch: 6 [246272/319902 (77%)] Loss: 0.024784, 1 batch cost time 0.51
Train Epoch: 6 [246784/319902 (77%)] Loss: 0.011858, 1 batch cost time 0.51
Train Epoch: 6 [247296/319902 (77%)] Loss: 0.034354, 1 batch cost time 0.51
Train Epoch: 6 [247808/319902 (77%)] Loss: 0.025945, 1 batch cost time 0.51
Train Epoch: 6 [248320/319902 (78%)] Loss: 0.028826, 1 batch cost time 0.51
Train Epoch: 6 [248832/319902 (78%)] Loss: 0.026846, 1 batch cost time 0.51
Train Epoch: 6 [249344/319902 (78%)] Loss: 0.098250, 1 batch cost time 0.51
Train Epoch: 6 [249856/319902 (78%)] Loss: 0.023817, 1 batch cost time 0.51
Train Epoch: 6 [250368/319902 (78%)] Loss: 0.068579, 1 batch cost time 0.51
Train Epoch: 6 [250880/319902 (78%)] Loss: 0.033108, 1 batch cost time 0.51
Train Epoch: 6 [251392/319902 (79%)] Loss: 0.025623, 1 batch cost time 0.51
Train Epoch: 6 [251904/319902 (79%)] Loss: 0.043236, 1 batch cost time 0.51
Train Epoch: 6 [252416/319902 (79%)] Loss: 0.074354, 1 batch cost time 0.51
Train Epoch: 6 [252928/319902 (79%)] Loss: 0.044913, 1 batch cost time 0.51
Train Epoch: 6 [253440/319902 (79%)] Loss: 0.044497, 1 batch cost time 0.51
Train Epoch: 6 [253952/319902 (79%)] Loss: 0.010901, 1 batch cost time 0.51
Train Epoch: 6 [254464/319902 (80%)] Loss: 0.058806, 1 batch cost time 0.51
Train Epoch: 6 [254976/319902 (80%)] Loss: 0.028689, 1 batch cost time 0.51
Train Epoch: 6 [255488/319902 (80%)] Loss: 0.015265, 1 batch cost time 0.51
Train Epoch: 6 [256000/319902 (80%)] Loss: 0.016842, 1 batch cost time 0.51
Train Epoch: 6 [256512/319902 (80%)] Loss: 0.035109, 1 batch cost time 0.51
Train Epoch: 6 [257024/319902 (80%)] Loss: 0.039917, 1 batch cost time 0.51
Train Epoch: 6 [257536/319902 (81%)] Loss: 0.046949, 1 batch cost time 0.51
Train Epoch: 6 [258048/319902 (81%)] Loss: 0.018431, 1 batch cost time 0.51
Train Epoch: 6 [258560/319902 (81%)] Loss: 0.056052, 1 batch cost time 0.51
Train Epoch: 6 [259072/319902 (81%)] Loss: 0.032947, 1 batch cost time 0.51
Train Epoch: 6 [259584/319902 (81%)] Loss: 0.033951, 1 batch cost time 0.51
Train Epoch: 6 [260096/319902 (81%)] Loss: 0.012525, 1 batch cost time 0.51
Train Epoch: 6 [260608/319902 (81%)] Loss: 0.024014, 1 batch cost time 0.51
Train Epoch: 6 [261120/319902 (82%)] Loss: 0.014575, 1 batch cost time 0.51
Train Epoch: 6 [261632/319902 (82%)] Loss: 0.044211, 1 batch cost time 0.51
Train Epoch: 6 [262144/319902 (82%)] Loss: 0.044350, 1 batch cost time 0.51
Train Epoch: 6 [262656/319902 (82%)] Loss: 0.020847, 1 batch cost time 0.51
Train Epoch: 6 [263168/319902 (82%)] Loss: 0.049949, 1 batch cost time 0.51
Train Epoch: 6 [263680/319902 (82%)] Loss: 0.054575, 1 batch cost time 0.51
Train Epoch: 6 [264192/319902 (83%)] Loss: 0.048393, 1 batch cost time 0.51
Train Epoch: 6 [264704/319902 (83%)] Loss: 0.034104, 1 batch cost time 0.51
Train Epoch: 6 [265216/319902 (83%)] Loss: 0.045936, 1 batch cost time 0.51
Train Epoch: 6 [265728/319902 (83%)] Loss: 0.023696, 1 batch cost time 0.51
Train Epoch: 6 [266240/319902 (83%)] Loss: 0.036287, 1 batch cost time 0.51
Train Epoch: 6 [266752/319902 (83%)] Loss: 0.035402, 1 batch cost time 0.51
Train Epoch: 6 [267264/319902 (84%)] Loss: 0.020617, 1 batch cost time 0.51
Train Epoch: 6 [267776/319902 (84%)] Loss: 0.039042, 1 batch cost time 0.51
Train Epoch: 6 [268288/319902 (84%)] Loss: 0.033101, 1 batch cost time 0.51
Train Epoch: 6 [268800/319902 (84%)] Loss: 0.019449, 1 batch cost time 0.51
Train Epoch: 6 [269312/319902 (84%)] Loss: 0.015885, 1 batch cost time 0.51
Train Epoch: 6 [269824/319902 (84%)] Loss: 0.022247, 1 batch cost time 0.51
Train Epoch: 6 [270336/319902 (85%)] Loss: 0.048758, 1 batch cost time 0.51
Train Epoch: 6 [270848/319902 (85%)] Loss: 0.051306, 1 batch cost time 0.51
Train Epoch: 6 [271360/319902 (85%)] Loss: 0.039983, 1 batch cost time 0.51
Train Epoch: 6 [271872/319902 (85%)] Loss: 0.048201, 1 batch cost time 0.51
Train Epoch: 6 [272384/319902 (85%)] Loss: 0.053532, 1 batch cost time 0.51
Train Epoch: 6 [272896/319902 (85%)] Loss: 0.011274, 1 batch cost time 0.51
Train Epoch: 6 [273408/319902 (85%)] Loss: 0.034836, 1 batch cost time 0.51
Train Epoch: 6 [273920/319902 (86%)] Loss: 0.073387, 1 batch cost time 0.51
Train Epoch: 6 [274432/319902 (86%)] Loss: 0.042996, 1 batch cost time 0.51
Train Epoch: 6 [274944/319902 (86%)] Loss: 0.038506, 1 batch cost time 0.51
Train Epoch: 6 [275456/319902 (86%)] Loss: 0.054354, 1 batch cost time 0.51
Train Epoch: 6 [275968/319902 (86%)] Loss: 0.092166, 1 batch cost time 0.51
Train Epoch: 6 [276480/319902 (86%)] Loss: 0.046314, 1 batch cost time 0.51
Train Epoch: 6 [276992/319902 (87%)] Loss: 0.019944, 1 batch cost time 0.51
Train Epoch: 6 [277504/319902 (87%)] Loss: 0.018313, 1 batch cost time 0.51
Train Epoch: 6 [278016/319902 (87%)] Loss: 0.053192, 1 batch cost time 0.51
Train Epoch: 6 [278528/319902 (87%)] Loss: 0.036142, 1 batch cost time 0.51
Train Epoch: 6 [279040/319902 (87%)] Loss: 0.026155, 1 batch cost time 0.51
Train Epoch: 6 [279552/319902 (87%)] Loss: 0.011180, 1 batch cost time 0.51
Train Epoch: 6 [280064/319902 (88%)] Loss: 0.038717, 1 batch cost time 0.51
Train Epoch: 6 [280576/319902 (88%)] Loss: 0.034066, 1 batch cost time 0.51
Train Epoch: 6 [281088/319902 (88%)] Loss: 0.026292, 1 batch cost time 0.51
Train Epoch: 6 [281600/319902 (88%)] Loss: 0.032352, 1 batch cost time 0.51
Train Epoch: 6 [282112/319902 (88%)] Loss: 0.049532, 1 batch cost time 0.51
Train Epoch: 6 [282624/319902 (88%)] Loss: 0.044206, 1 batch cost time 0.51
Train Epoch: 6 [283136/319902 (89%)] Loss: 0.009858, 1 batch cost time 0.51
Train Epoch: 6 [283648/319902 (89%)] Loss: 0.037661, 1 batch cost time 0.51
Train Epoch: 6 [284160/319902 (89%)] Loss: 0.067010, 1 batch cost time 0.51
Train Epoch: 6 [284672/319902 (89%)] Loss: 0.046048, 1 batch cost time 0.51
Train Epoch: 6 [285184/319902 (89%)] Loss: 0.015613, 1 batch cost time 0.51
Train Epoch: 6 [285696/319902 (89%)] Loss: 0.026119, 1 batch cost time 0.51
Train Epoch: 6 [286208/319902 (89%)] Loss: 0.021054, 1 batch cost time 0.51
Train Epoch: 6 [286720/319902 (90%)] Loss: 0.037248, 1 batch cost time 0.51
Train Epoch: 6 [287232/319902 (90%)] Loss: 0.016095, 1 batch cost time 0.51
Train Epoch: 6 [287744/319902 (90%)] Loss: 0.034565, 1 batch cost time 0.51
Train Epoch: 6 [288256/319902 (90%)] Loss: 0.022489, 1 batch cost time 0.51
Train Epoch: 6 [288768/319902 (90%)] Loss: 0.041616, 1 batch cost time 0.51
Train Epoch: 6 [289280/319902 (90%)] Loss: 0.046728, 1 batch cost time 0.51
Train Epoch: 6 [289792/319902 (91%)] Loss: 0.023371, 1 batch cost time 0.51
Train Epoch: 6 [290304/319902 (91%)] Loss: 0.008795, 1 batch cost time 0.51
Train Epoch: 6 [290816/319902 (91%)] Loss: 0.039057, 1 batch cost time 0.51
Train Epoch: 6 [291328/319902 (91%)] Loss: 0.014185, 1 batch cost time 0.51
Train Epoch: 6 [291840/319902 (91%)] Loss: 0.019717, 1 batch cost time 0.51
Train Epoch: 6 [292352/319902 (91%)] Loss: 0.024805, 1 batch cost time 0.51
Train Epoch: 6 [292864/319902 (92%)] Loss: 0.022961, 1 batch cost time 0.51
Train Epoch: 6 [293376/319902 (92%)] Loss: 0.019559, 1 batch cost time 0.51
Train Epoch: 6 [293888/319902 (92%)] Loss: 0.031653, 1 batch cost time 0.51
Train Epoch: 6 [294400/319902 (92%)] Loss: 0.019477, 1 batch cost time 0.51
Train Epoch: 6 [294912/319902 (92%)] Loss: 0.036844, 1 batch cost time 0.51
Train Epoch: 6 [295424/319902 (92%)] Loss: 0.026839, 1 batch cost time 0.51
Train Epoch: 6 [295936/319902 (93%)] Loss: 0.036784, 1 batch cost time 0.51
Train Epoch: 6 [296448/319902 (93%)] Loss: 0.030151, 1 batch cost time 0.51
Train Epoch: 6 [296960/319902 (93%)] Loss: 0.058326, 1 batch cost time 0.51
Train Epoch: 6 [297472/319902 (93%)] Loss: 0.071644, 1 batch cost time 0.51
Train Epoch: 6 [297984/319902 (93%)] Loss: 0.026825, 1 batch cost time 0.51
Train Epoch: 6 [298496/319902 (93%)] Loss: 0.013628, 1 batch cost time 0.51
Train Epoch: 6 [299008/319902 (93%)] Loss: 0.037081, 1 batch cost time 0.51
Train Epoch: 6 [299520/319902 (94%)] Loss: 0.032329, 1 batch cost time 0.51
Train Epoch: 6 [300032/319902 (94%)] Loss: 0.011718, 1 batch cost time 0.51
Train Epoch: 6 [300544/319902 (94%)] Loss: 0.052774, 1 batch cost time 0.51
Train Epoch: 6 [301056/319902 (94%)] Loss: 0.025259, 1 batch cost time 0.51
Train Epoch: 6 [301568/319902 (94%)] Loss: 0.030926, 1 batch cost time 0.51
Train Epoch: 6 [302080/319902 (94%)] Loss: 0.051689, 1 batch cost time 0.51
Train Epoch: 6 [302592/319902 (95%)] Loss: 0.036850, 1 batch cost time 0.51
Train Epoch: 6 [303104/319902 (95%)] Loss: 0.011821, 1 batch cost time 0.51
Train Epoch: 6 [303616/319902 (95%)] Loss: 0.019529, 1 batch cost time 0.51
Train Epoch: 6 [304128/319902 (95%)] Loss: 0.015850, 1 batch cost time 0.51
Train Epoch: 6 [304640/319902 (95%)] Loss: 0.030481, 1 batch cost time 0.51
Train Epoch: 6 [305152/319902 (95%)] Loss: 0.023098, 1 batch cost time 0.51
Train Epoch: 6 [305664/319902 (96%)] Loss: 0.045949, 1 batch cost time 0.51
Train Epoch: 6 [306176/319902 (96%)] Loss: 0.019049, 1 batch cost time 0.51
Train Epoch: 6 [306688/319902 (96%)] Loss: 0.019065, 1 batch cost time 0.51
Train Epoch: 6 [307200/319902 (96%)] Loss: 0.011764, 1 batch cost time 0.51
Train Epoch: 6 [307712/319902 (96%)] Loss: 0.018246, 1 batch cost time 0.51
Train Epoch: 6 [308224/319902 (96%)] Loss: 0.066809, 1 batch cost time 0.51
Train Epoch: 6 [308736/319902 (97%)] Loss: 0.031461, 1 batch cost time 0.51
Train Epoch: 6 [309248/319902 (97%)] Loss: 0.036176, 1 batch cost time 0.51
Train Epoch: 6 [309760/319902 (97%)] Loss: 0.048559, 1 batch cost time 0.51
Train Epoch: 6 [310272/319902 (97%)] Loss: 0.044617, 1 batch cost time 0.51
Train Epoch: 6 [310784/319902 (97%)] Loss: 0.043453, 1 batch cost time 0.51
Train Epoch: 6 [311296/319902 (97%)] Loss: 0.027205, 1 batch cost time 0.51
Train Epoch: 6 [311808/319902 (97%)] Loss: 0.037781, 1 batch cost time 0.51
Train Epoch: 6 [312320/319902 (98%)] Loss: 0.019805, 1 batch cost time 0.51
Train Epoch: 6 [312832/319902 (98%)] Loss: 0.021599, 1 batch cost time 0.51
Train Epoch: 6 [313344/319902 (98%)] Loss: 0.006729, 1 batch cost time 0.51
Train Epoch: 6 [313856/319902 (98%)] Loss: 0.035904, 1 batch cost time 0.51
Train Epoch: 6 [314368/319902 (98%)] Loss: 0.033592, 1 batch cost time 0.51
Train Epoch: 6 [314880/319902 (98%)] Loss: 0.041663, 1 batch cost time 0.51
Train Epoch: 6 [315392/319902 (99%)] Loss: 0.046172, 1 batch cost time 0.51
Train Epoch: 6 [315904/319902 (99%)] Loss: 0.020734, 1 batch cost time 0.51
Train Epoch: 6 [316416/319902 (99%)] Loss: 0.045678, 1 batch cost time 0.51
Train Epoch: 6 [316928/319902 (99%)] Loss: 0.044362, 1 batch cost time 0.51
Train Epoch: 6 [317440/319902 (99%)] Loss: 0.040785, 1 batch cost time 0.51
Train Epoch: 6 [317952/319902 (99%)] Loss: 0.022042, 1 batch cost time 0.51
Train Epoch: 6 [318464/319902 (100%)] Loss: 0.060161, 1 batch cost time 0.51
Train Epoch: 6 [318976/319902 (100%)] Loss: 0.021081, 1 batch cost time 0.51
Train Epoch: 6 [319488/319902 (100%)] Loss: 0.038800, 1 batch cost time 0.51
training epoch cost 8020.86819601059 seconds
    epoch          : 6
    lr             : 0.0001
    loss           : 0.032106206592527546
    accuracy       : 0.9305565976390556
    f_measure      : nan
    val_loss       : 0.026589049302856438
    val_accuracy   : 0.9423828125
    val_f_measure  : 0.5883141121031746
Saving current best: model_best.pth ...
Train Epoch: 7 [0/319902 (0%)] Loss: 0.022346, 1 batch cost time 0.52
Train Epoch: 7 [512/319902 (0%)] Loss: 0.019552, 1 batch cost time 0.51
Train Epoch: 7 [1024/319902 (0%)] Loss: 0.046541, 1 batch cost time 0.51
Train Epoch: 7 [1536/319902 (0%)] Loss: 0.033059, 1 batch cost time 0.51
Train Epoch: 7 [2048/319902 (1%)] Loss: 0.058101, 1 batch cost time 0.51
Train Epoch: 7 [2560/319902 (1%)] Loss: 0.016658, 1 batch cost time 0.51
Train Epoch: 7 [3072/319902 (1%)] Loss: 0.039567, 1 batch cost time 0.51
Train Epoch: 7 [3584/319902 (1%)] Loss: 0.023081, 1 batch cost time 0.51
Train Epoch: 7 [4096/319902 (1%)] Loss: 0.053672, 1 batch cost time 0.51
Train Epoch: 7 [4608/319902 (1%)] Loss: 0.022804, 1 batch cost time 0.51
Train Epoch: 7 [5120/319902 (2%)] Loss: 0.023433, 1 batch cost time 0.51
Train Epoch: 7 [5632/319902 (2%)] Loss: 0.029845, 1 batch cost time 0.51
Train Epoch: 7 [6144/319902 (2%)] Loss: 0.023622, 1 batch cost time 0.51
Train Epoch: 7 [6656/319902 (2%)] Loss: 0.032413, 1 batch cost time 0.51
Train Epoch: 7 [7168/319902 (2%)] Loss: 0.028449, 1 batch cost time 0.51
Train Epoch: 7 [7680/319902 (2%)] Loss: 0.068259, 1 batch cost time 0.51
Train Epoch: 7 [8192/319902 (3%)] Loss: 0.027791, 1 batch cost time 0.51
Train Epoch: 7 [8704/319902 (3%)] Loss: 0.030646, 1 batch cost time 0.51
Train Epoch: 7 [9216/319902 (3%)] Loss: 0.023400, 1 batch cost time 0.51
Train Epoch: 7 [9728/319902 (3%)] Loss: 0.037692, 1 batch cost time 0.51
Train Epoch: 7 [10240/319902 (3%)] Loss: 0.026379, 1 batch cost time 0.51
Train Epoch: 7 [10752/319902 (3%)] Loss: 0.031090, 1 batch cost time 0.51
Train Epoch: 7 [11264/319902 (4%)] Loss: 0.021514, 1 batch cost time 0.51
Train Epoch: 7 [11776/319902 (4%)] Loss: 0.043429, 1 batch cost time 0.51
Train Epoch: 7 [12288/319902 (4%)] Loss: 0.022143, 1 batch cost time 0.51
Train Epoch: 7 [12800/319902 (4%)] Loss: 0.015139, 1 batch cost time 0.51
Train Epoch: 7 [13312/319902 (4%)] Loss: 0.043301, 1 batch cost time 0.51
Train Epoch: 7 [13824/319902 (4%)] Loss: 0.028411, 1 batch cost time 0.51
Train Epoch: 7 [14336/319902 (4%)] Loss: 0.013653, 1 batch cost time 0.51
Train Epoch: 7 [14848/319902 (5%)] Loss: 0.013992, 1 batch cost time 0.51
Train Epoch: 7 [15360/319902 (5%)] Loss: 0.035782, 1 batch cost time 0.51
Train Epoch: 7 [15872/319902 (5%)] Loss: 0.043435, 1 batch cost time 0.51
Train Epoch: 7 [16384/319902 (5%)] Loss: 0.028805, 1 batch cost time 0.51
Train Epoch: 7 [16896/319902 (5%)] Loss: 0.057726, 1 batch cost time 0.51
Train Epoch: 7 [17408/319902 (5%)] Loss: 0.017093, 1 batch cost time 0.51
Train Epoch: 7 [17920/319902 (6%)] Loss: 0.047925, 1 batch cost time 0.51
Train Epoch: 7 [18432/319902 (6%)] Loss: 0.042465, 1 batch cost time 0.51
Train Epoch: 7 [18944/319902 (6%)] Loss: 0.045989, 1 batch cost time 0.51
Train Epoch: 7 [19456/319902 (6%)] Loss: 0.023906, 1 batch cost time 0.51
Train Epoch: 7 [19968/319902 (6%)] Loss: 0.045197, 1 batch cost time 0.51
Train Epoch: 7 [20480/319902 (6%)] Loss: 0.058007, 1 batch cost time 0.51
Train Epoch: 7 [20992/319902 (7%)] Loss: 0.045535, 1 batch cost time 0.51
Train Epoch: 7 [21504/319902 (7%)] Loss: 0.023089, 1 batch cost time 0.51
Train Epoch: 7 [22016/319902 (7%)] Loss: 0.018815, 1 batch cost time 0.51
Train Epoch: 7 [22528/319902 (7%)] Loss: 0.025163, 1 batch cost time 0.51
Train Epoch: 7 [23040/319902 (7%)] Loss: 0.030602, 1 batch cost time 0.51
Train Epoch: 7 [23552/319902 (7%)] Loss: 0.024478, 1 batch cost time 0.51
Train Epoch: 7 [24064/319902 (8%)] Loss: 0.046745, 1 batch cost time 0.51
Train Epoch: 7 [24576/319902 (8%)] Loss: 0.038671, 1 batch cost time 0.51
Train Epoch: 7 [25088/319902 (8%)] Loss: 0.031633, 1 batch cost time 0.51
Train Epoch: 7 [25600/319902 (8%)] Loss: 0.024729, 1 batch cost time 0.51
Train Epoch: 7 [26112/319902 (8%)] Loss: 0.015363, 1 batch cost time 0.51
Train Epoch: 7 [26624/319902 (8%)] Loss: 0.045792, 1 batch cost time 0.51
Train Epoch: 7 [27136/319902 (8%)] Loss: 0.067056, 1 batch cost time 0.51
Train Epoch: 7 [27648/319902 (9%)] Loss: 0.048734, 1 batch cost time 0.51
Train Epoch: 7 [28160/319902 (9%)] Loss: 0.032027, 1 batch cost time 0.51
Train Epoch: 7 [28672/319902 (9%)] Loss: 0.022837, 1 batch cost time 0.51
Train Epoch: 7 [29184/319902 (9%)] Loss: 0.019209, 1 batch cost time 0.51
Train Epoch: 7 [29696/319902 (9%)] Loss: 0.042986, 1 batch cost time 0.51
Train Epoch: 7 [30208/319902 (9%)] Loss: 0.019859, 1 batch cost time 0.51
Train Epoch: 7 [30720/319902 (10%)] Loss: 0.053552, 1 batch cost time 0.51
Train Epoch: 7 [31232/319902 (10%)] Loss: 0.025385, 1 batch cost time 0.51
Train Epoch: 7 [31744/319902 (10%)] Loss: 0.018745, 1 batch cost time 0.51
Train Epoch: 7 [32256/319902 (10%)] Loss: 0.041704, 1 batch cost time 0.51
Train Epoch: 7 [32768/319902 (10%)] Loss: 0.026998, 1 batch cost time 0.51
Train Epoch: 7 [33280/319902 (10%)] Loss: 0.033497, 1 batch cost time 0.51
Train Epoch: 7 [33792/319902 (11%)] Loss: 0.028810, 1 batch cost time 0.51
Train Epoch: 7 [34304/319902 (11%)] Loss: 0.038069, 1 batch cost time 0.51
Train Epoch: 7 [34816/319902 (11%)] Loss: 0.052149, 1 batch cost time 0.51
Train Epoch: 7 [35328/319902 (11%)] Loss: 0.042144, 1 batch cost time 0.51
Train Epoch: 7 [35840/319902 (11%)] Loss: 0.026277, 1 batch cost time 0.51
Train Epoch: 7 [36352/319902 (11%)] Loss: 0.016346, 1 batch cost time 0.51
Train Epoch: 7 [36864/319902 (12%)] Loss: 0.056322, 1 batch cost time 0.51
Train Epoch: 7 [37376/319902 (12%)] Loss: 0.018513, 1 batch cost time 0.51
Train Epoch: 7 [37888/319902 (12%)] Loss: 0.044282, 1 batch cost time 0.51
Train Epoch: 7 [38400/319902 (12%)] Loss: 0.024896, 1 batch cost time 0.51
Train Epoch: 7 [38912/319902 (12%)] Loss: 0.017335, 1 batch cost time 0.51
Train Epoch: 7 [39424/319902 (12%)] Loss: 0.020743, 1 batch cost time 0.51
Train Epoch: 7 [39936/319902 (12%)] Loss: 0.051905, 1 batch cost time 0.51
Train Epoch: 7 [40448/319902 (13%)] Loss: 0.014743, 1 batch cost time 0.51
Train Epoch: 7 [40960/319902 (13%)] Loss: 0.017416, 1 batch cost time 0.51
Train Epoch: 7 [41472/319902 (13%)] Loss: 0.023472, 1 batch cost time 0.51
Train Epoch: 7 [41984/319902 (13%)] Loss: 0.026036, 1 batch cost time 0.51
Train Epoch: 7 [42496/319902 (13%)] Loss: 0.030337, 1 batch cost time 0.51
Train Epoch: 7 [43008/319902 (13%)] Loss: 0.027971, 1 batch cost time 0.51
Train Epoch: 7 [43520/319902 (14%)] Loss: 0.028773, 1 batch cost time 0.51
Train Epoch: 7 [44032/319902 (14%)] Loss: 0.036289, 1 batch cost time 0.51
Train Epoch: 7 [44544/319902 (14%)] Loss: 0.034362, 1 batch cost time 0.51
Train Epoch: 7 [45056/319902 (14%)] Loss: 0.014016, 1 batch cost time 0.51
Train Epoch: 7 [45568/319902 (14%)] Loss: 0.037605, 1 batch cost time 0.51
Train Epoch: 7 [46080/319902 (14%)] Loss: 0.048136, 1 batch cost time 0.51
Train Epoch: 7 [46592/319902 (15%)] Loss: 0.026044, 1 batch cost time 0.51
Train Epoch: 7 [47104/319902 (15%)] Loss: 0.028752, 1 batch cost time 0.51
Train Epoch: 7 [47616/319902 (15%)] Loss: 0.048632, 1 batch cost time 0.51
Train Epoch: 7 [48128/319902 (15%)] Loss: 0.008557, 1 batch cost time 0.51
Train Epoch: 7 [48640/319902 (15%)] Loss: 0.046869, 1 batch cost time 0.51
Train Epoch: 7 [49152/319902 (15%)] Loss: 0.018480, 1 batch cost time 0.51
Train Epoch: 7 [49664/319902 (16%)] Loss: 0.014752, 1 batch cost time 0.51
Train Epoch: 7 [50176/319902 (16%)] Loss: 0.035415, 1 batch cost time 0.51
Train Epoch: 7 [50688/319902 (16%)] Loss: 0.037685, 1 batch cost time 0.51
Train Epoch: 7 [51200/319902 (16%)] Loss: 0.033626, 1 batch cost time 0.51
Train Epoch: 7 [51712/319902 (16%)] Loss: 0.039684, 1 batch cost time 0.51
Train Epoch: 7 [52224/319902 (16%)] Loss: 0.030008, 1 batch cost time 0.51
Train Epoch: 7 [52736/319902 (16%)] Loss: 0.043877, 1 batch cost time 0.51
Train Epoch: 7 [53248/319902 (17%)] Loss: 0.028173, 1 batch cost time 0.51
Train Epoch: 7 [53760/319902 (17%)] Loss: 0.041221, 1 batch cost time 0.51
Train Epoch: 7 [54272/319902 (17%)] Loss: 0.075521, 1 batch cost time 0.51
Train Epoch: 7 [54784/319902 (17%)] Loss: 0.035936, 1 batch cost time 0.51
Train Epoch: 7 [55296/319902 (17%)] Loss: 0.034354, 1 batch cost time 0.51
Train Epoch: 7 [55808/319902 (17%)] Loss: 0.029295, 1 batch cost time 0.51
Train Epoch: 7 [56320/319902 (18%)] Loss: 0.014127, 1 batch cost time 0.51
Train Epoch: 7 [56832/319902 (18%)] Loss: 0.040581, 1 batch cost time 0.51
Train Epoch: 7 [57344/319902 (18%)] Loss: 0.023398, 1 batch cost time 0.51
Train Epoch: 7 [57856/319902 (18%)] Loss: 0.027352, 1 batch cost time 0.51
Train Epoch: 7 [58368/319902 (18%)] Loss: 0.031035, 1 batch cost time 0.51
Train Epoch: 7 [58880/319902 (18%)] Loss: 0.014283, 1 batch cost time 0.51
Train Epoch: 7 [59392/319902 (19%)] Loss: 0.026069, 1 batch cost time 0.51
Train Epoch: 7 [59904/319902 (19%)] Loss: 0.024888, 1 batch cost time 0.51
Train Epoch: 7 [60416/319902 (19%)] Loss: 0.023206, 1 batch cost time 0.51
Train Epoch: 7 [60928/319902 (19%)] Loss: 0.034170, 1 batch cost time 0.51
Train Epoch: 7 [61440/319902 (19%)] Loss: 0.021587, 1 batch cost time 0.51
Train Epoch: 7 [61952/319902 (19%)] Loss: 0.047679, 1 batch cost time 0.51
Train Epoch: 7 [62464/319902 (20%)] Loss: 0.018477, 1 batch cost time 0.51
Train Epoch: 7 [62976/319902 (20%)] Loss: 0.017492, 1 batch cost time 0.51
Train Epoch: 7 [63488/319902 (20%)] Loss: 0.018895, 1 batch cost time 0.51
Train Epoch: 7 [64000/319902 (20%)] Loss: 0.025007, 1 batch cost time 0.51
Train Epoch: 7 [64512/319902 (20%)] Loss: 0.035770, 1 batch cost time 0.51
Train Epoch: 7 [65024/319902 (20%)] Loss: 0.042792, 1 batch cost time 0.51
Train Epoch: 7 [65536/319902 (20%)] Loss: 0.018370, 1 batch cost time 0.51
Train Epoch: 7 [66048/319902 (21%)] Loss: 0.027442, 1 batch cost time 0.51
Train Epoch: 7 [66560/319902 (21%)] Loss: 0.019754, 1 batch cost time 0.51
Train Epoch: 7 [67072/319902 (21%)] Loss: 0.028226, 1 batch cost time 0.51
Train Epoch: 7 [67584/319902 (21%)] Loss: 0.020856, 1 batch cost time 0.51
Train Epoch: 7 [68096/319902 (21%)] Loss: 0.026084, 1 batch cost time 0.51
Train Epoch: 7 [68608/319902 (21%)] Loss: 0.020543, 1 batch cost time 0.51
Train Epoch: 7 [69120/319902 (22%)] Loss: 0.029281, 1 batch cost time 0.51
Train Epoch: 7 [69632/319902 (22%)] Loss: 0.029507, 1 batch cost time 0.51
Train Epoch: 7 [70144/319902 (22%)] Loss: 0.019813, 1 batch cost time 0.51
Train Epoch: 7 [70656/319902 (22%)] Loss: 0.062564, 1 batch cost time 0.51
Train Epoch: 7 [71168/319902 (22%)] Loss: 0.047707, 1 batch cost time 0.51
Train Epoch: 7 [71680/319902 (22%)] Loss: 0.044274, 1 batch cost time 0.51
Train Epoch: 7 [72192/319902 (23%)] Loss: 0.031679, 1 batch cost time 0.51
Train Epoch: 7 [72704/319902 (23%)] Loss: 0.017193, 1 batch cost time 0.51
Train Epoch: 7 [73216/319902 (23%)] Loss: 0.039664, 1 batch cost time 0.51
Train Epoch: 7 [73728/319902 (23%)] Loss: 0.038441, 1 batch cost time 0.51
Train Epoch: 7 [74240/319902 (23%)] Loss: 0.042300, 1 batch cost time 0.51
Train Epoch: 7 [74752/319902 (23%)] Loss: 0.046717, 1 batch cost time 0.51
Train Epoch: 7 [75264/319902 (24%)] Loss: 0.032783, 1 batch cost time 0.51
Train Epoch: 7 [75776/319902 (24%)] Loss: 0.051552, 1 batch cost time 0.51
Train Epoch: 7 [76288/319902 (24%)] Loss: 0.016642, 1 batch cost time 0.51
Train Epoch: 7 [76800/319902 (24%)] Loss: 0.031272, 1 batch cost time 0.51
Train Epoch: 7 [77312/319902 (24%)] Loss: 0.013709, 1 batch cost time 0.51
Train Epoch: 7 [77824/319902 (24%)] Loss: 0.018671, 1 batch cost time 0.51
Train Epoch: 7 [78336/319902 (24%)] Loss: 0.027540, 1 batch cost time 0.51
Train Epoch: 7 [78848/319902 (25%)] Loss: 0.020034, 1 batch cost time 0.51
Train Epoch: 7 [79360/319902 (25%)] Loss: 0.023641, 1 batch cost time 0.51
Train Epoch: 7 [79872/319902 (25%)] Loss: 0.037864, 1 batch cost time 0.51
Train Epoch: 7 [80384/319902 (25%)] Loss: 0.028409, 1 batch cost time 0.51
Train Epoch: 7 [80896/319902 (25%)] Loss: 0.036386, 1 batch cost time 0.51
Train Epoch: 7 [81408/319902 (25%)] Loss: 0.014680, 1 batch cost time 0.51
Train Epoch: 7 [81920/319902 (26%)] Loss: 0.032646, 1 batch cost time 0.51
Train Epoch: 7 [82432/319902 (26%)] Loss: 0.024692, 1 batch cost time 0.51
Train Epoch: 7 [82944/319902 (26%)] Loss: 0.035866, 1 batch cost time 0.51
Train Epoch: 7 [83456/319902 (26%)] Loss: 0.058675, 1 batch cost time 0.51
Train Epoch: 7 [83968/319902 (26%)] Loss: 0.039696, 1 batch cost time 0.51
Train Epoch: 7 [84480/319902 (26%)] Loss: 0.031035, 1 batch cost time 0.51
Train Epoch: 7 [84992/319902 (27%)] Loss: 0.049365, 1 batch cost time 0.51
Train Epoch: 7 [85504/319902 (27%)] Loss: 0.018467, 1 batch cost time 0.51
Train Epoch: 7 [86016/319902 (27%)] Loss: 0.029636, 1 batch cost time 0.51
Train Epoch: 7 [86528/319902 (27%)] Loss: 0.028775, 1 batch cost time 0.51
Train Epoch: 7 [87040/319902 (27%)] Loss: 0.043690, 1 batch cost time 0.51
Train Epoch: 7 [87552/319902 (27%)] Loss: 0.025064, 1 batch cost time 0.51
Train Epoch: 7 [88064/319902 (28%)] Loss: 0.025757, 1 batch cost time 0.51
Train Epoch: 7 [88576/319902 (28%)] Loss: 0.032746, 1 batch cost time 0.51
Train Epoch: 7 [89088/319902 (28%)] Loss: 0.024664, 1 batch cost time 0.51
Train Epoch: 7 [89600/319902 (28%)] Loss: 0.042061, 1 batch cost time 0.51
Train Epoch: 7 [90112/319902 (28%)] Loss: 0.039565, 1 batch cost time 0.51
Train Epoch: 7 [90624/319902 (28%)] Loss: 0.031624, 1 batch cost time 0.51
Train Epoch: 7 [91136/319902 (28%)] Loss: 0.022827, 1 batch cost time 0.51
Train Epoch: 7 [91648/319902 (29%)] Loss: 0.017114, 1 batch cost time 0.51
Train Epoch: 7 [92160/319902 (29%)] Loss: 0.029807, 1 batch cost time 0.51
Train Epoch: 7 [92672/319902 (29%)] Loss: 0.020157, 1 batch cost time 0.51
Train Epoch: 7 [93184/319902 (29%)] Loss: 0.027245, 1 batch cost time 0.51
Train Epoch: 7 [93696/319902 (29%)] Loss: 0.029972, 1 batch cost time 0.51
Train Epoch: 7 [94208/319902 (29%)] Loss: 0.015793, 1 batch cost time 0.51
Train Epoch: 7 [94720/319902 (30%)] Loss: 0.021691, 1 batch cost time 0.51
Train Epoch: 7 [95232/319902 (30%)] Loss: 0.016295, 1 batch cost time 0.51
Train Epoch: 7 [95744/319902 (30%)] Loss: 0.010723, 1 batch cost time 0.51
Train Epoch: 7 [96256/319902 (30%)] Loss: 0.040842, 1 batch cost time 0.51
Train Epoch: 7 [96768/319902 (30%)] Loss: 0.041555, 1 batch cost time 0.51
Train Epoch: 7 [97280/319902 (30%)] Loss: 0.026239, 1 batch cost time 0.51
Train Epoch: 7 [97792/319902 (31%)] Loss: 0.035644, 1 batch cost time 0.51
Train Epoch: 7 [98304/319902 (31%)] Loss: 0.028557, 1 batch cost time 0.51
Train Epoch: 7 [98816/319902 (31%)] Loss: 0.024864, 1 batch cost time 0.51
Train Epoch: 7 [99328/319902 (31%)] Loss: 0.029721, 1 batch cost time 0.51
Train Epoch: 7 [99840/319902 (31%)] Loss: 0.024174, 1 batch cost time 0.51
Train Epoch: 7 [100352/319902 (31%)] Loss: 0.044035, 1 batch cost time 0.51
Train Epoch: 7 [100864/319902 (32%)] Loss: 0.020434, 1 batch cost time 0.51
Train Epoch: 7 [101376/319902 (32%)] Loss: 0.047751, 1 batch cost time 0.51
Train Epoch: 7 [101888/319902 (32%)] Loss: 0.047401, 1 batch cost time 0.51
Train Epoch: 7 [102400/319902 (32%)] Loss: 0.035721, 1 batch cost time 0.51
Train Epoch: 7 [102912/319902 (32%)] Loss: 0.054447, 1 batch cost time 0.51
Train Epoch: 7 [103424/319902 (32%)] Loss: 0.030228, 1 batch cost time 0.51
Train Epoch: 7 [103936/319902 (32%)] Loss: 0.019977, 1 batch cost time 0.51
Train Epoch: 7 [104448/319902 (33%)] Loss: 0.039481, 1 batch cost time 0.51
Train Epoch: 7 [104960/319902 (33%)] Loss: 0.019092, 1 batch cost time 0.51
Train Epoch: 7 [105472/319902 (33%)] Loss: 0.025126, 1 batch cost time 0.51
Train Epoch: 7 [105984/319902 (33%)] Loss: 0.008895, 1 batch cost time 0.51
Train Epoch: 7 [106496/319902 (33%)] Loss: 0.014735, 1 batch cost time 0.51
Train Epoch: 7 [107008/319902 (33%)] Loss: 0.016318, 1 batch cost time 0.51
Train Epoch: 7 [107520/319902 (34%)] Loss: 0.038814, 1 batch cost time 0.51
Train Epoch: 7 [108032/319902 (34%)] Loss: 0.022910, 1 batch cost time 0.51
Train Epoch: 7 [108544/319902 (34%)] Loss: 0.008938, 1 batch cost time 0.51
Train Epoch: 7 [109056/319902 (34%)] Loss: 0.055146, 1 batch cost time 0.51
Train Epoch: 7 [109568/319902 (34%)] Loss: 0.031658, 1 batch cost time 0.51
Train Epoch: 7 [110080/319902 (34%)] Loss: 0.011042, 1 batch cost time 0.51
Train Epoch: 7 [110592/319902 (35%)] Loss: 0.023564, 1 batch cost time 0.51
Train Epoch: 7 [111104/319902 (35%)] Loss: 0.034181, 1 batch cost time 0.51
Train Epoch: 7 [111616/319902 (35%)] Loss: 0.033573, 1 batch cost time 0.51
Train Epoch: 7 [112128/319902 (35%)] Loss: 0.035822, 1 batch cost time 0.51
Train Epoch: 7 [112640/319902 (35%)] Loss: 0.021911, 1 batch cost time 0.51
Train Epoch: 7 [113152/319902 (35%)] Loss: 0.027984, 1 batch cost time 0.51
Train Epoch: 7 [113664/319902 (36%)] Loss: 0.036370, 1 batch cost time 0.51
Train Epoch: 7 [114176/319902 (36%)] Loss: 0.040011, 1 batch cost time 0.51
Train Epoch: 7 [114688/319902 (36%)] Loss: 0.045409, 1 batch cost time 0.51
Train Epoch: 7 [115200/319902 (36%)] Loss: 0.028211, 1 batch cost time 0.51
Train Epoch: 7 [115712/319902 (36%)] Loss: 0.037133, 1 batch cost time 0.51
Train Epoch: 7 [116224/319902 (36%)] Loss: 0.040917, 1 batch cost time 0.51
Train Epoch: 7 [116736/319902 (36%)] Loss: 0.067634, 1 batch cost time 0.51
Train Epoch: 7 [117248/319902 (37%)] Loss: 0.028453, 1 batch cost time 0.51
Train Epoch: 7 [117760/319902 (37%)] Loss: 0.019211, 1 batch cost time 0.51
Train Epoch: 7 [118272/319902 (37%)] Loss: 0.021818, 1 batch cost time 0.51
Train Epoch: 7 [118784/319902 (37%)] Loss: 0.039180, 1 batch cost time 0.51
Train Epoch: 7 [119296/319902 (37%)] Loss: 0.044321, 1 batch cost time 0.51
Train Epoch: 7 [119808/319902 (37%)] Loss: 0.032639, 1 batch cost time 0.51
Train Epoch: 7 [120320/319902 (38%)] Loss: 0.022306, 1 batch cost time 0.51
Train Epoch: 7 [120832/319902 (38%)] Loss: 0.047202, 1 batch cost time 0.51
Train Epoch: 7 [121344/319902 (38%)] Loss: 0.021149, 1 batch cost time 0.51
Train Epoch: 7 [121856/319902 (38%)] Loss: 0.024141, 1 batch cost time 0.51
Train Epoch: 7 [122368/319902 (38%)] Loss: 0.018934, 1 batch cost time 0.51
Train Epoch: 7 [122880/319902 (38%)] Loss: 0.027931, 1 batch cost time 0.51
Train Epoch: 7 [123392/319902 (39%)] Loss: 0.041174, 1 batch cost time 0.51
Train Epoch: 7 [123904/319902 (39%)] Loss: 0.016086, 1 batch cost time 0.51
Train Epoch: 7 [124416/319902 (39%)] Loss: 0.026807, 1 batch cost time 0.51
Train Epoch: 7 [124928/319902 (39%)] Loss: 0.087999, 1 batch cost time 0.51
Train Epoch: 7 [125440/319902 (39%)] Loss: 0.024439, 1 batch cost time 0.51
Train Epoch: 7 [125952/319902 (39%)] Loss: 0.021084, 1 batch cost time 0.51
Train Epoch: 7 [126464/319902 (40%)] Loss: 0.026372, 1 batch cost time 0.51
Train Epoch: 7 [126976/319902 (40%)] Loss: 0.011199, 1 batch cost time 0.51
Train Epoch: 7 [127488/319902 (40%)] Loss: 0.034206, 1 batch cost time 0.51
Train Epoch: 7 [128000/319902 (40%)] Loss: 0.040163, 1 batch cost time 0.51
Train Epoch: 7 [128512/319902 (40%)] Loss: 0.033853, 1 batch cost time 0.51
Train Epoch: 7 [129024/319902 (40%)] Loss: 0.026206, 1 batch cost time 0.51
Train Epoch: 7 [129536/319902 (40%)] Loss: 0.034711, 1 batch cost time 0.51
Train Epoch: 7 [130048/319902 (41%)] Loss: 0.016794, 1 batch cost time 0.51
Train Epoch: 7 [130560/319902 (41%)] Loss: 0.015213, 1 batch cost time 0.51
Train Epoch: 7 [131072/319902 (41%)] Loss: 0.040995, 1 batch cost time 0.51
Train Epoch: 7 [131584/319902 (41%)] Loss: 0.041915, 1 batch cost time 0.51
Train Epoch: 7 [132096/319902 (41%)] Loss: 0.017777, 1 batch cost time 0.51
Train Epoch: 7 [132608/319902 (41%)] Loss: 0.016719, 1 batch cost time 0.51
Train Epoch: 7 [133120/319902 (42%)] Loss: 0.045034, 1 batch cost time 0.51
Train Epoch: 7 [133632/319902 (42%)] Loss: 0.026259, 1 batch cost time 0.51
Train Epoch: 7 [134144/319902 (42%)] Loss: 0.011310, 1 batch cost time 0.51
Train Epoch: 7 [134656/319902 (42%)] Loss: 0.045893, 1 batch cost time 0.51
Train Epoch: 7 [135168/319902 (42%)] Loss: 0.040629, 1 batch cost time 0.51
Train Epoch: 7 [135680/319902 (42%)] Loss: 0.022515, 1 batch cost time 0.51
Train Epoch: 7 [136192/319902 (43%)] Loss: 0.020023, 1 batch cost time 0.51
Train Epoch: 7 [136704/319902 (43%)] Loss: 0.027507, 1 batch cost time 0.51
Train Epoch: 7 [137216/319902 (43%)] Loss: 0.027136, 1 batch cost time 0.51
Train Epoch: 7 [137728/319902 (43%)] Loss: 0.045734, 1 batch cost time 0.51
Train Epoch: 7 [138240/319902 (43%)] Loss: 0.011078, 1 batch cost time 0.51
Train Epoch: 7 [138752/319902 (43%)] Loss: 0.028625, 1 batch cost time 0.51
Train Epoch: 7 [139264/319902 (44%)] Loss: 0.041824, 1 batch cost time 0.51
Train Epoch: 7 [139776/319902 (44%)] Loss: 0.013042, 1 batch cost time 0.51
Train Epoch: 7 [140288/319902 (44%)] Loss: 0.031311, 1 batch cost time 0.51
Train Epoch: 7 [140800/319902 (44%)] Loss: 0.009793, 1 batch cost time 0.51
Train Epoch: 7 [141312/319902 (44%)] Loss: 0.026715, 1 batch cost time 0.51
Train Epoch: 7 [141824/319902 (44%)] Loss: 0.013459, 1 batch cost time 0.51
Train Epoch: 7 [142336/319902 (44%)] Loss: 0.028864, 1 batch cost time 0.51
Train Epoch: 7 [142848/319902 (45%)] Loss: 0.035252, 1 batch cost time 0.51
Train Epoch: 7 [143360/319902 (45%)] Loss: 0.021460, 1 batch cost time 0.51
Train Epoch: 7 [143872/319902 (45%)] Loss: 0.046912, 1 batch cost time 0.51
Train Epoch: 7 [144384/319902 (45%)] Loss: 0.035455, 1 batch cost time 0.51
Train Epoch: 7 [144896/319902 (45%)] Loss: 0.006002, 1 batch cost time 0.51
Train Epoch: 7 [145408/319902 (45%)] Loss: 0.049730, 1 batch cost time 0.51
Train Epoch: 7 [145920/319902 (46%)] Loss: 0.040407, 1 batch cost time 0.51
Train Epoch: 7 [146432/319902 (46%)] Loss: 0.036086, 1 batch cost time 0.51
Train Epoch: 7 [146944/319902 (46%)] Loss: 0.017133, 1 batch cost time 0.51
Train Epoch: 7 [147456/319902 (46%)] Loss: 0.043527, 1 batch cost time 0.51
Train Epoch: 7 [147968/319902 (46%)] Loss: 0.033640, 1 batch cost time 0.51
Train Epoch: 7 [148480/319902 (46%)] Loss: 0.043622, 1 batch cost time 0.51
Train Epoch: 7 [148992/319902 (47%)] Loss: 0.047087, 1 batch cost time 0.51
Train Epoch: 7 [149504/319902 (47%)] Loss: 0.034942, 1 batch cost time 0.51
Train Epoch: 7 [150016/319902 (47%)] Loss: 0.030717, 1 batch cost time 0.51
Train Epoch: 7 [150528/319902 (47%)] Loss: 0.029034, 1 batch cost time 0.51
Train Epoch: 7 [151040/319902 (47%)] Loss: 0.012578, 1 batch cost time 0.51
Train Epoch: 7 [151552/319902 (47%)] Loss: 0.051400, 1 batch cost time 0.51
Train Epoch: 7 [152064/319902 (48%)] Loss: 0.022700, 1 batch cost time 0.51
Train Epoch: 7 [152576/319902 (48%)] Loss: 0.030036, 1 batch cost time 0.51
Train Epoch: 7 [153088/319902 (48%)] Loss: 0.037635, 1 batch cost time 0.51
Train Epoch: 7 [153600/319902 (48%)] Loss: 0.045360, 1 batch cost time 0.51
Train Epoch: 7 [154112/319902 (48%)] Loss: 0.041074, 1 batch cost time 0.51
Train Epoch: 7 [154624/319902 (48%)] Loss: 0.027950, 1 batch cost time 0.51
Train Epoch: 7 [155136/319902 (48%)] Loss: 0.032734, 1 batch cost time 0.51
Train Epoch: 7 [155648/319902 (49%)] Loss: 0.023047, 1 batch cost time 0.51
Train Epoch: 7 [156160/319902 (49%)] Loss: 0.018257, 1 batch cost time 0.51
Train Epoch: 7 [156672/319902 (49%)] Loss: 0.020805, 1 batch cost time 0.51
Train Epoch: 7 [157184/319902 (49%)] Loss: 0.021549, 1 batch cost time 0.51
Train Epoch: 7 [157696/319902 (49%)] Loss: 0.063769, 1 batch cost time 0.51
Train Epoch: 7 [158208/319902 (49%)] Loss: 0.044756, 1 batch cost time 0.51
Train Epoch: 7 [158720/319902 (50%)] Loss: 0.036832, 1 batch cost time 0.51
Train Epoch: 7 [159232/319902 (50%)] Loss: 0.065603, 1 batch cost time 0.51
Train Epoch: 7 [159744/319902 (50%)] Loss: 0.031323, 1 batch cost time 0.51
Train Epoch: 7 [160256/319902 (50%)] Loss: 0.025126, 1 batch cost time 0.51
Train Epoch: 7 [160768/319902 (50%)] Loss: 0.026256, 1 batch cost time 0.51
Train Epoch: 7 [161280/319902 (50%)] Loss: 0.037616, 1 batch cost time 0.51
Train Epoch: 7 [161792/319902 (51%)] Loss: 0.010333, 1 batch cost time 0.51
Train Epoch: 7 [162304/319902 (51%)] Loss: 0.043063, 1 batch cost time 0.51
Train Epoch: 7 [162816/319902 (51%)] Loss: 0.027001, 1 batch cost time 0.51
Train Epoch: 7 [163328/319902 (51%)] Loss: 0.016964, 1 batch cost time 0.51
Train Epoch: 7 [163840/319902 (51%)] Loss: 0.053818, 1 batch cost time 0.51
Train Epoch: 7 [164352/319902 (51%)] Loss: 0.030797, 1 batch cost time 0.51
Train Epoch: 7 [164864/319902 (52%)] Loss: 0.022223, 1 batch cost time 0.51
Train Epoch: 7 [165376/319902 (52%)] Loss: 0.013550, 1 batch cost time 0.51
Train Epoch: 7 [165888/319902 (52%)] Loss: 0.064700, 1 batch cost time 0.51
Train Epoch: 7 [166400/319902 (52%)] Loss: 0.029785, 1 batch cost time 0.51
Train Epoch: 7 [166912/319902 (52%)] Loss: 0.041528, 1 batch cost time 0.51
Train Epoch: 7 [167424/319902 (52%)] Loss: 0.013245, 1 batch cost time 0.51
Train Epoch: 7 [167936/319902 (52%)] Loss: 0.041124, 1 batch cost time 0.51
Train Epoch: 7 [168448/319902 (53%)] Loss: 0.035240, 1 batch cost time 0.51
Train Epoch: 7 [168960/319902 (53%)] Loss: 0.025749, 1 batch cost time 0.51
Train Epoch: 7 [169472/319902 (53%)] Loss: 0.047874, 1 batch cost time 0.51
Train Epoch: 7 [169984/319902 (53%)] Loss: 0.037174, 1 batch cost time 0.51
Train Epoch: 7 [170496/319902 (53%)] Loss: 0.058033, 1 batch cost time 0.51
Train Epoch: 7 [171008/319902 (53%)] Loss: 0.037391, 1 batch cost time 0.51
Train Epoch: 7 [171520/319902 (54%)] Loss: 0.018449, 1 batch cost time 0.51
Train Epoch: 7 [172032/319902 (54%)] Loss: 0.027981, 1 batch cost time 0.51
Train Epoch: 7 [172544/319902 (54%)] Loss: 0.043562, 1 batch cost time 0.51
Train Epoch: 7 [173056/319902 (54%)] Loss: 0.038194, 1 batch cost time 0.51
Train Epoch: 7 [173568/319902 (54%)] Loss: 0.019206, 1 batch cost time 0.51
Train Epoch: 7 [174080/319902 (54%)] Loss: 0.022707, 1 batch cost time 0.51
Train Epoch: 7 [174592/319902 (55%)] Loss: 0.015697, 1 batch cost time 0.51
Train Epoch: 7 [175104/319902 (55%)] Loss: 0.021806, 1 batch cost time 0.51
Train Epoch: 7 [175616/319902 (55%)] Loss: 0.042088, 1 batch cost time 0.51
Train Epoch: 7 [176128/319902 (55%)] Loss: 0.031781, 1 batch cost time 0.51
Train Epoch: 7 [176640/319902 (55%)] Loss: 0.041186, 1 batch cost time 0.51
Train Epoch: 7 [177152/319902 (55%)] Loss: 0.043718, 1 batch cost time 0.51
Train Epoch: 7 [177664/319902 (56%)] Loss: 0.029290, 1 batch cost time 0.51
Train Epoch: 7 [178176/319902 (56%)] Loss: 0.021804, 1 batch cost time 0.51
Train Epoch: 7 [178688/319902 (56%)] Loss: 0.018983, 1 batch cost time 0.51
Train Epoch: 7 [179200/319902 (56%)] Loss: 0.029350, 1 batch cost time 0.51
Train Epoch: 7 [179712/319902 (56%)] Loss: 0.040210, 1 batch cost time 0.51
Train Epoch: 7 [180224/319902 (56%)] Loss: 0.041170, 1 batch cost time 0.51
Train Epoch: 7 [180736/319902 (56%)] Loss: 0.023845, 1 batch cost time 0.51
Train Epoch: 7 [181248/319902 (57%)] Loss: 0.029679, 1 batch cost time 0.51
Train Epoch: 7 [181760/319902 (57%)] Loss: 0.047113, 1 batch cost time 0.51
Train Epoch: 7 [182272/319902 (57%)] Loss: 0.027615, 1 batch cost time 0.51
Train Epoch: 7 [182784/319902 (57%)] Loss: 0.040731, 1 batch cost time 0.51
Train Epoch: 7 [183296/319902 (57%)] Loss: 0.019827, 1 batch cost time 0.51
Train Epoch: 7 [183808/319902 (57%)] Loss: 0.037430, 1 batch cost time 0.51
Train Epoch: 7 [184320/319902 (58%)] Loss: 0.036640, 1 batch cost time 0.51
Train Epoch: 7 [184832/319902 (58%)] Loss: 0.014966, 1 batch cost time 0.51
Train Epoch: 7 [185344/319902 (58%)] Loss: 0.019451, 1 batch cost time 0.51
Train Epoch: 7 [185856/319902 (58%)] Loss: 0.047618, 1 batch cost time 0.51
Train Epoch: 7 [186368/319902 (58%)] Loss: 0.030527, 1 batch cost time 0.51
Train Epoch: 7 [186880/319902 (58%)] Loss: 0.014905, 1 batch cost time 0.51
Train Epoch: 7 [187392/319902 (59%)] Loss: 0.049757, 1 batch cost time 0.51
Train Epoch: 7 [187904/319902 (59%)] Loss: 0.019549, 1 batch cost time 0.51
Train Epoch: 7 [188416/319902 (59%)] Loss: 0.013589, 1 batch cost time 0.51
Train Epoch: 7 [188928/319902 (59%)] Loss: 0.019327, 1 batch cost time 0.51
Train Epoch: 7 [189440/319902 (59%)] Loss: 0.049621, 1 batch cost time 0.51
Train Epoch: 7 [189952/319902 (59%)] Loss: 0.025147, 1 batch cost time 0.51
Train Epoch: 7 [190464/319902 (60%)] Loss: 0.031503, 1 batch cost time 0.51
Train Epoch: 7 [190976/319902 (60%)] Loss: 0.016508, 1 batch cost time 0.51
Train Epoch: 7 [191488/319902 (60%)] Loss: 0.025366, 1 batch cost time 0.51
Train Epoch: 7 [192000/319902 (60%)] Loss: 0.037300, 1 batch cost time 0.51
Train Epoch: 7 [192512/319902 (60%)] Loss: 0.016594, 1 batch cost time 0.51
Train Epoch: 7 [193024/319902 (60%)] Loss: 0.029652, 1 batch cost time 0.51
Train Epoch: 7 [193536/319902 (60%)] Loss: 0.033973, 1 batch cost time 0.51
Train Epoch: 7 [194048/319902 (61%)] Loss: 0.017643, 1 batch cost time 0.51
Train Epoch: 7 [194560/319902 (61%)] Loss: 0.025197, 1 batch cost time 0.51
Train Epoch: 7 [195072/319902 (61%)] Loss: 0.042884, 1 batch cost time 0.51
Train Epoch: 7 [195584/319902 (61%)] Loss: 0.043541, 1 batch cost time 0.51
Train Epoch: 7 [196096/319902 (61%)] Loss: 0.011585, 1 batch cost time 0.51
Train Epoch: 7 [196608/319902 (61%)] Loss: 0.047325, 1 batch cost time 0.51
Train Epoch: 7 [197120/319902 (62%)] Loss: 0.046310, 1 batch cost time 0.51
Train Epoch: 7 [197632/319902 (62%)] Loss: 0.027688, 1 batch cost time 0.51
Train Epoch: 7 [198144/319902 (62%)] Loss: 0.039040, 1 batch cost time 0.51
Train Epoch: 7 [198656/319902 (62%)] Loss: 0.019283, 1 batch cost time 0.51
Train Epoch: 7 [199168/319902 (62%)] Loss: 0.026142, 1 batch cost time 0.51
Train Epoch: 7 [199680/319902 (62%)] Loss: 0.024290, 1 batch cost time 0.51
Train Epoch: 7 [200192/319902 (63%)] Loss: 0.026990, 1 batch cost time 0.51
Train Epoch: 7 [200704/319902 (63%)] Loss: 0.036236, 1 batch cost time 0.51
Train Epoch: 7 [201216/319902 (63%)] Loss: 0.042400, 1 batch cost time 0.51
Train Epoch: 7 [201728/319902 (63%)] Loss: 0.029973, 1 batch cost time 0.51
Train Epoch: 7 [202240/319902 (63%)] Loss: 0.016841, 1 batch cost time 0.51
Train Epoch: 7 [202752/319902 (63%)] Loss: 0.045840, 1 batch cost time 0.51
Train Epoch: 7 [203264/319902 (64%)] Loss: 0.014034, 1 batch cost time 0.51
Train Epoch: 7 [203776/319902 (64%)] Loss: 0.010740, 1 batch cost time 0.51
Train Epoch: 7 [204288/319902 (64%)] Loss: 0.058133, 1 batch cost time 0.51
Train Epoch: 7 [204800/319902 (64%)] Loss: 0.024616, 1 batch cost time 0.51
Train Epoch: 7 [205312/319902 (64%)] Loss: 0.027705, 1 batch cost time 0.51
Train Epoch: 7 [205824/319902 (64%)] Loss: 0.016847, 1 batch cost time 0.51
Train Epoch: 7 [206336/319902 (64%)] Loss: 0.063567, 1 batch cost time 0.51
Train Epoch: 7 [206848/319902 (65%)] Loss: 0.026881, 1 batch cost time 0.51
Train Epoch: 7 [207360/319902 (65%)] Loss: 0.030813, 1 batch cost time 0.51
Train Epoch: 7 [207872/319902 (65%)] Loss: 0.020983, 1 batch cost time 0.51
Train Epoch: 7 [208384/319902 (65%)] Loss: 0.034845, 1 batch cost time 0.51
Train Epoch: 7 [208896/319902 (65%)] Loss: 0.039485, 1 batch cost time 0.51
Train Epoch: 7 [209408/319902 (65%)] Loss: 0.022359, 1 batch cost time 0.51
Train Epoch: 7 [209920/319902 (66%)] Loss: 0.032116, 1 batch cost time 0.51
Train Epoch: 7 [210432/319902 (66%)] Loss: 0.027142, 1 batch cost time 0.51
Train Epoch: 7 [210944/319902 (66%)] Loss: 0.020967, 1 batch cost time 0.51
Train Epoch: 7 [211456/319902 (66%)] Loss: 0.055558, 1 batch cost time 0.51
Train Epoch: 7 [211968/319902 (66%)] Loss: 0.051960, 1 batch cost time 0.51
Train Epoch: 7 [212480/319902 (66%)] Loss: 0.040750, 1 batch cost time 0.51
Train Epoch: 7 [212992/319902 (67%)] Loss: 0.044691, 1 batch cost time 0.51
Train Epoch: 7 [213504/319902 (67%)] Loss: 0.028220, 1 batch cost time 0.51
Train Epoch: 7 [214016/319902 (67%)] Loss: 0.015566, 1 batch cost time 0.51
Train Epoch: 7 [214528/319902 (67%)] Loss: 0.035206, 1 batch cost time 0.51
Train Epoch: 7 [215040/319902 (67%)] Loss: 0.019618, 1 batch cost time 0.51
Train Epoch: 7 [215552/319902 (67%)] Loss: 0.017630, 1 batch cost time 0.51
Train Epoch: 7 [216064/319902 (68%)] Loss: 0.039861, 1 batch cost time 0.51
Train Epoch: 7 [216576/319902 (68%)] Loss: 0.041544, 1 batch cost time 0.51
Train Epoch: 7 [217088/319902 (68%)] Loss: 0.016989, 1 batch cost time 0.51
Train Epoch: 7 [217600/319902 (68%)] Loss: 0.042457, 1 batch cost time 0.51
Train Epoch: 7 [218112/319902 (68%)] Loss: 0.013584, 1 batch cost time 0.51
Train Epoch: 7 [218624/319902 (68%)] Loss: 0.017344, 1 batch cost time 0.51
Train Epoch: 7 [219136/319902 (69%)] Loss: 0.027677, 1 batch cost time 0.51
Train Epoch: 7 [219648/319902 (69%)] Loss: 0.036632, 1 batch cost time 0.51
Train Epoch: 7 [220160/319902 (69%)] Loss: 0.025029, 1 batch cost time 0.51
Train Epoch: 7 [220672/319902 (69%)] Loss: 0.034727, 1 batch cost time 0.51
Train Epoch: 7 [221184/319902 (69%)] Loss: 0.038368, 1 batch cost time 0.51
Train Epoch: 7 [221696/319902 (69%)] Loss: 0.030584, 1 batch cost time 0.51
Train Epoch: 7 [222208/319902 (69%)] Loss: 0.050113, 1 batch cost time 0.51
Train Epoch: 7 [222720/319902 (70%)] Loss: 0.030851, 1 batch cost time 0.51
Train Epoch: 7 [223232/319902 (70%)] Loss: 0.009061, 1 batch cost time 0.51
Train Epoch: 7 [223744/319902 (70%)] Loss: 0.023422, 1 batch cost time 0.51
Train Epoch: 7 [224256/319902 (70%)] Loss: 0.031198, 1 batch cost time 0.51
Train Epoch: 7 [224768/319902 (70%)] Loss: 0.059095, 1 batch cost time 0.51
Train Epoch: 7 [225280/319902 (70%)] Loss: 0.041635, 1 batch cost time 0.51
Train Epoch: 7 [225792/319902 (71%)] Loss: 0.022053, 1 batch cost time 0.51
Train Epoch: 7 [226304/319902 (71%)] Loss: 0.020859, 1 batch cost time 0.51
Train Epoch: 7 [226816/319902 (71%)] Loss: 0.029377, 1 batch cost time 0.51
Train Epoch: 7 [227328/319902 (71%)] Loss: 0.035760, 1 batch cost time 0.51
Train Epoch: 7 [227840/319902 (71%)] Loss: 0.054739, 1 batch cost time 0.51
Train Epoch: 7 [228352/319902 (71%)] Loss: 0.023908, 1 batch cost time 0.51
Train Epoch: 7 [228864/319902 (72%)] Loss: 0.021640, 1 batch cost time 0.51
Train Epoch: 7 [229376/319902 (72%)] Loss: 0.035097, 1 batch cost time 0.51
Train Epoch: 7 [229888/319902 (72%)] Loss: 0.026296, 1 batch cost time 0.51
Train Epoch: 7 [230400/319902 (72%)] Loss: 0.013590, 1 batch cost time 0.51
Train Epoch: 7 [230912/319902 (72%)] Loss: 0.030343, 1 batch cost time 0.51
Train Epoch: 7 [231424/319902 (72%)] Loss: 0.021835, 1 batch cost time 0.51
Train Epoch: 7 [231936/319902 (73%)] Loss: 0.039637, 1 batch cost time 0.51
Train Epoch: 7 [232448/319902 (73%)] Loss: 0.026357, 1 batch cost time 0.51
Train Epoch: 7 [232960/319902 (73%)] Loss: 0.055660, 1 batch cost time 0.51
Train Epoch: 7 [233472/319902 (73%)] Loss: 0.052687, 1 batch cost time 0.51
Train Epoch: 7 [233984/319902 (73%)] Loss: 0.033237, 1 batch cost time 0.51
Train Epoch: 7 [234496/319902 (73%)] Loss: 0.017216, 1 batch cost time 0.51
Train Epoch: 7 [235008/319902 (73%)] Loss: 0.055478, 1 batch cost time 0.51
Train Epoch: 7 [235520/319902 (74%)] Loss: 0.015204, 1 batch cost time 0.51
Train Epoch: 7 [236032/319902 (74%)] Loss: 0.012279, 1 batch cost time 0.51
Train Epoch: 7 [236544/319902 (74%)] Loss: 0.029028, 1 batch cost time 0.51
Train Epoch: 7 [237056/319902 (74%)] Loss: 0.029885, 1 batch cost time 0.51
Train Epoch: 7 [237568/319902 (74%)] Loss: 0.035781, 1 batch cost time 0.51
Train Epoch: 7 [238080/319902 (74%)] Loss: 0.044982, 1 batch cost time 0.51
Train Epoch: 7 [238592/319902 (75%)] Loss: 0.014515, 1 batch cost time 0.51
Train Epoch: 7 [239104/319902 (75%)] Loss: 0.027958, 1 batch cost time 0.51
Train Epoch: 7 [239616/319902 (75%)] Loss: 0.036896, 1 batch cost time 0.51
Train Epoch: 7 [240128/319902 (75%)] Loss: 0.017828, 1 batch cost time 0.51
Train Epoch: 7 [240640/319902 (75%)] Loss: 0.039163, 1 batch cost time 0.51
Train Epoch: 7 [241152/319902 (75%)] Loss: 0.042217, 1 batch cost time 0.51
Train Epoch: 7 [241664/319902 (76%)] Loss: 0.022301, 1 batch cost time 0.51
Train Epoch: 7 [242176/319902 (76%)] Loss: 0.015524, 1 batch cost time 0.51
Train Epoch: 7 [242688/319902 (76%)] Loss: 0.048429, 1 batch cost time 0.51
Train Epoch: 7 [243200/319902 (76%)] Loss: 0.032431, 1 batch cost time 0.51
Train Epoch: 7 [243712/319902 (76%)] Loss: 0.029620, 1 batch cost time 0.51
Train Epoch: 7 [244224/319902 (76%)] Loss: 0.029324, 1 batch cost time 0.51
Train Epoch: 7 [244736/319902 (77%)] Loss: 0.026661, 1 batch cost time 0.51
Train Epoch: 7 [245248/319902 (77%)] Loss: 0.029622, 1 batch cost time 0.51
Train Epoch: 7 [245760/319902 (77%)] Loss: 0.007357, 1 batch cost time 0.51
Train Epoch: 7 [246272/319902 (77%)] Loss: 0.017448, 1 batch cost time 0.51
Train Epoch: 7 [246784/319902 (77%)] Loss: 0.031444, 1 batch cost time 0.51
Train Epoch: 7 [247296/319902 (77%)] Loss: 0.030195, 1 batch cost time 0.51
Train Epoch: 7 [247808/319902 (77%)] Loss: 0.043539, 1 batch cost time 0.51
Train Epoch: 7 [248320/319902 (78%)] Loss: 0.031767, 1 batch cost time 0.51
Train Epoch: 7 [248832/319902 (78%)] Loss: 0.024825, 1 batch cost time 0.51
Train Epoch: 7 [249344/319902 (78%)] Loss: 0.034555, 1 batch cost time 0.51
Train Epoch: 7 [249856/319902 (78%)] Loss: 0.013120, 1 batch cost time 0.51
Train Epoch: 7 [250368/319902 (78%)] Loss: 0.026468, 1 batch cost time 0.51
Train Epoch: 7 [250880/319902 (78%)] Loss: 0.032005, 1 batch cost time 0.51
Train Epoch: 7 [251392/319902 (79%)] Loss: 0.014780, 1 batch cost time 0.51
Train Epoch: 7 [251904/319902 (79%)] Loss: 0.075865, 1 batch cost time 0.51
Train Epoch: 7 [252416/319902 (79%)] Loss: 0.014998, 1 batch cost time 0.51
Train Epoch: 7 [252928/319902 (79%)] Loss: 0.009037, 1 batch cost time 0.51
Train Epoch: 7 [253440/319902 (79%)] Loss: 0.031179, 1 batch cost time 0.51
Train Epoch: 7 [253952/319902 (79%)] Loss: 0.011289, 1 batch cost time 0.51
Train Epoch: 7 [254464/319902 (80%)] Loss: 0.028594, 1 batch cost time 0.51
Train Epoch: 7 [254976/319902 (80%)] Loss: 0.025919, 1 batch cost time 0.51
Train Epoch: 7 [255488/319902 (80%)] Loss: 0.029176, 1 batch cost time 0.51
Train Epoch: 7 [256000/319902 (80%)] Loss: 0.033110, 1 batch cost time 0.51
Train Epoch: 7 [256512/319902 (80%)] Loss: 0.017408, 1 batch cost time 0.51
Train Epoch: 7 [257024/319902 (80%)] Loss: 0.057448, 1 batch cost time 0.51
Train Epoch: 7 [257536/319902 (81%)] Loss: 0.055732, 1 batch cost time 0.51
Train Epoch: 7 [258048/319902 (81%)] Loss: 0.019149, 1 batch cost time 0.51
Train Epoch: 7 [258560/319902 (81%)] Loss: 0.038433, 1 batch cost time 0.51
Train Epoch: 7 [259072/319902 (81%)] Loss: 0.042644, 1 batch cost time 0.51
Train Epoch: 7 [259584/319902 (81%)] Loss: 0.026473, 1 batch cost time 0.51
Train Epoch: 7 [260096/319902 (81%)] Loss: 0.020793, 1 batch cost time 0.51
Train Epoch: 7 [260608/319902 (81%)] Loss: 0.022358, 1 batch cost time 0.51
Train Epoch: 7 [261120/319902 (82%)] Loss: 0.032486, 1 batch cost time 0.51
Train Epoch: 7 [261632/319902 (82%)] Loss: 0.021687, 1 batch cost time 0.51
Train Epoch: 7 [262144/319902 (82%)] Loss: 0.035301, 1 batch cost time 0.51
Train Epoch: 7 [262656/319902 (82%)] Loss: 0.056092, 1 batch cost time 0.51
Train Epoch: 7 [263168/319902 (82%)] Loss: 0.054234, 1 batch cost time 0.51
Train Epoch: 7 [263680/319902 (82%)] Loss: 0.038078, 1 batch cost time 0.51
Train Epoch: 7 [264192/319902 (83%)] Loss: 0.033032, 1 batch cost time 0.51
Train Epoch: 7 [264704/319902 (83%)] Loss: 0.032904, 1 batch cost time 0.51
Train Epoch: 7 [265216/319902 (83%)] Loss: 0.027410, 1 batch cost time 0.51
Train Epoch: 7 [265728/319902 (83%)] Loss: 0.024316, 1 batch cost time 0.51
Train Epoch: 7 [266240/319902 (83%)] Loss: 0.062132, 1 batch cost time 0.51
Train Epoch: 7 [266752/319902 (83%)] Loss: 0.038274, 1 batch cost time 0.51
Train Epoch: 7 [267264/319902 (84%)] Loss: 0.026945, 1 batch cost time 0.51
Train Epoch: 7 [267776/319902 (84%)] Loss: 0.022879, 1 batch cost time 0.51
Train Epoch: 7 [268288/319902 (84%)] Loss: 0.036260, 1 batch cost time 0.51
Train Epoch: 7 [268800/319902 (84%)] Loss: 0.019622, 1 batch cost time 0.51
Train Epoch: 7 [269312/319902 (84%)] Loss: 0.040950, 1 batch cost time 0.51
Train Epoch: 7 [269824/319902 (84%)] Loss: 0.029835, 1 batch cost time 0.51
Train Epoch: 7 [270336/319902 (85%)] Loss: 0.030025, 1 batch cost time 0.51
Train Epoch: 7 [270848/319902 (85%)] Loss: 0.028720, 1 batch cost time 0.51
Train Epoch: 7 [271360/319902 (85%)] Loss: 0.015812, 1 batch cost time 0.51
Train Epoch: 7 [271872/319902 (85%)] Loss: 0.030396, 1 batch cost time 0.51
Train Epoch: 7 [272384/319902 (85%)] Loss: 0.027893, 1 batch cost time 0.51
Train Epoch: 7 [272896/319902 (85%)] Loss: 0.034901, 1 batch cost time 0.51
Train Epoch: 7 [273408/319902 (85%)] Loss: 0.020590, 1 batch cost time 0.51
Train Epoch: 7 [273920/319902 (86%)] Loss: 0.025708, 1 batch cost time 0.51
Train Epoch: 7 [274432/319902 (86%)] Loss: 0.010606, 1 batch cost time 0.51
Train Epoch: 7 [274944/319902 (86%)] Loss: 0.032323, 1 batch cost time 0.51
Train Epoch: 7 [275456/319902 (86%)] Loss: 0.053761, 1 batch cost time 0.51
Train Epoch: 7 [275968/319902 (86%)] Loss: 0.033624, 1 batch cost time 0.51
Train Epoch: 7 [276480/319902 (86%)] Loss: 0.039251, 1 batch cost time 0.51
Train Epoch: 7 [276992/319902 (87%)] Loss: 0.030107, 1 batch cost time 0.51
Train Epoch: 7 [277504/319902 (87%)] Loss: 0.053703, 1 batch cost time 0.51
Train Epoch: 7 [278016/319902 (87%)] Loss: 0.065906, 1 batch cost time 0.51
Train Epoch: 7 [278528/319902 (87%)] Loss: 0.014839, 1 batch cost time 0.51
Train Epoch: 7 [279040/319902 (87%)] Loss: 0.033141, 1 batch cost time 0.51
Train Epoch: 7 [279552/319902 (87%)] Loss: 0.046393, 1 batch cost time 0.51
Train Epoch: 7 [280064/319902 (88%)] Loss: 0.021417, 1 batch cost time 0.51
Train Epoch: 7 [280576/319902 (88%)] Loss: 0.024550, 1 batch cost time 0.51
Train Epoch: 7 [281088/319902 (88%)] Loss: 0.017975, 1 batch cost time 0.51
Train Epoch: 7 [281600/319902 (88%)] Loss: 0.013178, 1 batch cost time 0.51
Train Epoch: 7 [282112/319902 (88%)] Loss: 0.041651, 1 batch cost time 0.51
Train Epoch: 7 [282624/319902 (88%)] Loss: 0.052665, 1 batch cost time 0.51
Train Epoch: 7 [283136/319902 (89%)] Loss: 0.034386, 1 batch cost time 0.51
Train Epoch: 7 [283648/319902 (89%)] Loss: 0.037558, 1 batch cost time 0.51
Train Epoch: 7 [284160/319902 (89%)] Loss: 0.048832, 1 batch cost time 0.51
Train Epoch: 7 [284672/319902 (89%)] Loss: 0.021352, 1 batch cost time 0.51
Train Epoch: 7 [285184/319902 (89%)] Loss: 0.044407, 1 batch cost time 0.51
Train Epoch: 7 [285696/319902 (89%)] Loss: 0.044316, 1 batch cost time 0.51
Train Epoch: 7 [286208/319902 (89%)] Loss: 0.075618, 1 batch cost time 0.51
Train Epoch: 7 [286720/319902 (90%)] Loss: 0.027203, 1 batch cost time 0.51
Train Epoch: 7 [287232/319902 (90%)] Loss: 0.026922, 1 batch cost time 0.51
Train Epoch: 7 [287744/319902 (90%)] Loss: 0.018731, 1 batch cost time 0.51
Train Epoch: 7 [288256/319902 (90%)] Loss: 0.020539, 1 batch cost time 0.51
Train Epoch: 7 [288768/319902 (90%)] Loss: 0.023473, 1 batch cost time 0.51
Train Epoch: 7 [289280/319902 (90%)] Loss: 0.030276, 1 batch cost time 0.51
Train Epoch: 7 [289792/319902 (91%)] Loss: 0.031869, 1 batch cost time 0.51
Train Epoch: 7 [290304/319902 (91%)] Loss: 0.016117, 1 batch cost time 0.51
Train Epoch: 7 [290816/319902 (91%)] Loss: 0.051936, 1 batch cost time 0.51
Train Epoch: 7 [291328/319902 (91%)] Loss: 0.048798, 1 batch cost time 0.51
Train Epoch: 7 [291840/319902 (91%)] Loss: 0.026082, 1 batch cost time 0.51
Train Epoch: 7 [292352/319902 (91%)] Loss: 0.028382, 1 batch cost time 0.51
Train Epoch: 7 [292864/319902 (92%)] Loss: 0.016859, 1 batch cost time 0.51
Train Epoch: 7 [293376/319902 (92%)] Loss: 0.033068, 1 batch cost time 0.51
Train Epoch: 7 [293888/319902 (92%)] Loss: 0.030092, 1 batch cost time 0.51
Train Epoch: 7 [294400/319902 (92%)] Loss: 0.020842, 1 batch cost time 0.51
Train Epoch: 7 [294912/319902 (92%)] Loss: 0.016918, 1 batch cost time 0.51
Train Epoch: 7 [295424/319902 (92%)] Loss: 0.036947, 1 batch cost time 0.51
Train Epoch: 7 [295936/319902 (93%)] Loss: 0.029087, 1 batch cost time 0.51
Train Epoch: 7 [296448/319902 (93%)] Loss: 0.025264, 1 batch cost time 0.51
Train Epoch: 7 [296960/319902 (93%)] Loss: 0.032384, 1 batch cost time 0.51
Train Epoch: 7 [297472/319902 (93%)] Loss: 0.049152, 1 batch cost time 0.51
Train Epoch: 7 [297984/319902 (93%)] Loss: 0.019373, 1 batch cost time 0.51
Train Epoch: 7 [298496/319902 (93%)] Loss: 0.022198, 1 batch cost time 0.51
Train Epoch: 7 [299008/319902 (93%)] Loss: 0.067897, 1 batch cost time 0.51
Train Epoch: 7 [299520/319902 (94%)] Loss: 0.020527, 1 batch cost time 0.51
Train Epoch: 7 [300032/319902 (94%)] Loss: 0.025224, 1 batch cost time 0.51
Train Epoch: 7 [300544/319902 (94%)] Loss: 0.016737, 1 batch cost time 0.51
Train Epoch: 7 [301056/319902 (94%)] Loss: 0.027868, 1 batch cost time 0.51
Train Epoch: 7 [301568/319902 (94%)] Loss: 0.033100, 1 batch cost time 0.51
Train Epoch: 7 [302080/319902 (94%)] Loss: 0.074682, 1 batch cost time 0.51
Train Epoch: 7 [302592/319902 (95%)] Loss: 0.021766, 1 batch cost time 0.51
Train Epoch: 7 [303104/319902 (95%)] Loss: 0.021041, 1 batch cost time 0.51
Train Epoch: 7 [303616/319902 (95%)] Loss: 0.024819, 1 batch cost time 0.51
Train Epoch: 7 [304128/319902 (95%)] Loss: 0.026603, 1 batch cost time 0.51
Train Epoch: 7 [304640/319902 (95%)] Loss: 0.009652, 1 batch cost time 0.51
Train Epoch: 7 [305152/319902 (95%)] Loss: 0.033606, 1 batch cost time 0.51
Train Epoch: 7 [305664/319902 (96%)] Loss: 0.025632, 1 batch cost time 0.51
Train Epoch: 7 [306176/319902 (96%)] Loss: 0.021699, 1 batch cost time 0.51
Train Epoch: 7 [306688/319902 (96%)] Loss: 0.042535, 1 batch cost time 0.51
Train Epoch: 7 [307200/319902 (96%)] Loss: 0.010096, 1 batch cost time 0.51
Train Epoch: 7 [307712/319902 (96%)] Loss: 0.023556, 1 batch cost time 0.51
Train Epoch: 7 [308224/319902 (96%)] Loss: 0.041804, 1 batch cost time 0.51
Train Epoch: 7 [308736/319902 (97%)] Loss: 0.033275, 1 batch cost time 0.51
Train Epoch: 7 [309248/319902 (97%)] Loss: 0.050286, 1 batch cost time 0.51
Train Epoch: 7 [309760/319902 (97%)] Loss: 0.027544, 1 batch cost time 0.51
Train Epoch: 7 [310272/319902 (97%)] Loss: 0.033447, 1 batch cost time 0.51
Train Epoch: 7 [310784/319902 (97%)] Loss: 0.016274, 1 batch cost time 0.51
Train Epoch: 7 [311296/319902 (97%)] Loss: 0.052436, 1 batch cost time 0.51
Train Epoch: 7 [311808/319902 (97%)] Loss: 0.022482, 1 batch cost time 0.51
Train Epoch: 7 [312320/319902 (98%)] Loss: 0.047474, 1 batch cost time 0.51
Train Epoch: 7 [312832/319902 (98%)] Loss: 0.033339, 1 batch cost time 0.51
Train Epoch: 7 [313344/319902 (98%)] Loss: 0.019312, 1 batch cost time 0.51
Train Epoch: 7 [313856/319902 (98%)] Loss: 0.018750, 1 batch cost time 0.51
Train Epoch: 7 [314368/319902 (98%)] Loss: 0.027757, 1 batch cost time 0.51
Train Epoch: 7 [314880/319902 (98%)] Loss: 0.042699, 1 batch cost time 0.51
Train Epoch: 7 [315392/319902 (99%)] Loss: 0.052004, 1 batch cost time 0.51
Train Epoch: 7 [315904/319902 (99%)] Loss: 0.050315, 1 batch cost time 0.51
Train Epoch: 7 [316416/319902 (99%)] Loss: 0.020289, 1 batch cost time 0.51
Train Epoch: 7 [316928/319902 (99%)] Loss: 0.075316, 1 batch cost time 0.51
Train Epoch: 7 [317440/319902 (99%)] Loss: 0.068285, 1 batch cost time 0.51
Train Epoch: 7 [317952/319902 (99%)] Loss: 0.044430, 1 batch cost time 0.51
Train Epoch: 7 [318464/319902 (100%)] Loss: 0.022633, 1 batch cost time 0.51
Train Epoch: 7 [318976/319902 (100%)] Loss: 0.043744, 1 batch cost time 0.51
Train Epoch: 7 [319488/319902 (100%)] Loss: 0.017856, 1 batch cost time 0.51
training epoch cost 8015.697295427322 seconds
    epoch          : 7
    lr             : 0.0001
    loss           : 0.03131209817446102
    accuracy       : 0.9317039315726291
    f_measure      : 0.5447963349416415
    val_loss       : 0.025136522580093395
    val_accuracy   : 0.9444173177083334
    val_f_measure  : 0.561438905423281
Saving current best: model_best.pth ...
Train Epoch: 8 [0/319902 (0%)] Loss: 0.036309, 1 batch cost time 0.53
Train Epoch: 8 [512/319902 (0%)] Loss: 0.034374, 1 batch cost time 0.51
Train Epoch: 8 [1024/319902 (0%)] Loss: 0.015298, 1 batch cost time 0.51
Train Epoch: 8 [1536/319902 (0%)] Loss: 0.032015, 1 batch cost time 0.51
Train Epoch: 8 [2048/319902 (1%)] Loss: 0.038784, 1 batch cost time 0.51
Train Epoch: 8 [2560/319902 (1%)] Loss: 0.031047, 1 batch cost time 0.51
Train Epoch: 8 [3072/319902 (1%)] Loss: 0.036020, 1 batch cost time 0.51
Train Epoch: 8 [3584/319902 (1%)] Loss: 0.018660, 1 batch cost time 0.51
Train Epoch: 8 [4096/319902 (1%)] Loss: 0.055718, 1 batch cost time 0.51
Train Epoch: 8 [4608/319902 (1%)] Loss: 0.022021, 1 batch cost time 0.51
Train Epoch: 8 [5120/319902 (2%)] Loss: 0.031503, 1 batch cost time 0.51
Train Epoch: 8 [5632/319902 (2%)] Loss: 0.021990, 1 batch cost time 0.51
Train Epoch: 8 [6144/319902 (2%)] Loss: 0.018847, 1 batch cost time 0.51
Train Epoch: 8 [6656/319902 (2%)] Loss: 0.017729, 1 batch cost time 0.51
Train Epoch: 8 [7168/319902 (2%)] Loss: 0.018307, 1 batch cost time 0.51
Train Epoch: 8 [7680/319902 (2%)] Loss: 0.041738, 1 batch cost time 0.51
Train Epoch: 8 [8192/319902 (3%)] Loss: 0.034421, 1 batch cost time 0.51
Train Epoch: 8 [8704/319902 (3%)] Loss: 0.018236, 1 batch cost time 0.51
Train Epoch: 8 [9216/319902 (3%)] Loss: 0.034954, 1 batch cost time 0.51
Train Epoch: 8 [9728/319902 (3%)] Loss: 0.015866, 1 batch cost time 0.51
Train Epoch: 8 [10240/319902 (3%)] Loss: 0.024771, 1 batch cost time 0.51
Train Epoch: 8 [10752/319902 (3%)] Loss: 0.025773, 1 batch cost time 0.51
Train Epoch: 8 [11264/319902 (4%)] Loss: 0.025262, 1 batch cost time 0.51
Train Epoch: 8 [11776/319902 (4%)] Loss: 0.021608, 1 batch cost time 0.51
Train Epoch: 8 [12288/319902 (4%)] Loss: 0.036446, 1 batch cost time 0.51
Train Epoch: 8 [12800/319902 (4%)] Loss: 0.039116, 1 batch cost time 0.51
Train Epoch: 8 [13312/319902 (4%)] Loss: 0.027894, 1 batch cost time 0.51
Train Epoch: 8 [13824/319902 (4%)] Loss: 0.042819, 1 batch cost time 0.51
Train Epoch: 8 [14336/319902 (4%)] Loss: 0.009630, 1 batch cost time 0.51
Train Epoch: 8 [14848/319902 (5%)] Loss: 0.033085, 1 batch cost time 0.51
Train Epoch: 8 [15360/319902 (5%)] Loss: 0.012343, 1 batch cost time 0.51
Train Epoch: 8 [15872/319902 (5%)] Loss: 0.008280, 1 batch cost time 0.51
Train Epoch: 8 [16384/319902 (5%)] Loss: 0.041352, 1 batch cost time 0.51
Train Epoch: 8 [16896/319902 (5%)] Loss: 0.031042, 1 batch cost time 0.51
Train Epoch: 8 [17408/319902 (5%)] Loss: 0.026455, 1 batch cost time 0.51
Train Epoch: 8 [17920/319902 (6%)] Loss: 0.044196, 1 batch cost time 0.51
Train Epoch: 8 [18432/319902 (6%)] Loss: 0.022020, 1 batch cost time 0.51
Train Epoch: 8 [18944/319902 (6%)] Loss: 0.061321, 1 batch cost time 0.51
Train Epoch: 8 [19456/319902 (6%)] Loss: 0.012875, 1 batch cost time 0.51
Train Epoch: 8 [19968/319902 (6%)] Loss: 0.027525, 1 batch cost time 0.51
Train Epoch: 8 [20480/319902 (6%)] Loss: 0.028871, 1 batch cost time 0.51
Train Epoch: 8 [20992/319902 (7%)] Loss: 0.037806, 1 batch cost time 0.51
Train Epoch: 8 [21504/319902 (7%)] Loss: 0.021294, 1 batch cost time 0.51
Train Epoch: 8 [22016/319902 (7%)] Loss: 0.030532, 1 batch cost time 0.51
Train Epoch: 8 [22528/319902 (7%)] Loss: 0.014849, 1 batch cost time 0.51
Train Epoch: 8 [23040/319902 (7%)] Loss: 0.040805, 1 batch cost time 0.51
Train Epoch: 8 [23552/319902 (7%)] Loss: 0.033632, 1 batch cost time 0.51
Train Epoch: 8 [24064/319902 (8%)] Loss: 0.011328, 1 batch cost time 0.51
Train Epoch: 8 [24576/319902 (8%)] Loss: 0.027662, 1 batch cost time 0.51
Train Epoch: 8 [25088/319902 (8%)] Loss: 0.032035, 1 batch cost time 0.51
Train Epoch: 8 [25600/319902 (8%)] Loss: 0.039339, 1 batch cost time 0.51
Train Epoch: 8 [26112/319902 (8%)] Loss: 0.022709, 1 batch cost time 0.51
Train Epoch: 8 [26624/319902 (8%)] Loss: 0.042961, 1 batch cost time 0.51
Train Epoch: 8 [27136/319902 (8%)] Loss: 0.014663, 1 batch cost time 0.51
Train Epoch: 8 [27648/319902 (9%)] Loss: 0.025287, 1 batch cost time 0.51
Train Epoch: 8 [28160/319902 (9%)] Loss: 0.018695, 1 batch cost time 0.51
Train Epoch: 8 [28672/319902 (9%)] Loss: 0.035208, 1 batch cost time 0.51
Train Epoch: 8 [29184/319902 (9%)] Loss: 0.027724, 1 batch cost time 0.51
Train Epoch: 8 [29696/319902 (9%)] Loss: 0.029612, 1 batch cost time 0.51
Train Epoch: 8 [30208/319902 (9%)] Loss: 0.012681, 1 batch cost time 0.51
Train Epoch: 8 [30720/319902 (10%)] Loss: 0.064613, 1 batch cost time 0.51
Train Epoch: 8 [31232/319902 (10%)] Loss: 0.023575, 1 batch cost time 0.51
Train Epoch: 8 [31744/319902 (10%)] Loss: 0.044108, 1 batch cost time 0.51
Train Epoch: 8 [32256/319902 (10%)] Loss: 0.027436, 1 batch cost time 0.51
Train Epoch: 8 [32768/319902 (10%)] Loss: 0.012549, 1 batch cost time 0.51
Train Epoch: 8 [33280/319902 (10%)] Loss: 0.026866, 1 batch cost time 0.51
Train Epoch: 8 [33792/319902 (11%)] Loss: 0.027069, 1 batch cost time 0.51
Train Epoch: 8 [34304/319902 (11%)] Loss: 0.059395, 1 batch cost time 0.51
Train Epoch: 8 [34816/319902 (11%)] Loss: 0.046359, 1 batch cost time 0.51
Train Epoch: 8 [35328/319902 (11%)] Loss: 0.042193, 1 batch cost time 0.51
Train Epoch: 8 [35840/319902 (11%)] Loss: 0.036789, 1 batch cost time 0.51
Train Epoch: 8 [36352/319902 (11%)] Loss: 0.057750, 1 batch cost time 0.51
Train Epoch: 8 [36864/319902 (12%)] Loss: 0.028909, 1 batch cost time 0.51
Train Epoch: 8 [37376/319902 (12%)] Loss: 0.026261, 1 batch cost time 0.51
Train Epoch: 8 [37888/319902 (12%)] Loss: 0.028851, 1 batch cost time 0.51
Train Epoch: 8 [38400/319902 (12%)] Loss: 0.056486, 1 batch cost time 0.51
Train Epoch: 8 [38912/319902 (12%)] Loss: 0.033227, 1 batch cost time 0.51
Train Epoch: 8 [39424/319902 (12%)] Loss: 0.025482, 1 batch cost time 0.51
Train Epoch: 8 [39936/319902 (12%)] Loss: 0.016924, 1 batch cost time 0.51
Train Epoch: 8 [40448/319902 (13%)] Loss: 0.022700, 1 batch cost time 0.51
Train Epoch: 8 [40960/319902 (13%)] Loss: 0.030891, 1 batch cost time 0.51
Train Epoch: 8 [41472/319902 (13%)] Loss: 0.046703, 1 batch cost time 0.51
Train Epoch: 8 [41984/319902 (13%)] Loss: 0.019310, 1 batch cost time 0.51
Train Epoch: 8 [42496/319902 (13%)] Loss: 0.026835, 1 batch cost time 0.51
Train Epoch: 8 [43008/319902 (13%)] Loss: 0.015730, 1 batch cost time 0.51
Train Epoch: 8 [43520/319902 (14%)] Loss: 0.052595, 1 batch cost time 0.51
Train Epoch: 8 [44032/319902 (14%)] Loss: 0.020233, 1 batch cost time 0.51
Train Epoch: 8 [44544/319902 (14%)] Loss: 0.021616, 1 batch cost time 0.51
Train Epoch: 8 [45056/319902 (14%)] Loss: 0.026252, 1 batch cost time 0.51
Train Epoch: 8 [45568/319902 (14%)] Loss: 0.017240, 1 batch cost time 0.51
Train Epoch: 8 [46080/319902 (14%)] Loss: 0.016203, 1 batch cost time 0.51
Train Epoch: 8 [46592/319902 (15%)] Loss: 0.027810, 1 batch cost time 0.51
Train Epoch: 8 [47104/319902 (15%)] Loss: 0.032514, 1 batch cost time 0.51
Train Epoch: 8 [47616/319902 (15%)] Loss: 0.047560, 1 batch cost time 0.51
Train Epoch: 8 [48128/319902 (15%)] Loss: 0.020189, 1 batch cost time 0.51
Train Epoch: 8 [48640/319902 (15%)] Loss: 0.028542, 1 batch cost time 0.51
Train Epoch: 8 [49152/319902 (15%)] Loss: 0.038958, 1 batch cost time 0.51
Train Epoch: 8 [49664/319902 (16%)] Loss: 0.042049, 1 batch cost time 0.51
Train Epoch: 8 [50176/319902 (16%)] Loss: 0.022357, 1 batch cost time 0.51
Train Epoch: 8 [50688/319902 (16%)] Loss: 0.021062, 1 batch cost time 0.51
Train Epoch: 8 [51200/319902 (16%)] Loss: 0.055983, 1 batch cost time 0.51
Train Epoch: 8 [51712/319902 (16%)] Loss: 0.047420, 1 batch cost time 0.51
Train Epoch: 8 [52224/319902 (16%)] Loss: 0.017303, 1 batch cost time 0.51
Train Epoch: 8 [52736/319902 (16%)] Loss: 0.013412, 1 batch cost time 0.51
Train Epoch: 8 [53248/319902 (17%)] Loss: 0.023058, 1 batch cost time 0.51
Train Epoch: 8 [53760/319902 (17%)] Loss: 0.029858, 1 batch cost time 0.51
Train Epoch: 8 [54272/319902 (17%)] Loss: 0.040052, 1 batch cost time 0.51
Train Epoch: 8 [54784/319902 (17%)] Loss: 0.022993, 1 batch cost time 0.51
Train Epoch: 8 [55296/319902 (17%)] Loss: 0.017121, 1 batch cost time 0.51
Train Epoch: 8 [55808/319902 (17%)] Loss: 0.023868, 1 batch cost time 0.51
Train Epoch: 8 [56320/319902 (18%)] Loss: 0.021535, 1 batch cost time 0.51
Train Epoch: 8 [56832/319902 (18%)] Loss: 0.037248, 1 batch cost time 0.51
Train Epoch: 8 [57344/319902 (18%)] Loss: 0.035164, 1 batch cost time 0.51
Train Epoch: 8 [57856/319902 (18%)] Loss: 0.041692, 1 batch cost time 0.51
Train Epoch: 8 [58368/319902 (18%)] Loss: 0.036448, 1 batch cost time 0.51
Train Epoch: 8 [58880/319902 (18%)] Loss: 0.023935, 1 batch cost time 0.51
Train Epoch: 8 [59392/319902 (19%)] Loss: 0.056672, 1 batch cost time 0.51
Train Epoch: 8 [59904/319902 (19%)] Loss: 0.060157, 1 batch cost time 0.51
Train Epoch: 8 [60416/319902 (19%)] Loss: 0.036562, 1 batch cost time 0.51
Train Epoch: 8 [60928/319902 (19%)] Loss: 0.028473, 1 batch cost time 0.51
Train Epoch: 8 [61440/319902 (19%)] Loss: 0.017157, 1 batch cost time 0.51
Train Epoch: 8 [61952/319902 (19%)] Loss: 0.025168, 1 batch cost time 0.51
Train Epoch: 8 [62464/319902 (20%)] Loss: 0.026141, 1 batch cost time 0.51
Train Epoch: 8 [62976/319902 (20%)] Loss: 0.018109, 1 batch cost time 0.51
Train Epoch: 8 [63488/319902 (20%)] Loss: 0.026995, 1 batch cost time 0.51
Train Epoch: 8 [64000/319902 (20%)] Loss: 0.023068, 1 batch cost time 0.51
Train Epoch: 8 [64512/319902 (20%)] Loss: 0.050577, 1 batch cost time 0.51
Train Epoch: 8 [65024/319902 (20%)] Loss: 0.027102, 1 batch cost time 0.51
Train Epoch: 8 [65536/319902 (20%)] Loss: 0.034232, 1 batch cost time 0.51
Train Epoch: 8 [66048/319902 (21%)] Loss: 0.031586, 1 batch cost time 0.51
Train Epoch: 8 [66560/319902 (21%)] Loss: 0.035080, 1 batch cost time 0.51
Train Epoch: 8 [67072/319902 (21%)] Loss: 0.046172, 1 batch cost time 0.51
Train Epoch: 8 [67584/319902 (21%)] Loss: 0.030495, 1 batch cost time 0.51
Train Epoch: 8 [68096/319902 (21%)] Loss: 0.018329, 1 batch cost time 0.51
Train Epoch: 8 [68608/319902 (21%)] Loss: 0.023918, 1 batch cost time 0.51
Train Epoch: 8 [69120/319902 (22%)] Loss: 0.018363, 1 batch cost time 0.51
Train Epoch: 8 [69632/319902 (22%)] Loss: 0.034275, 1 batch cost time 0.51
Train Epoch: 8 [70144/319902 (22%)] Loss: 0.013300, 1 batch cost time 0.51
Train Epoch: 8 [70656/319902 (22%)] Loss: 0.042639, 1 batch cost time 0.51
Train Epoch: 8 [71168/319902 (22%)] Loss: 0.023028, 1 batch cost time 0.51
Train Epoch: 8 [71680/319902 (22%)] Loss: 0.021399, 1 batch cost time 0.51
Train Epoch: 8 [72192/319902 (23%)] Loss: 0.037741, 1 batch cost time 0.51
Train Epoch: 8 [72704/319902 (23%)] Loss: 0.014765, 1 batch cost time 0.51
Train Epoch: 8 [73216/319902 (23%)] Loss: 0.055845, 1 batch cost time 0.51
Train Epoch: 8 [73728/319902 (23%)] Loss: 0.028960, 1 batch cost time 0.51
Train Epoch: 8 [74240/319902 (23%)] Loss: 0.017360, 1 batch cost time 0.51
Train Epoch: 8 [74752/319902 (23%)] Loss: 0.024201, 1 batch cost time 0.51
Train Epoch: 8 [75264/319902 (24%)] Loss: 0.019566, 1 batch cost time 0.51
Train Epoch: 8 [75776/319902 (24%)] Loss: 0.026834, 1 batch cost time 0.51
Train Epoch: 8 [76288/319902 (24%)] Loss: 0.011369, 1 batch cost time 0.51
Train Epoch: 8 [76800/319902 (24%)] Loss: 0.027325, 1 batch cost time 0.51
Train Epoch: 8 [77312/319902 (24%)] Loss: 0.023621, 1 batch cost time 0.52
Train Epoch: 8 [77824/319902 (24%)] Loss: 0.024751, 1 batch cost time 0.51
Train Epoch: 8 [78336/319902 (24%)] Loss: 0.035975, 1 batch cost time 0.51
Train Epoch: 8 [78848/319902 (25%)] Loss: 0.019740, 1 batch cost time 0.51
Train Epoch: 8 [79360/319902 (25%)] Loss: 0.036002, 1 batch cost time 0.51
Train Epoch: 8 [79872/319902 (25%)] Loss: 0.020199, 1 batch cost time 0.51
Train Epoch: 8 [80384/319902 (25%)] Loss: 0.018779, 1 batch cost time 0.51
Train Epoch: 8 [80896/319902 (25%)] Loss: 0.050246, 1 batch cost time 0.51
Train Epoch: 8 [81408/319902 (25%)] Loss: 0.065772, 1 batch cost time 0.51
Train Epoch: 8 [81920/319902 (26%)] Loss: 0.036536, 1 batch cost time 0.51
Train Epoch: 8 [82432/319902 (26%)] Loss: 0.023632, 1 batch cost time 0.51
Train Epoch: 8 [82944/319902 (26%)] Loss: 0.041920, 1 batch cost time 0.51
Train Epoch: 8 [83456/319902 (26%)] Loss: 0.008603, 1 batch cost time 0.51
Train Epoch: 8 [83968/319902 (26%)] Loss: 0.036059, 1 batch cost time 0.51
Train Epoch: 8 [84480/319902 (26%)] Loss: 0.044398, 1 batch cost time 0.51
Train Epoch: 8 [84992/319902 (27%)] Loss: 0.029149, 1 batch cost time 0.51
Train Epoch: 8 [85504/319902 (27%)] Loss: 0.019323, 1 batch cost time 0.51
Train Epoch: 8 [86016/319902 (27%)] Loss: 0.026971, 1 batch cost time 0.51
Train Epoch: 8 [86528/319902 (27%)] Loss: 0.027805, 1 batch cost time 0.51
Train Epoch: 8 [87040/319902 (27%)] Loss: 0.013065, 1 batch cost time 0.51
Train Epoch: 8 [87552/319902 (27%)] Loss: 0.017279, 1 batch cost time 0.51
Train Epoch: 8 [88064/319902 (28%)] Loss: 0.031613, 1 batch cost time 0.51
Train Epoch: 8 [88576/319902 (28%)] Loss: 0.039988, 1 batch cost time 0.52
Train Epoch: 8 [89088/319902 (28%)] Loss: 0.013123, 1 batch cost time 0.51
Train Epoch: 8 [89600/319902 (28%)] Loss: 0.013646, 1 batch cost time 0.51
Train Epoch: 8 [90112/319902 (28%)] Loss: 0.011571, 1 batch cost time 0.51
Train Epoch: 8 [90624/319902 (28%)] Loss: 0.029154, 1 batch cost time 0.51
Train Epoch: 8 [91136/319902 (28%)] Loss: 0.019270, 1 batch cost time 0.51
Train Epoch: 8 [91648/319902 (29%)] Loss: 0.020654, 1 batch cost time 0.51
Train Epoch: 8 [92160/319902 (29%)] Loss: 0.017444, 1 batch cost time 0.51
Train Epoch: 8 [92672/319902 (29%)] Loss: 0.049222, 1 batch cost time 0.51
Train Epoch: 8 [93184/319902 (29%)] Loss: 0.051776, 1 batch cost time 0.51
Train Epoch: 8 [93696/319902 (29%)] Loss: 0.046613, 1 batch cost time 0.51
Train Epoch: 8 [94208/319902 (29%)] Loss: 0.016475, 1 batch cost time 0.51
Train Epoch: 8 [94720/319902 (30%)] Loss: 0.034239, 1 batch cost time 0.51
Train Epoch: 8 [95232/319902 (30%)] Loss: 0.035270, 1 batch cost time 0.51
Train Epoch: 8 [95744/319902 (30%)] Loss: 0.040730, 1 batch cost time 0.51
Train Epoch: 8 [96256/319902 (30%)] Loss: 0.023003, 1 batch cost time 0.51
Train Epoch: 8 [96768/319902 (30%)] Loss: 0.014961, 1 batch cost time 0.51
Train Epoch: 8 [97280/319902 (30%)] Loss: 0.035981, 1 batch cost time 0.51
Train Epoch: 8 [97792/319902 (31%)] Loss: 0.031026, 1 batch cost time 0.51
Train Epoch: 8 [98304/319902 (31%)] Loss: 0.028414, 1 batch cost time 0.51
Train Epoch: 8 [98816/319902 (31%)] Loss: 0.027125, 1 batch cost time 0.51
Train Epoch: 8 [99328/319902 (31%)] Loss: 0.027140, 1 batch cost time 0.51
Train Epoch: 8 [99840/319902 (31%)] Loss: 0.024984, 1 batch cost time 0.51
Train Epoch: 8 [100352/319902 (31%)] Loss: 0.031426, 1 batch cost time 0.51
Train Epoch: 8 [100864/319902 (32%)] Loss: 0.025723, 1 batch cost time 0.51
Train Epoch: 8 [101376/319902 (32%)] Loss: 0.042758, 1 batch cost time 0.51
Train Epoch: 8 [101888/319902 (32%)] Loss: 0.018869, 1 batch cost time 0.51
Train Epoch: 8 [102400/319902 (32%)] Loss: 0.022660, 1 batch cost time 0.51
Train Epoch: 8 [102912/319902 (32%)] Loss: 0.007518, 1 batch cost time 0.51
Train Epoch: 8 [103424/319902 (32%)] Loss: 0.015572, 1 batch cost time 0.51
Train Epoch: 8 [103936/319902 (32%)] Loss: 0.052975, 1 batch cost time 0.51
Train Epoch: 8 [104448/319902 (33%)] Loss: 0.032337, 1 batch cost time 0.51
Train Epoch: 8 [104960/319902 (33%)] Loss: 0.048318, 1 batch cost time 0.51
Train Epoch: 8 [105472/319902 (33%)] Loss: 0.027367, 1 batch cost time 0.51
Train Epoch: 8 [105984/319902 (33%)] Loss: 0.033183, 1 batch cost time 0.51
Train Epoch: 8 [106496/319902 (33%)] Loss: 0.019576, 1 batch cost time 0.51
Train Epoch: 8 [107008/319902 (33%)] Loss: 0.026911, 1 batch cost time 0.51
Train Epoch: 8 [107520/319902 (34%)] Loss: 0.017373, 1 batch cost time 0.51
Train Epoch: 8 [108032/319902 (34%)] Loss: 0.021407, 1 batch cost time 0.51
Train Epoch: 8 [108544/319902 (34%)] Loss: 0.040933, 1 batch cost time 0.51
Train Epoch: 8 [109056/319902 (34%)] Loss: 0.030610, 1 batch cost time 0.51
Train Epoch: 8 [109568/319902 (34%)] Loss: 0.038758, 1 batch cost time 0.51
Train Epoch: 8 [110080/319902 (34%)] Loss: 0.036657, 1 batch cost time 0.51
Train Epoch: 8 [110592/319902 (35%)] Loss: 0.024361, 1 batch cost time 0.51
Train Epoch: 8 [111104/319902 (35%)] Loss: 0.036526, 1 batch cost time 0.51
Train Epoch: 8 [111616/319902 (35%)] Loss: 0.037714, 1 batch cost time 0.51
Train Epoch: 8 [112128/319902 (35%)] Loss: 0.032247, 1 batch cost time 0.51
Train Epoch: 8 [112640/319902 (35%)] Loss: 0.022475, 1 batch cost time 0.51
Train Epoch: 8 [113152/319902 (35%)] Loss: 0.018183, 1 batch cost time 0.51
Train Epoch: 8 [113664/319902 (36%)] Loss: 0.029922, 1 batch cost time 0.51
Train Epoch: 8 [114176/319902 (36%)] Loss: 0.038932, 1 batch cost time 0.51
Train Epoch: 8 [114688/319902 (36%)] Loss: 0.051759, 1 batch cost time 0.51
Train Epoch: 8 [115200/319902 (36%)] Loss: 0.012490, 1 batch cost time 0.51
Train Epoch: 8 [115712/319902 (36%)] Loss: 0.036341, 1 batch cost time 0.51
Train Epoch: 8 [116224/319902 (36%)] Loss: 0.045254, 1 batch cost time 0.51
Train Epoch: 8 [116736/319902 (36%)] Loss: 0.028205, 1 batch cost time 0.51
Train Epoch: 8 [117248/319902 (37%)] Loss: 0.029105, 1 batch cost time 0.51
Train Epoch: 8 [117760/319902 (37%)] Loss: 0.044014, 1 batch cost time 0.51
Train Epoch: 8 [118272/319902 (37%)] Loss: 0.022597, 1 batch cost time 0.51
Train Epoch: 8 [118784/319902 (37%)] Loss: 0.035462, 1 batch cost time 0.51
Train Epoch: 8 [119296/319902 (37%)] Loss: 0.012749, 1 batch cost time 0.51
Train Epoch: 8 [119808/319902 (37%)] Loss: 0.034652, 1 batch cost time 0.51
Train Epoch: 8 [120320/319902 (38%)] Loss: 0.028235, 1 batch cost time 0.51
Train Epoch: 8 [120832/319902 (38%)] Loss: 0.016328, 1 batch cost time 0.51
Train Epoch: 8 [121344/319902 (38%)] Loss: 0.029192, 1 batch cost time 0.51
Train Epoch: 8 [121856/319902 (38%)] Loss: 0.026703, 1 batch cost time 0.51
Train Epoch: 8 [122368/319902 (38%)] Loss: 0.032748, 1 batch cost time 0.51
Train Epoch: 8 [122880/319902 (38%)] Loss: 0.048878, 1 batch cost time 0.51
Train Epoch: 8 [123392/319902 (39%)] Loss: 0.043884, 1 batch cost time 0.51
Train Epoch: 8 [123904/319902 (39%)] Loss: 0.030619, 1 batch cost time 0.51
Train Epoch: 8 [124416/319902 (39%)] Loss: 0.030196, 1 batch cost time 0.51
Train Epoch: 8 [124928/319902 (39%)] Loss: 0.034800, 1 batch cost time 0.51
Train Epoch: 8 [125440/319902 (39%)] Loss: 0.011103, 1 batch cost time 0.51
Train Epoch: 8 [125952/319902 (39%)] Loss: 0.019615, 1 batch cost time 0.51
Train Epoch: 8 [126464/319902 (40%)] Loss: 0.035678, 1 batch cost time 0.51
Train Epoch: 8 [126976/319902 (40%)] Loss: 0.057190, 1 batch cost time 0.51
Train Epoch: 8 [127488/319902 (40%)] Loss: 0.029800, 1 batch cost time 0.51
Train Epoch: 8 [128000/319902 (40%)] Loss: 0.025639, 1 batch cost time 0.51
Train Epoch: 8 [128512/319902 (40%)] Loss: 0.011818, 1 batch cost time 0.51
Train Epoch: 8 [129024/319902 (40%)] Loss: 0.017474, 1 batch cost time 0.51
Train Epoch: 8 [129536/319902 (40%)] Loss: 0.038041, 1 batch cost time 0.51
Train Epoch: 8 [130048/319902 (41%)] Loss: 0.023250, 1 batch cost time 0.51
Train Epoch: 8 [130560/319902 (41%)] Loss: 0.033764, 1 batch cost time 0.51
Train Epoch: 8 [131072/319902 (41%)] Loss: 0.044984, 1 batch cost time 0.51
Train Epoch: 8 [131584/319902 (41%)] Loss: 0.032315, 1 batch cost time 0.51
Train Epoch: 8 [132096/319902 (41%)] Loss: 0.013409, 1 batch cost time 0.51
Train Epoch: 8 [132608/319902 (41%)] Loss: 0.048251, 1 batch cost time 0.51
Train Epoch: 8 [133120/319902 (42%)] Loss: 0.022989, 1 batch cost time 0.51
Train Epoch: 8 [133632/319902 (42%)] Loss: 0.020247, 1 batch cost time 0.51
Train Epoch: 8 [134144/319902 (42%)] Loss: 0.009969, 1 batch cost time 0.51
Train Epoch: 8 [134656/319902 (42%)] Loss: 0.033186, 1 batch cost time 0.51
Train Epoch: 8 [135168/319902 (42%)] Loss: 0.040444, 1 batch cost time 0.51
Train Epoch: 8 [135680/319902 (42%)] Loss: 0.030536, 1 batch cost time 0.51
Train Epoch: 8 [136192/319902 (43%)] Loss: 0.024301, 1 batch cost time 0.51
Train Epoch: 8 [136704/319902 (43%)] Loss: 0.020512, 1 batch cost time 0.51
Train Epoch: 8 [137216/319902 (43%)] Loss: 0.031625, 1 batch cost time 0.51
Train Epoch: 8 [137728/319902 (43%)] Loss: 0.025793, 1 batch cost time 0.51
Train Epoch: 8 [138240/319902 (43%)] Loss: 0.044282, 1 batch cost time 0.51
Train Epoch: 8 [138752/319902 (43%)] Loss: 0.018000, 1 batch cost time 0.51
Train Epoch: 8 [139264/319902 (44%)] Loss: 0.020759, 1 batch cost time 0.51
Train Epoch: 8 [139776/319902 (44%)] Loss: 0.015578, 1 batch cost time 0.51
Train Epoch: 8 [140288/319902 (44%)] Loss: 0.058496, 1 batch cost time 0.51
Train Epoch: 8 [140800/319902 (44%)] Loss: 0.030887, 1 batch cost time 0.51
Train Epoch: 8 [141312/319902 (44%)] Loss: 0.021531, 1 batch cost time 0.51
Train Epoch: 8 [141824/319902 (44%)] Loss: 0.033886, 1 batch cost time 0.51
Train Epoch: 8 [142336/319902 (44%)] Loss: 0.019461, 1 batch cost time 0.51
Train Epoch: 8 [142848/319902 (45%)] Loss: 0.016136, 1 batch cost time 0.51
Train Epoch: 8 [143360/319902 (45%)] Loss: 0.020070, 1 batch cost time 0.51
Train Epoch: 8 [143872/319902 (45%)] Loss: 0.035453, 1 batch cost time 0.51
Train Epoch: 8 [144384/319902 (45%)] Loss: 0.019321, 1 batch cost time 0.51
Train Epoch: 8 [144896/319902 (45%)] Loss: 0.040745, 1 batch cost time 0.51
Train Epoch: 8 [145408/319902 (45%)] Loss: 0.017836, 1 batch cost time 0.51
Train Epoch: 8 [145920/319902 (46%)] Loss: 0.020794, 1 batch cost time 0.51
Train Epoch: 8 [146432/319902 (46%)] Loss: 0.022560, 1 batch cost time 0.51
Train Epoch: 8 [146944/319902 (46%)] Loss: 0.043508, 1 batch cost time 0.51
Train Epoch: 8 [147456/319902 (46%)] Loss: 0.014213, 1 batch cost time 0.51
Train Epoch: 8 [147968/319902 (46%)] Loss: 0.036087, 1 batch cost time 0.51
Train Epoch: 8 [148480/319902 (46%)] Loss: 0.028545, 1 batch cost time 0.51
Train Epoch: 8 [148992/319902 (47%)] Loss: 0.030062, 1 batch cost time 0.51
Train Epoch: 8 [149504/319902 (47%)] Loss: 0.023899, 1 batch cost time 0.51
Train Epoch: 8 [150016/319902 (47%)] Loss: 0.017058, 1 batch cost time 0.51
Train Epoch: 8 [150528/319902 (47%)] Loss: 0.028774, 1 batch cost time 0.51
Train Epoch: 8 [151040/319902 (47%)] Loss: 0.013996, 1 batch cost time 0.51
Train Epoch: 8 [151552/319902 (47%)] Loss: 0.022211, 1 batch cost time 0.51
Train Epoch: 8 [152064/319902 (48%)] Loss: 0.022679, 1 batch cost time 0.51
Train Epoch: 8 [152576/319902 (48%)] Loss: 0.030281, 1 batch cost time 0.51
Train Epoch: 8 [153088/319902 (48%)] Loss: 0.030719, 1 batch cost time 0.51
Train Epoch: 8 [153600/319902 (48%)] Loss: 0.026860, 1 batch cost time 0.51
Train Epoch: 8 [154112/319902 (48%)] Loss: 0.033843, 1 batch cost time 0.51
Train Epoch: 8 [154624/319902 (48%)] Loss: 0.011407, 1 batch cost time 0.51
Train Epoch: 8 [155136/319902 (48%)] Loss: 0.042619, 1 batch cost time 0.51
Train Epoch: 8 [155648/319902 (49%)] Loss: 0.044156, 1 batch cost time 0.51
Train Epoch: 8 [156160/319902 (49%)] Loss: 0.025434, 1 batch cost time 0.51
Train Epoch: 8 [156672/319902 (49%)] Loss: 0.016292, 1 batch cost time 0.51
Train Epoch: 8 [157184/319902 (49%)] Loss: 0.027975, 1 batch cost time 0.51
Train Epoch: 8 [157696/319902 (49%)] Loss: 0.068562, 1 batch cost time 0.51
Train Epoch: 8 [158208/319902 (49%)] Loss: 0.019727, 1 batch cost time 0.51
Train Epoch: 8 [158720/319902 (50%)] Loss: 0.048474, 1 batch cost time 0.51
Train Epoch: 8 [159232/319902 (50%)] Loss: 0.028524, 1 batch cost time 0.51
Train Epoch: 8 [159744/319902 (50%)] Loss: 0.049431, 1 batch cost time 0.51
Train Epoch: 8 [160256/319902 (50%)] Loss: 0.037052, 1 batch cost time 0.51
Train Epoch: 8 [160768/319902 (50%)] Loss: 0.031138, 1 batch cost time 0.51
Train Epoch: 8 [161280/319902 (50%)] Loss: 0.044732, 1 batch cost time 0.51
Train Epoch: 8 [161792/319902 (51%)] Loss: 0.026986, 1 batch cost time 0.51
Train Epoch: 8 [162304/319902 (51%)] Loss: 0.022766, 1 batch cost time 0.51
Train Epoch: 8 [162816/319902 (51%)] Loss: 0.022799, 1 batch cost time 0.51
Train Epoch: 8 [163328/319902 (51%)] Loss: 0.028613, 1 batch cost time 0.51
Train Epoch: 8 [163840/319902 (51%)] Loss: 0.031484, 1 batch cost time 0.51
Train Epoch: 8 [164352/319902 (51%)] Loss: 0.038674, 1 batch cost time 0.51
Train Epoch: 8 [164864/319902 (52%)] Loss: 0.045521, 1 batch cost time 0.51
Train Epoch: 8 [165376/319902 (52%)] Loss: 0.028235, 1 batch cost time 0.51
Train Epoch: 8 [165888/319902 (52%)] Loss: 0.054120, 1 batch cost time 0.51
Train Epoch: 8 [166400/319902 (52%)] Loss: 0.010512, 1 batch cost time 0.51
Train Epoch: 8 [166912/319902 (52%)] Loss: 0.032857, 1 batch cost time 0.51
Train Epoch: 8 [167424/319902 (52%)] Loss: 0.025952, 1 batch cost time 0.51
Train Epoch: 8 [167936/319902 (52%)] Loss: 0.012947, 1 batch cost time 0.51
Train Epoch: 8 [168448/319902 (53%)] Loss: 0.036292, 1 batch cost time 0.51
Train Epoch: 8 [168960/319902 (53%)] Loss: 0.022931, 1 batch cost time 0.51
Train Epoch: 8 [169472/319902 (53%)] Loss: 0.029929, 1 batch cost time 0.51
Train Epoch: 8 [169984/319902 (53%)] Loss: 0.024293, 1 batch cost time 0.51
Train Epoch: 8 [170496/319902 (53%)] Loss: 0.011706, 1 batch cost time 0.51
Train Epoch: 8 [171008/319902 (53%)] Loss: 0.015287, 1 batch cost time 0.51
Train Epoch: 8 [171520/319902 (54%)] Loss: 0.054740, 1 batch cost time 0.51
Train Epoch: 8 [172032/319902 (54%)] Loss: 0.028714, 1 batch cost time 0.51
Train Epoch: 8 [172544/319902 (54%)] Loss: 0.018497, 1 batch cost time 0.51
Train Epoch: 8 [173056/319902 (54%)] Loss: 0.042624, 1 batch cost time 0.51
Train Epoch: 8 [173568/319902 (54%)] Loss: 0.045526, 1 batch cost time 0.51
Train Epoch: 8 [174080/319902 (54%)] Loss: 0.025979, 1 batch cost time 0.51
Train Epoch: 8 [174592/319902 (55%)] Loss: 0.018433, 1 batch cost time 0.51
Train Epoch: 8 [175104/319902 (55%)] Loss: 0.023227, 1 batch cost time 0.51
Train Epoch: 8 [175616/319902 (55%)] Loss: 0.028547, 1 batch cost time 0.51
Train Epoch: 8 [176128/319902 (55%)] Loss: 0.025142, 1 batch cost time 0.51
Train Epoch: 8 [176640/319902 (55%)] Loss: 0.016911, 1 batch cost time 0.51
Train Epoch: 8 [177152/319902 (55%)] Loss: 0.043250, 1 batch cost time 0.51
Train Epoch: 8 [177664/319902 (56%)] Loss: 0.033806, 1 batch cost time 0.51
Train Epoch: 8 [178176/319902 (56%)] Loss: 0.047018, 1 batch cost time 0.51
Train Epoch: 8 [178688/319902 (56%)] Loss: 0.024662, 1 batch cost time 0.51
Train Epoch: 8 [179200/319902 (56%)] Loss: 0.045704, 1 batch cost time 0.51
Train Epoch: 8 [179712/319902 (56%)] Loss: 0.014943, 1 batch cost time 0.51
Train Epoch: 8 [180224/319902 (56%)] Loss: 0.018332, 1 batch cost time 0.51
Train Epoch: 8 [180736/319902 (56%)] Loss: 0.022784, 1 batch cost time 0.51
Train Epoch: 8 [181248/319902 (57%)] Loss: 0.019029, 1 batch cost time 0.51
Train Epoch: 8 [181760/319902 (57%)] Loss: 0.027053, 1 batch cost time 0.51
Train Epoch: 8 [182272/319902 (57%)] Loss: 0.025247, 1 batch cost time 0.51
Train Epoch: 8 [182784/319902 (57%)] Loss: 0.034897, 1 batch cost time 0.51
Train Epoch: 8 [183296/319902 (57%)] Loss: 0.064911, 1 batch cost time 0.51
Train Epoch: 8 [183808/319902 (57%)] Loss: 0.022835, 1 batch cost time 0.51
Train Epoch: 8 [184320/319902 (58%)] Loss: 0.028924, 1 batch cost time 0.51
Train Epoch: 8 [184832/319902 (58%)] Loss: 0.032558, 1 batch cost time 0.51
Train Epoch: 8 [185344/319902 (58%)] Loss: 0.011158, 1 batch cost time 0.51
Train Epoch: 8 [185856/319902 (58%)] Loss: 0.040201, 1 batch cost time 0.51
Train Epoch: 8 [186368/319902 (58%)] Loss: 0.037086, 1 batch cost time 0.51
Train Epoch: 8 [186880/319902 (58%)] Loss: 0.022022, 1 batch cost time 0.51
Train Epoch: 8 [187392/319902 (59%)] Loss: 0.066697, 1 batch cost time 0.51
Train Epoch: 8 [187904/319902 (59%)] Loss: 0.016847, 1 batch cost time 0.51
Train Epoch: 8 [188416/319902 (59%)] Loss: 0.016934, 1 batch cost time 0.51
Train Epoch: 8 [188928/319902 (59%)] Loss: 0.014184, 1 batch cost time 0.51
Train Epoch: 8 [189440/319902 (59%)] Loss: 0.035910, 1 batch cost time 0.51
Train Epoch: 8 [189952/319902 (59%)] Loss: 0.026402, 1 batch cost time 0.51
Train Epoch: 8 [190464/319902 (60%)] Loss: 0.027103, 1 batch cost time 0.51
Train Epoch: 8 [190976/319902 (60%)] Loss: 0.008776, 1 batch cost time 0.51
Train Epoch: 8 [191488/319902 (60%)] Loss: 0.022160, 1 batch cost time 0.51
Train Epoch: 8 [192000/319902 (60%)] Loss: 0.032876, 1 batch cost time 0.51
Train Epoch: 8 [192512/319902 (60%)] Loss: 0.010897, 1 batch cost time 0.51
Train Epoch: 8 [193024/319902 (60%)] Loss: 0.018638, 1 batch cost time 0.51
Train Epoch: 8 [193536/319902 (60%)] Loss: 0.022359, 1 batch cost time 0.51
Train Epoch: 8 [194048/319902 (61%)] Loss: 0.035235, 1 batch cost time 0.51
Train Epoch: 8 [194560/319902 (61%)] Loss: 0.047004, 1 batch cost time 0.51
Train Epoch: 8 [195072/319902 (61%)] Loss: 0.037331, 1 batch cost time 0.51
Train Epoch: 8 [195584/319902 (61%)] Loss: 0.044768, 1 batch cost time 0.51
Train Epoch: 8 [196096/319902 (61%)] Loss: 0.017248, 1 batch cost time 0.51
Train Epoch: 8 [196608/319902 (61%)] Loss: 0.061740, 1 batch cost time 0.51
Train Epoch: 8 [197120/319902 (62%)] Loss: 0.046645, 1 batch cost time 0.51
Train Epoch: 8 [197632/319902 (62%)] Loss: 0.026279, 1 batch cost time 0.51
Train Epoch: 8 [198144/319902 (62%)] Loss: 0.027933, 1 batch cost time 0.51
Train Epoch: 8 [198656/319902 (62%)] Loss: 0.036511, 1 batch cost time 0.51
Train Epoch: 8 [199168/319902 (62%)] Loss: 0.023515, 1 batch cost time 0.51
Train Epoch: 8 [199680/319902 (62%)] Loss: 0.018752, 1 batch cost time 0.51
Train Epoch: 8 [200192/319902 (63%)] Loss: 0.026738, 1 batch cost time 0.51
Train Epoch: 8 [200704/319902 (63%)] Loss: 0.019983, 1 batch cost time 0.51
Train Epoch: 8 [201216/319902 (63%)] Loss: 0.043224, 1 batch cost time 0.51
Train Epoch: 8 [201728/319902 (63%)] Loss: 0.031540, 1 batch cost time 0.51
Train Epoch: 8 [202240/319902 (63%)] Loss: 0.027968, 1 batch cost time 0.51
Train Epoch: 8 [202752/319902 (63%)] Loss: 0.046708, 1 batch cost time 0.51
Train Epoch: 8 [203264/319902 (64%)] Loss: 0.047975, 1 batch cost time 0.51
Train Epoch: 8 [203776/319902 (64%)] Loss: 0.038784, 1 batch cost time 0.51
Train Epoch: 8 [204288/319902 (64%)] Loss: 0.049531, 1 batch cost time 0.51
Train Epoch: 8 [204800/319902 (64%)] Loss: 0.032098, 1 batch cost time 0.51
Train Epoch: 8 [205312/319902 (64%)] Loss: 0.029738, 1 batch cost time 0.51
Train Epoch: 8 [205824/319902 (64%)] Loss: 0.027401, 1 batch cost time 0.51
Train Epoch: 8 [206336/319902 (64%)] Loss: 0.049386, 1 batch cost time 0.51
Train Epoch: 8 [206848/319902 (65%)] Loss: 0.061304, 1 batch cost time 0.51
Train Epoch: 8 [207360/319902 (65%)] Loss: 0.013710, 1 batch cost time 0.51
Train Epoch: 8 [207872/319902 (65%)] Loss: 0.048783, 1 batch cost time 0.51
Train Epoch: 8 [208384/319902 (65%)] Loss: 0.029712, 1 batch cost time 0.51
Train Epoch: 8 [208896/319902 (65%)] Loss: 0.042745, 1 batch cost time 0.51
Train Epoch: 8 [209408/319902 (65%)] Loss: 0.041211, 1 batch cost time 0.51
Train Epoch: 8 [209920/319902 (66%)] Loss: 0.033064, 1 batch cost time 0.51
Train Epoch: 8 [210432/319902 (66%)] Loss: 0.017745, 1 batch cost time 0.51
Train Epoch: 8 [210944/319902 (66%)] Loss: 0.034307, 1 batch cost time 0.51
Train Epoch: 8 [211456/319902 (66%)] Loss: 0.026774, 1 batch cost time 0.51
Train Epoch: 8 [211968/319902 (66%)] Loss: 0.022732, 1 batch cost time 0.51
Train Epoch: 8 [212480/319902 (66%)] Loss: 0.013578, 1 batch cost time 0.51
Train Epoch: 8 [212992/319902 (67%)] Loss: 0.014270, 1 batch cost time 0.51
Train Epoch: 8 [213504/319902 (67%)] Loss: 0.022261, 1 batch cost time 0.51
Train Epoch: 8 [214016/319902 (67%)] Loss: 0.037564, 1 batch cost time 0.51
Train Epoch: 8 [214528/319902 (67%)] Loss: 0.021129, 1 batch cost time 0.51
Train Epoch: 8 [215040/319902 (67%)] Loss: 0.035739, 1 batch cost time 0.51
Train Epoch: 8 [215552/319902 (67%)] Loss: 0.041275, 1 batch cost time 0.51
Train Epoch: 8 [216064/319902 (68%)] Loss: 0.025280, 1 batch cost time 0.51
Train Epoch: 8 [216576/319902 (68%)] Loss: 0.023097, 1 batch cost time 0.51
Train Epoch: 8 [217088/319902 (68%)] Loss: 0.059596, 1 batch cost time 0.51
Train Epoch: 8 [217600/319902 (68%)] Loss: 0.012722, 1 batch cost time 0.51
Train Epoch: 8 [218112/319902 (68%)] Loss: 0.020669, 1 batch cost time 0.51
Train Epoch: 8 [218624/319902 (68%)] Loss: 0.053887, 1 batch cost time 0.51
Train Epoch: 8 [219136/319902 (69%)] Loss: 0.040521, 1 batch cost time 0.51
Train Epoch: 8 [219648/319902 (69%)] Loss: 0.048810, 1 batch cost time 0.51
Train Epoch: 8 [220160/319902 (69%)] Loss: 0.008677, 1 batch cost time 0.51
Train Epoch: 8 [220672/319902 (69%)] Loss: 0.014301, 1 batch cost time 0.51
Train Epoch: 8 [221184/319902 (69%)] Loss: 0.021903, 1 batch cost time 0.51
Train Epoch: 8 [221696/319902 (69%)] Loss: 0.030713, 1 batch cost time 0.51
Train Epoch: 8 [222208/319902 (69%)] Loss: 0.022270, 1 batch cost time 0.51
Train Epoch: 8 [222720/319902 (70%)] Loss: 0.010612, 1 batch cost time 0.51
Train Epoch: 8 [223232/319902 (70%)] Loss: 0.036224, 1 batch cost time 0.51
Train Epoch: 8 [223744/319902 (70%)] Loss: 0.061861, 1 batch cost time 0.51
Train Epoch: 8 [224256/319902 (70%)] Loss: 0.020020, 1 batch cost time 0.51
Train Epoch: 8 [224768/319902 (70%)] Loss: 0.046128, 1 batch cost time 0.51
Train Epoch: 8 [225280/319902 (70%)] Loss: 0.038487, 1 batch cost time 0.51
Train Epoch: 8 [225792/319902 (71%)] Loss: 0.039033, 1 batch cost time 0.51
Train Epoch: 8 [226304/319902 (71%)] Loss: 0.034351, 1 batch cost time 0.51
Train Epoch: 8 [226816/319902 (71%)] Loss: 0.027885, 1 batch cost time 0.51
Train Epoch: 8 [227328/319902 (71%)] Loss: 0.039264, 1 batch cost time 0.51
Train Epoch: 8 [227840/319902 (71%)] Loss: 0.031655, 1 batch cost time 0.51
Train Epoch: 8 [228352/319902 (71%)] Loss: 0.017535, 1 batch cost time 0.51
Train Epoch: 8 [228864/319902 (72%)] Loss: 0.033737, 1 batch cost time 0.51
Train Epoch: 8 [229376/319902 (72%)] Loss: 0.040733, 1 batch cost time 0.51
Train Epoch: 8 [229888/319902 (72%)] Loss: 0.044224, 1 batch cost time 0.51
Train Epoch: 8 [230400/319902 (72%)] Loss: 0.028070, 1 batch cost time 0.51
Train Epoch: 8 [230912/319902 (72%)] Loss: 0.021604, 1 batch cost time 0.51
Train Epoch: 8 [231424/319902 (72%)] Loss: 0.028998, 1 batch cost time 0.51
Train Epoch: 8 [231936/319902 (73%)] Loss: 0.044790, 1 batch cost time 0.51
Train Epoch: 8 [232448/319902 (73%)] Loss: 0.031023, 1 batch cost time 0.51
Train Epoch: 8 [232960/319902 (73%)] Loss: 0.029197, 1 batch cost time 0.51
Train Epoch: 8 [233472/319902 (73%)] Loss: 0.039389, 1 batch cost time 0.51
Train Epoch: 8 [233984/319902 (73%)] Loss: 0.049625, 1 batch cost time 0.51
Train Epoch: 8 [234496/319902 (73%)] Loss: 0.032834, 1 batch cost time 0.51
Train Epoch: 8 [235008/319902 (73%)] Loss: 0.017358, 1 batch cost time 0.51
Train Epoch: 8 [235520/319902 (74%)] Loss: 0.045718, 1 batch cost time 0.51
Train Epoch: 8 [236032/319902 (74%)] Loss: 0.023029, 1 batch cost time 0.51
Train Epoch: 8 [236544/319902 (74%)] Loss: 0.024257, 1 batch cost time 0.51
Train Epoch: 8 [237056/319902 (74%)] Loss: 0.045917, 1 batch cost time 0.51
Train Epoch: 8 [237568/319902 (74%)] Loss: 0.015969, 1 batch cost time 0.51
Train Epoch: 8 [238080/319902 (74%)] Loss: 0.042541, 1 batch cost time 0.51
Train Epoch: 8 [238592/319902 (75%)] Loss: 0.020097, 1 batch cost time 0.51
Train Epoch: 8 [239104/319902 (75%)] Loss: 0.014502, 1 batch cost time 0.51
Train Epoch: 8 [239616/319902 (75%)] Loss: 0.027257, 1 batch cost time 0.51
Train Epoch: 8 [240128/319902 (75%)] Loss: 0.028618, 1 batch cost time 0.51
Train Epoch: 8 [240640/319902 (75%)] Loss: 0.028457, 1 batch cost time 0.51
Train Epoch: 8 [241152/319902 (75%)] Loss: 0.034989, 1 batch cost time 0.51
Train Epoch: 8 [241664/319902 (76%)] Loss: 0.017807, 1 batch cost time 0.51
Train Epoch: 8 [242176/319902 (76%)] Loss: 0.038513, 1 batch cost time 0.51
Train Epoch: 8 [242688/319902 (76%)] Loss: 0.027061, 1 batch cost time 0.51
Train Epoch: 8 [243200/319902 (76%)] Loss: 0.009787, 1 batch cost time 0.51
Train Epoch: 8 [243712/319902 (76%)] Loss: 0.042508, 1 batch cost time 0.51
Train Epoch: 8 [244224/319902 (76%)] Loss: 0.016857, 1 batch cost time 0.51
Train Epoch: 8 [244736/319902 (77%)] Loss: 0.028966, 1 batch cost time 0.51
Train Epoch: 8 [245248/319902 (77%)] Loss: 0.057432, 1 batch cost time 0.51
Train Epoch: 8 [245760/319902 (77%)] Loss: 0.016383, 1 batch cost time 0.51
Train Epoch: 8 [246272/319902 (77%)] Loss: 0.038228, 1 batch cost time 0.51
Train Epoch: 8 [246784/319902 (77%)] Loss: 0.036717, 1 batch cost time 0.51
Train Epoch: 8 [247296/319902 (77%)] Loss: 0.039898, 1 batch cost time 0.51
Train Epoch: 8 [247808/319902 (77%)] Loss: 0.022122, 1 batch cost time 0.51
Train Epoch: 8 [248320/319902 (78%)] Loss: 0.056930, 1 batch cost time 0.51
Train Epoch: 8 [248832/319902 (78%)] Loss: 0.023733, 1 batch cost time 0.51
Train Epoch: 8 [249344/319902 (78%)] Loss: 0.038178, 1 batch cost time 0.51
Train Epoch: 8 [249856/319902 (78%)] Loss: 0.076710, 1 batch cost time 0.51
Train Epoch: 8 [250368/319902 (78%)] Loss: 0.044691, 1 batch cost time 0.51
Train Epoch: 8 [250880/319902 (78%)] Loss: 0.018248, 1 batch cost time 0.51
Train Epoch: 8 [251392/319902 (79%)] Loss: 0.041037, 1 batch cost time 0.51
Train Epoch: 8 [251904/319902 (79%)] Loss: 0.030110, 1 batch cost time 0.51
Train Epoch: 8 [252416/319902 (79%)] Loss: 0.046732, 1 batch cost time 0.51
Train Epoch: 8 [252928/319902 (79%)] Loss: 0.015954, 1 batch cost time 0.51
Train Epoch: 8 [253440/319902 (79%)] Loss: 0.007108, 1 batch cost time 0.51
Train Epoch: 8 [253952/319902 (79%)] Loss: 0.032721, 1 batch cost time 0.51
Train Epoch: 8 [254464/319902 (80%)] Loss: 0.020078, 1 batch cost time 0.51
Train Epoch: 8 [254976/319902 (80%)] Loss: 0.013697, 1 batch cost time 0.51
Train Epoch: 8 [255488/319902 (80%)] Loss: 0.017312, 1 batch cost time 0.51
Train Epoch: 8 [256000/319902 (80%)] Loss: 0.023300, 1 batch cost time 0.51
Train Epoch: 8 [256512/319902 (80%)] Loss: 0.026784, 1 batch cost time 0.51
Train Epoch: 8 [257024/319902 (80%)] Loss: 0.031902, 1 batch cost time 0.51
Train Epoch: 8 [257536/319902 (81%)] Loss: 0.034748, 1 batch cost time 0.51
Train Epoch: 8 [258048/319902 (81%)] Loss: 0.032568, 1 batch cost time 0.51
Train Epoch: 8 [258560/319902 (81%)] Loss: 0.045013, 1 batch cost time 0.51
Train Epoch: 8 [259072/319902 (81%)] Loss: 0.023236, 1 batch cost time 0.51
Train Epoch: 8 [259584/319902 (81%)] Loss: 0.019954, 1 batch cost time 0.51
Train Epoch: 8 [260096/319902 (81%)] Loss: 0.045453, 1 batch cost time 0.51
Train Epoch: 8 [260608/319902 (81%)] Loss: 0.027931, 1 batch cost time 0.51
Train Epoch: 8 [261120/319902 (82%)] Loss: 0.033609, 1 batch cost time 0.51
Train Epoch: 8 [261632/319902 (82%)] Loss: 0.014795, 1 batch cost time 0.51
Train Epoch: 8 [262144/319902 (82%)] Loss: 0.026191, 1 batch cost time 0.51
Train Epoch: 8 [262656/319902 (82%)] Loss: 0.015660, 1 batch cost time 0.51
Train Epoch: 8 [263168/319902 (82%)] Loss: 0.026595, 1 batch cost time 0.51
Train Epoch: 8 [263680/319902 (82%)] Loss: 0.017442, 1 batch cost time 0.51
Train Epoch: 8 [264192/319902 (83%)] Loss: 0.051259, 1 batch cost time 0.51
Train Epoch: 8 [264704/319902 (83%)] Loss: 0.024293, 1 batch cost time 0.51
Train Epoch: 8 [265216/319902 (83%)] Loss: 0.025111, 1 batch cost time 0.51
Train Epoch: 8 [265728/319902 (83%)] Loss: 0.027580, 1 batch cost time 0.51
Train Epoch: 8 [266240/319902 (83%)] Loss: 0.039588, 1 batch cost time 0.51
Train Epoch: 8 [266752/319902 (83%)] Loss: 0.060303, 1 batch cost time 0.51
Train Epoch: 8 [267264/319902 (84%)] Loss: 0.018884, 1 batch cost time 0.51
Train Epoch: 8 [267776/319902 (84%)] Loss: 0.030617, 1 batch cost time 0.51
Train Epoch: 8 [268288/319902 (84%)] Loss: 0.023819, 1 batch cost time 0.51
Train Epoch: 8 [268800/319902 (84%)] Loss: 0.050897, 1 batch cost time 0.51
Train Epoch: 8 [269312/319902 (84%)] Loss: 0.025476, 1 batch cost time 0.51
Train Epoch: 8 [269824/319902 (84%)] Loss: 0.032904, 1 batch cost time 0.51
Train Epoch: 8 [270336/319902 (85%)] Loss: 0.019676, 1 batch cost time 0.51
Train Epoch: 8 [270848/319902 (85%)] Loss: 0.017404, 1 batch cost time 0.51
Train Epoch: 8 [271360/319902 (85%)] Loss: 0.011142, 1 batch cost time 0.51
Train Epoch: 8 [271872/319902 (85%)] Loss: 0.014500, 1 batch cost time 0.51
Train Epoch: 8 [272384/319902 (85%)] Loss: 0.035305, 1 batch cost time 0.51
Train Epoch: 8 [272896/319902 (85%)] Loss: 0.027810, 1 batch cost time 0.51
Train Epoch: 8 [273408/319902 (85%)] Loss: 0.021459, 1 batch cost time 0.51
Train Epoch: 8 [273920/319902 (86%)] Loss: 0.044244, 1 batch cost time 0.51
Train Epoch: 8 [274432/319902 (86%)] Loss: 0.030990, 1 batch cost time 0.51
Train Epoch: 8 [274944/319902 (86%)] Loss: 0.025716, 1 batch cost time 0.51
Train Epoch: 8 [275456/319902 (86%)] Loss: 0.034706, 1 batch cost time 0.51
Train Epoch: 8 [275968/319902 (86%)] Loss: 0.035543, 1 batch cost time 0.51
Train Epoch: 8 [276480/319902 (86%)] Loss: 0.017503, 1 batch cost time 0.51
Train Epoch: 8 [276992/319902 (87%)] Loss: 0.034964, 1 batch cost time 0.51
Train Epoch: 8 [277504/319902 (87%)] Loss: 0.028916, 1 batch cost time 0.51
Train Epoch: 8 [278016/319902 (87%)] Loss: 0.044255, 1 batch cost time 0.51
Train Epoch: 8 [278528/319902 (87%)] Loss: 0.031599, 1 batch cost time 0.51
Train Epoch: 8 [279040/319902 (87%)] Loss: 0.026699, 1 batch cost time 0.51
Train Epoch: 8 [279552/319902 (87%)] Loss: 0.029992, 1 batch cost time 0.51
Train Epoch: 8 [280064/319902 (88%)] Loss: 0.047871, 1 batch cost time 0.51
Train Epoch: 8 [280576/319902 (88%)] Loss: 0.036800, 1 batch cost time 0.51
Train Epoch: 8 [281088/319902 (88%)] Loss: 0.047598, 1 batch cost time 0.51
Train Epoch: 8 [281600/319902 (88%)] Loss: 0.016141, 1 batch cost time 0.51
Train Epoch: 8 [282112/319902 (88%)] Loss: 0.012939, 1 batch cost time 0.51
Train Epoch: 8 [282624/319902 (88%)] Loss: 0.059491, 1 batch cost time 0.51
Train Epoch: 8 [283136/319902 (89%)] Loss: 0.018985, 1 batch cost time 0.51
Train Epoch: 8 [283648/319902 (89%)] Loss: 0.028997, 1 batch cost time 0.51
Train Epoch: 8 [284160/319902 (89%)] Loss: 0.031726, 1 batch cost time 0.51
Train Epoch: 8 [284672/319902 (89%)] Loss: 0.044009, 1 batch cost time 0.51
Train Epoch: 8 [285184/319902 (89%)] Loss: 0.038961, 1 batch cost time 0.51
Train Epoch: 8 [285696/319902 (89%)] Loss: 0.025947, 1 batch cost time 0.51
Train Epoch: 8 [286208/319902 (89%)] Loss: 0.024099, 1 batch cost time 0.51
Train Epoch: 8 [286720/319902 (90%)] Loss: 0.052850, 1 batch cost time 0.51
Train Epoch: 8 [287232/319902 (90%)] Loss: 0.028561, 1 batch cost time 0.51
Train Epoch: 8 [287744/319902 (90%)] Loss: 0.020889, 1 batch cost time 0.51
Train Epoch: 8 [288256/319902 (90%)] Loss: 0.018315, 1 batch cost time 0.51
Train Epoch: 8 [288768/319902 (90%)] Loss: 0.023730, 1 batch cost time 0.51
Train Epoch: 8 [289280/319902 (90%)] Loss: 0.016690, 1 batch cost time 0.51
Train Epoch: 8 [289792/319902 (91%)] Loss: 0.020230, 1 batch cost time 0.51
Train Epoch: 8 [290304/319902 (91%)] Loss: 0.019672, 1 batch cost time 0.51
Train Epoch: 8 [290816/319902 (91%)] Loss: 0.016324, 1 batch cost time 0.51
Train Epoch: 8 [291328/319902 (91%)] Loss: 0.028004, 1 batch cost time 0.51
Train Epoch: 8 [291840/319902 (91%)] Loss: 0.023130, 1 batch cost time 0.51
Train Epoch: 8 [292352/319902 (91%)] Loss: 0.022440, 1 batch cost time 0.51
Train Epoch: 8 [292864/319902 (92%)] Loss: 0.018350, 1 batch cost time 0.51
Train Epoch: 8 [293376/319902 (92%)] Loss: 0.029925, 1 batch cost time 0.51
Train Epoch: 8 [293888/319902 (92%)] Loss: 0.023496, 1 batch cost time 0.51
Train Epoch: 8 [294400/319902 (92%)] Loss: 0.057626, 1 batch cost time 0.51
Train Epoch: 8 [294912/319902 (92%)] Loss: 0.040211, 1 batch cost time 0.51
Train Epoch: 8 [295424/319902 (92%)] Loss: 0.031915, 1 batch cost time 0.51
Train Epoch: 8 [295936/319902 (93%)] Loss: 0.017669, 1 batch cost time 0.51
Train Epoch: 8 [296448/319902 (93%)] Loss: 0.050580, 1 batch cost time 0.51
Train Epoch: 8 [296960/319902 (93%)] Loss: 0.022061, 1 batch cost time 0.51
Train Epoch: 8 [297472/319902 (93%)] Loss: 0.047029, 1 batch cost time 0.51
Train Epoch: 8 [297984/319902 (93%)] Loss: 0.033691, 1 batch cost time 0.51
Train Epoch: 8 [298496/319902 (93%)] Loss: 0.011279, 1 batch cost time 0.51
Train Epoch: 8 [299008/319902 (93%)] Loss: 0.020063, 1 batch cost time 0.51
Train Epoch: 8 [299520/319902 (94%)] Loss: 0.030806, 1 batch cost time 0.51
Train Epoch: 8 [300032/319902 (94%)] Loss: 0.008657, 1 batch cost time 0.51
Train Epoch: 8 [300544/319902 (94%)] Loss: 0.016173, 1 batch cost time 0.51
Train Epoch: 8 [301056/319902 (94%)] Loss: 0.024058, 1 batch cost time 0.51
Train Epoch: 8 [301568/319902 (94%)] Loss: 0.023561, 1 batch cost time 0.51
Train Epoch: 8 [302080/319902 (94%)] Loss: 0.034540, 1 batch cost time 0.51
Train Epoch: 8 [302592/319902 (95%)] Loss: 0.025371, 1 batch cost time 0.51
Train Epoch: 8 [303104/319902 (95%)] Loss: 0.041213, 1 batch cost time 0.51
Train Epoch: 8 [303616/319902 (95%)] Loss: 0.033844, 1 batch cost time 0.51
Train Epoch: 8 [304128/319902 (95%)] Loss: 0.041365, 1 batch cost time 0.51
Train Epoch: 8 [304640/319902 (95%)] Loss: 0.023493, 1 batch cost time 0.51
Train Epoch: 8 [305152/319902 (95%)] Loss: 0.018506, 1 batch cost time 0.51
Train Epoch: 8 [305664/319902 (96%)] Loss: 0.050513, 1 batch cost time 0.51
Train Epoch: 8 [306176/319902 (96%)] Loss: 0.040270, 1 batch cost time 0.51
Train Epoch: 8 [306688/319902 (96%)] Loss: 0.023814, 1 batch cost time 0.51
Train Epoch: 8 [307200/319902 (96%)] Loss: 0.051950, 1 batch cost time 0.51
Train Epoch: 8 [307712/319902 (96%)] Loss: 0.019190, 1 batch cost time 0.51
Train Epoch: 8 [308224/319902 (96%)] Loss: 0.032899, 1 batch cost time 0.51
Train Epoch: 8 [308736/319902 (97%)] Loss: 0.053053, 1 batch cost time 0.51
Train Epoch: 8 [309248/319902 (97%)] Loss: 0.021691, 1 batch cost time 0.51
Train Epoch: 8 [309760/319902 (97%)] Loss: 0.020952, 1 batch cost time 0.51
Train Epoch: 8 [310272/319902 (97%)] Loss: 0.034041, 1 batch cost time 0.51
Train Epoch: 8 [310784/319902 (97%)] Loss: 0.011116, 1 batch cost time 0.51
Train Epoch: 8 [311296/319902 (97%)] Loss: 0.019753, 1 batch cost time 0.51
Train Epoch: 8 [311808/319902 (97%)] Loss: 0.017034, 1 batch cost time 0.51
Train Epoch: 8 [312320/319902 (98%)] Loss: 0.033230, 1 batch cost time 0.51
Train Epoch: 8 [312832/319902 (98%)] Loss: 0.030330, 1 batch cost time 0.51
Train Epoch: 8 [313344/319902 (98%)] Loss: 0.023144, 1 batch cost time 0.51
Train Epoch: 8 [313856/319902 (98%)] Loss: 0.043700, 1 batch cost time 0.51
Train Epoch: 8 [314368/319902 (98%)] Loss: 0.057968, 1 batch cost time 0.51
Train Epoch: 8 [314880/319902 (98%)] Loss: 0.023790, 1 batch cost time 0.51
Train Epoch: 8 [315392/319902 (99%)] Loss: 0.041810, 1 batch cost time 0.51
Train Epoch: 8 [315904/319902 (99%)] Loss: 0.010844, 1 batch cost time 0.51
Train Epoch: 8 [316416/319902 (99%)] Loss: 0.031865, 1 batch cost time 0.51
Train Epoch: 8 [316928/319902 (99%)] Loss: 0.030219, 1 batch cost time 0.51
Train Epoch: 8 [317440/319902 (99%)] Loss: 0.052110, 1 batch cost time 0.51
Train Epoch: 8 [317952/319902 (99%)] Loss: 0.029639, 1 batch cost time 0.51
Train Epoch: 8 [318464/319902 (100%)] Loss: 0.043510, 1 batch cost time 0.51
Train Epoch: 8 [318976/319902 (100%)] Loss: 0.017715, 1 batch cost time 0.51
Train Epoch: 8 [319488/319902 (100%)] Loss: 0.022770, 1 batch cost time 0.51
training epoch cost 8052.451589107513 seconds
    epoch          : 8
    lr             : 0.0001
    loss           : 0.030843573749954608
    accuracy       : 0.9324448529411765
    f_measure      : 0.5550223022386872
    val_loss       : 0.025723968790164992
    val_accuracy   : 0.9425455729166666
    val_f_measure  : 0.5674420294211961
Saving current best: model_best.pth ...
Train Epoch: 9 [0/319902 (0%)] Loss: 0.025191, 1 batch cost time 0.52
Train Epoch: 9 [512/319902 (0%)] Loss: 0.037291, 1 batch cost time 0.51
Train Epoch: 9 [1024/319902 (0%)] Loss: 0.023881, 1 batch cost time 0.51
Train Epoch: 9 [1536/319902 (0%)] Loss: 0.033437, 1 batch cost time 0.51
Train Epoch: 9 [2048/319902 (1%)] Loss: 0.034405, 1 batch cost time 0.51
Train Epoch: 9 [2560/319902 (1%)] Loss: 0.028600, 1 batch cost time 0.51
Train Epoch: 9 [3072/319902 (1%)] Loss: 0.026092, 1 batch cost time 0.51
Train Epoch: 9 [3584/319902 (1%)] Loss: 0.040679, 1 batch cost time 0.51
Train Epoch: 9 [4096/319902 (1%)] Loss: 0.023025, 1 batch cost time 0.51
Train Epoch: 9 [4608/319902 (1%)] Loss: 0.043088, 1 batch cost time 0.51
Train Epoch: 9 [5120/319902 (2%)] Loss: 0.019581, 1 batch cost time 0.51
Train Epoch: 9 [5632/319902 (2%)] Loss: 0.015441, 1 batch cost time 0.51
Train Epoch: 9 [6144/319902 (2%)] Loss: 0.021528, 1 batch cost time 0.51
Train Epoch: 9 [6656/319902 (2%)] Loss: 0.032213, 1 batch cost time 0.51
Train Epoch: 9 [7168/319902 (2%)] Loss: 0.031950, 1 batch cost time 0.51
Train Epoch: 9 [7680/319902 (2%)] Loss: 0.057043, 1 batch cost time 0.51
Train Epoch: 9 [8192/319902 (3%)] Loss: 0.037451, 1 batch cost time 0.51
Train Epoch: 9 [8704/319902 (3%)] Loss: 0.043201, 1 batch cost time 0.51
Train Epoch: 9 [9216/319902 (3%)] Loss: 0.066220, 1 batch cost time 0.51
Train Epoch: 9 [9728/319902 (3%)] Loss: 0.027054, 1 batch cost time 0.51
Train Epoch: 9 [10240/319902 (3%)] Loss: 0.020462, 1 batch cost time 0.51
Train Epoch: 9 [10752/319902 (3%)] Loss: 0.033258, 1 batch cost time 0.51
Train Epoch: 9 [11264/319902 (4%)] Loss: 0.036027, 1 batch cost time 0.51
Train Epoch: 9 [11776/319902 (4%)] Loss: 0.024345, 1 batch cost time 0.51
Train Epoch: 9 [12288/319902 (4%)] Loss: 0.022996, 1 batch cost time 0.51
Train Epoch: 9 [12800/319902 (4%)] Loss: 0.024503, 1 batch cost time 0.51
Train Epoch: 9 [13312/319902 (4%)] Loss: 0.031877, 1 batch cost time 0.51
Train Epoch: 9 [13824/319902 (4%)] Loss: 0.033036, 1 batch cost time 0.51
Train Epoch: 9 [14336/319902 (4%)] Loss: 0.052008, 1 batch cost time 0.51
Train Epoch: 9 [14848/319902 (5%)] Loss: 0.051429, 1 batch cost time 0.51
Train Epoch: 9 [15360/319902 (5%)] Loss: 0.034908, 1 batch cost time 0.51
Train Epoch: 9 [15872/319902 (5%)] Loss: 0.040603, 1 batch cost time 0.51
Train Epoch: 9 [16384/319902 (5%)] Loss: 0.051333, 1 batch cost time 0.51
Train Epoch: 9 [16896/319902 (5%)] Loss: 0.036640, 1 batch cost time 0.51
Train Epoch: 9 [17408/319902 (5%)] Loss: 0.029694, 1 batch cost time 0.51
Train Epoch: 9 [17920/319902 (6%)] Loss: 0.019309, 1 batch cost time 0.51
Train Epoch: 9 [18432/319902 (6%)] Loss: 0.022940, 1 batch cost time 0.51
Train Epoch: 9 [18944/319902 (6%)] Loss: 0.012239, 1 batch cost time 0.51
Train Epoch: 9 [19456/319902 (6%)] Loss: 0.051553, 1 batch cost time 0.51
Train Epoch: 9 [19968/319902 (6%)] Loss: 0.044032, 1 batch cost time 0.51
Train Epoch: 9 [20480/319902 (6%)] Loss: 0.023251, 1 batch cost time 0.51
Train Epoch: 9 [20992/319902 (7%)] Loss: 0.013188, 1 batch cost time 0.51
Train Epoch: 9 [21504/319902 (7%)] Loss: 0.051243, 1 batch cost time 0.51
Train Epoch: 9 [22016/319902 (7%)] Loss: 0.030274, 1 batch cost time 0.51
Train Epoch: 9 [22528/319902 (7%)] Loss: 0.017500, 1 batch cost time 0.51
Train Epoch: 9 [23040/319902 (7%)] Loss: 0.036373, 1 batch cost time 0.51
Train Epoch: 9 [23552/319902 (7%)] Loss: 0.016410, 1 batch cost time 0.51
Train Epoch: 9 [24064/319902 (8%)] Loss: 0.041532, 1 batch cost time 0.51
Train Epoch: 9 [24576/319902 (8%)] Loss: 0.043292, 1 batch cost time 0.51
Train Epoch: 9 [25088/319902 (8%)] Loss: 0.010608, 1 batch cost time 0.51
Train Epoch: 9 [25600/319902 (8%)] Loss: 0.017581, 1 batch cost time 0.51
Train Epoch: 9 [26112/319902 (8%)] Loss: 0.020498, 1 batch cost time 0.51
Train Epoch: 9 [26624/319902 (8%)] Loss: 0.011140, 1 batch cost time 0.51
Train Epoch: 9 [27136/319902 (8%)] Loss: 0.057813, 1 batch cost time 0.51
Train Epoch: 9 [27648/319902 (9%)] Loss: 0.023610, 1 batch cost time 0.51
Train Epoch: 9 [28160/319902 (9%)] Loss: 0.025175, 1 batch cost time 0.51
Train Epoch: 9 [28672/319902 (9%)] Loss: 0.013580, 1 batch cost time 0.51
Train Epoch: 9 [29184/319902 (9%)] Loss: 0.014709, 1 batch cost time 0.51
Train Epoch: 9 [29696/319902 (9%)] Loss: 0.018910, 1 batch cost time 0.51
Train Epoch: 9 [30208/319902 (9%)] Loss: 0.039408, 1 batch cost time 0.51
Train Epoch: 9 [30720/319902 (10%)] Loss: 0.041033, 1 batch cost time 0.51
Train Epoch: 9 [31232/319902 (10%)] Loss: 0.017853, 1 batch cost time 0.51
Train Epoch: 9 [31744/319902 (10%)] Loss: 0.027200, 1 batch cost time 0.51
Train Epoch: 9 [32256/319902 (10%)] Loss: 0.073620, 1 batch cost time 0.51
Train Epoch: 9 [32768/319902 (10%)] Loss: 0.016449, 1 batch cost time 0.51
Train Epoch: 9 [33280/319902 (10%)] Loss: 0.018438, 1 batch cost time 0.51
Train Epoch: 9 [33792/319902 (11%)] Loss: 0.013458, 1 batch cost time 0.51
Train Epoch: 9 [34304/319902 (11%)] Loss: 0.029406, 1 batch cost time 0.51
Train Epoch: 9 [34816/319902 (11%)] Loss: 0.027492, 1 batch cost time 0.51
Train Epoch: 9 [35328/319902 (11%)] Loss: 0.021727, 1 batch cost time 0.51
Train Epoch: 9 [35840/319902 (11%)] Loss: 0.024664, 1 batch cost time 0.51
Train Epoch: 9 [36352/319902 (11%)] Loss: 0.042722, 1 batch cost time 0.51
Train Epoch: 9 [36864/319902 (12%)] Loss: 0.053426, 1 batch cost time 0.51
Train Epoch: 9 [37376/319902 (12%)] Loss: 0.017783, 1 batch cost time 0.51
Train Epoch: 9 [37888/319902 (12%)] Loss: 0.052646, 1 batch cost time 0.51
Train Epoch: 9 [38400/319902 (12%)] Loss: 0.048876, 1 batch cost time 0.51
Train Epoch: 9 [38912/319902 (12%)] Loss: 0.033589, 1 batch cost time 0.51
Train Epoch: 9 [39424/319902 (12%)] Loss: 0.020988, 1 batch cost time 0.51
Train Epoch: 9 [39936/319902 (12%)] Loss: 0.026808, 1 batch cost time 0.51
Train Epoch: 9 [40448/319902 (13%)] Loss: 0.022173, 1 batch cost time 0.51
Train Epoch: 9 [40960/319902 (13%)] Loss: 0.032873, 1 batch cost time 0.51
Train Epoch: 9 [41472/319902 (13%)] Loss: 0.037614, 1 batch cost time 0.51
Train Epoch: 9 [41984/319902 (13%)] Loss: 0.024040, 1 batch cost time 0.51
Train Epoch: 9 [42496/319902 (13%)] Loss: 0.021997, 1 batch cost time 0.51
Train Epoch: 9 [43008/319902 (13%)] Loss: 0.035362, 1 batch cost time 0.51
Train Epoch: 9 [43520/319902 (14%)] Loss: 0.043825, 1 batch cost time 0.51
Train Epoch: 9 [44032/319902 (14%)] Loss: 0.018466, 1 batch cost time 0.51
Train Epoch: 9 [44544/319902 (14%)] Loss: 0.011962, 1 batch cost time 0.51
Train Epoch: 9 [45056/319902 (14%)] Loss: 0.045762, 1 batch cost time 0.51
Train Epoch: 9 [45568/319902 (14%)] Loss: 0.015253, 1 batch cost time 0.51
Train Epoch: 9 [46080/319902 (14%)] Loss: 0.035248, 1 batch cost time 0.51
Train Epoch: 9 [46592/319902 (15%)] Loss: 0.030452, 1 batch cost time 0.51
Train Epoch: 9 [47104/319902 (15%)] Loss: 0.044379, 1 batch cost time 0.51
Train Epoch: 9 [47616/319902 (15%)] Loss: 0.017325, 1 batch cost time 0.51
Train Epoch: 9 [48128/319902 (15%)] Loss: 0.044591, 1 batch cost time 0.51
Train Epoch: 9 [48640/319902 (15%)] Loss: 0.078780, 1 batch cost time 0.51
Train Epoch: 9 [49152/319902 (15%)] Loss: 0.029134, 1 batch cost time 0.51
Train Epoch: 9 [49664/319902 (16%)] Loss: 0.029362, 1 batch cost time 0.51
Train Epoch: 9 [50176/319902 (16%)] Loss: 0.002775, 1 batch cost time 0.51
Train Epoch: 9 [50688/319902 (16%)] Loss: 0.034866, 1 batch cost time 0.51
Train Epoch: 9 [51200/319902 (16%)] Loss: 0.019966, 1 batch cost time 0.51
Train Epoch: 9 [51712/319902 (16%)] Loss: 0.037661, 1 batch cost time 0.51
Train Epoch: 9 [52224/319902 (16%)] Loss: 0.056083, 1 batch cost time 0.51
Train Epoch: 9 [52736/319902 (16%)] Loss: 0.042903, 1 batch cost time 0.51
Train Epoch: 9 [53248/319902 (17%)] Loss: 0.032402, 1 batch cost time 0.51
Train Epoch: 9 [53760/319902 (17%)] Loss: 0.007233, 1 batch cost time 0.51
Train Epoch: 9 [54272/319902 (17%)] Loss: 0.047032, 1 batch cost time 0.51
Train Epoch: 9 [54784/319902 (17%)] Loss: 0.036716, 1 batch cost time 0.51
Train Epoch: 9 [55296/319902 (17%)] Loss: 0.016802, 1 batch cost time 0.51
Train Epoch: 9 [55808/319902 (17%)] Loss: 0.039719, 1 batch cost time 0.51
Train Epoch: 9 [56320/319902 (18%)] Loss: 0.012433, 1 batch cost time 0.51
Train Epoch: 9 [56832/319902 (18%)] Loss: 0.025598, 1 batch cost time 0.51
Train Epoch: 9 [57344/319902 (18%)] Loss: 0.041317, 1 batch cost time 0.51
Train Epoch: 9 [57856/319902 (18%)] Loss: 0.021398, 1 batch cost time 0.51
Train Epoch: 9 [58368/319902 (18%)] Loss: 0.026566, 1 batch cost time 0.51
Train Epoch: 9 [58880/319902 (18%)] Loss: 0.051822, 1 batch cost time 0.51
Train Epoch: 9 [59392/319902 (19%)] Loss: 0.012230, 1 batch cost time 0.51
Train Epoch: 9 [59904/319902 (19%)] Loss: 0.033834, 1 batch cost time 0.51
Train Epoch: 9 [60416/319902 (19%)] Loss: 0.019753, 1 batch cost time 0.51
Train Epoch: 9 [60928/319902 (19%)] Loss: 0.019769, 1 batch cost time 0.51
Train Epoch: 9 [61440/319902 (19%)] Loss: 0.021580, 1 batch cost time 0.51
Train Epoch: 9 [61952/319902 (19%)] Loss: 0.018090, 1 batch cost time 0.51
Train Epoch: 9 [62464/319902 (20%)] Loss: 0.039866, 1 batch cost time 0.51
Train Epoch: 9 [62976/319902 (20%)] Loss: 0.030290, 1 batch cost time 0.51
Train Epoch: 9 [63488/319902 (20%)] Loss: 0.036399, 1 batch cost time 0.51
Train Epoch: 9 [64000/319902 (20%)] Loss: 0.037225, 1 batch cost time 0.51
Train Epoch: 9 [64512/319902 (20%)] Loss: 0.031879, 1 batch cost time 0.51
Train Epoch: 9 [65024/319902 (20%)] Loss: 0.011072, 1 batch cost time 0.51
Train Epoch: 9 [65536/319902 (20%)] Loss: 0.045800, 1 batch cost time 0.51
Train Epoch: 9 [66048/319902 (21%)] Loss: 0.021409, 1 batch cost time 0.51
Train Epoch: 9 [66560/319902 (21%)] Loss: 0.012804, 1 batch cost time 0.51
Train Epoch: 9 [67072/319902 (21%)] Loss: 0.040586, 1 batch cost time 0.51
Train Epoch: 9 [67584/319902 (21%)] Loss: 0.022121, 1 batch cost time 0.51
Train Epoch: 9 [68096/319902 (21%)] Loss: 0.021457, 1 batch cost time 0.51
Train Epoch: 9 [68608/319902 (21%)] Loss: 0.014867, 1 batch cost time 0.51
Train Epoch: 9 [69120/319902 (22%)] Loss: 0.019805, 1 batch cost time 0.51
Train Epoch: 9 [69632/319902 (22%)] Loss: 0.022701, 1 batch cost time 0.51
Train Epoch: 9 [70144/319902 (22%)] Loss: 0.025464, 1 batch cost time 0.51
Train Epoch: 9 [70656/319902 (22%)] Loss: 0.012003, 1 batch cost time 0.51
Train Epoch: 9 [71168/319902 (22%)] Loss: 0.018856, 1 batch cost time 0.51
Train Epoch: 9 [71680/319902 (22%)] Loss: 0.041212, 1 batch cost time 0.51
Train Epoch: 9 [72192/319902 (23%)] Loss: 0.013823, 1 batch cost time 0.51
Train Epoch: 9 [72704/319902 (23%)] Loss: 0.018558, 1 batch cost time 0.51
Train Epoch: 9 [73216/319902 (23%)] Loss: 0.042564, 1 batch cost time 0.51
Train Epoch: 9 [73728/319902 (23%)] Loss: 0.031900, 1 batch cost time 0.51
Train Epoch: 9 [74240/319902 (23%)] Loss: 0.019901, 1 batch cost time 0.51
Train Epoch: 9 [74752/319902 (23%)] Loss: 0.021806, 1 batch cost time 0.51
Train Epoch: 9 [75264/319902 (24%)] Loss: 0.022275, 1 batch cost time 0.51
Train Epoch: 9 [75776/319902 (24%)] Loss: 0.030309, 1 batch cost time 0.51
Train Epoch: 9 [76288/319902 (24%)] Loss: 0.030208, 1 batch cost time 0.51
Train Epoch: 9 [76800/319902 (24%)] Loss: 0.036643, 1 batch cost time 0.51
Train Epoch: 9 [77312/319902 (24%)] Loss: 0.033454, 1 batch cost time 0.51
Train Epoch: 9 [77824/319902 (24%)] Loss: 0.027721, 1 batch cost time 0.51
Train Epoch: 9 [78336/319902 (24%)] Loss: 0.022825, 1 batch cost time 0.51
Train Epoch: 9 [78848/319902 (25%)] Loss: 0.024328, 1 batch cost time 0.51
Train Epoch: 9 [79360/319902 (25%)] Loss: 0.026567, 1 batch cost time 0.51
Train Epoch: 9 [79872/319902 (25%)] Loss: 0.013576, 1 batch cost time 0.51
Train Epoch: 9 [80384/319902 (25%)] Loss: 0.041883, 1 batch cost time 0.51
Train Epoch: 9 [80896/319902 (25%)] Loss: 0.018266, 1 batch cost time 0.51
Train Epoch: 9 [81408/319902 (25%)] Loss: 0.014564, 1 batch cost time 0.51
Train Epoch: 9 [81920/319902 (26%)] Loss: 0.029463, 1 batch cost time 0.51
Train Epoch: 9 [82432/319902 (26%)] Loss: 0.032836, 1 batch cost time 0.51
Train Epoch: 9 [82944/319902 (26%)] Loss: 0.038423, 1 batch cost time 0.51
Train Epoch: 9 [83456/319902 (26%)] Loss: 0.022458, 1 batch cost time 0.51
Train Epoch: 9 [83968/319902 (26%)] Loss: 0.016216, 1 batch cost time 0.51
Train Epoch: 9 [84480/319902 (26%)] Loss: 0.033255, 1 batch cost time 0.51
Train Epoch: 9 [84992/319902 (27%)] Loss: 0.036592, 1 batch cost time 0.51
Train Epoch: 9 [85504/319902 (27%)] Loss: 0.015683, 1 batch cost time 0.51
Train Epoch: 9 [86016/319902 (27%)] Loss: 0.037511, 1 batch cost time 0.51
Train Epoch: 9 [86528/319902 (27%)] Loss: 0.013869, 1 batch cost time 0.51
Train Epoch: 9 [87040/319902 (27%)] Loss: 0.029951, 1 batch cost time 0.51
Train Epoch: 9 [87552/319902 (27%)] Loss: 0.049305, 1 batch cost time 0.51
Train Epoch: 9 [88064/319902 (28%)] Loss: 0.025958, 1 batch cost time 0.51
Train Epoch: 9 [88576/319902 (28%)] Loss: 0.035656, 1 batch cost time 0.51
Train Epoch: 9 [89088/319902 (28%)] Loss: 0.024034, 1 batch cost time 0.51
Train Epoch: 9 [89600/319902 (28%)] Loss: 0.033295, 1 batch cost time 0.51
Train Epoch: 9 [90112/319902 (28%)] Loss: 0.036614, 1 batch cost time 0.51
Train Epoch: 9 [90624/319902 (28%)] Loss: 0.040790, 1 batch cost time 0.51
Train Epoch: 9 [91136/319902 (28%)] Loss: 0.042963, 1 batch cost time 0.51
Train Epoch: 9 [91648/319902 (29%)] Loss: 0.031986, 1 batch cost time 0.51
Train Epoch: 9 [92160/319902 (29%)] Loss: 0.037084, 1 batch cost time 0.51
Train Epoch: 9 [92672/319902 (29%)] Loss: 0.029923, 1 batch cost time 0.51
Train Epoch: 9 [93184/319902 (29%)] Loss: 0.016276, 1 batch cost time 0.51
Train Epoch: 9 [93696/319902 (29%)] Loss: 0.028492, 1 batch cost time 0.51
Train Epoch: 9 [94208/319902 (29%)] Loss: 0.025878, 1 batch cost time 0.51
Train Epoch: 9 [94720/319902 (30%)] Loss: 0.027287, 1 batch cost time 0.51
Train Epoch: 9 [95232/319902 (30%)] Loss: 0.018781, 1 batch cost time 0.51
Train Epoch: 9 [95744/319902 (30%)] Loss: 0.031887, 1 batch cost time 0.51
Train Epoch: 9 [96256/319902 (30%)] Loss: 0.018884, 1 batch cost time 0.51
Train Epoch: 9 [96768/319902 (30%)] Loss: 0.018089, 1 batch cost time 0.51
Train Epoch: 9 [97280/319902 (30%)] Loss: 0.016037, 1 batch cost time 0.51
Train Epoch: 9 [97792/319902 (31%)] Loss: 0.024118, 1 batch cost time 0.51
Train Epoch: 9 [98304/319902 (31%)] Loss: 0.041418, 1 batch cost time 0.51
Train Epoch: 9 [98816/319902 (31%)] Loss: 0.024601, 1 batch cost time 0.51
Train Epoch: 9 [99328/319902 (31%)] Loss: 0.028839, 1 batch cost time 0.51
Train Epoch: 9 [99840/319902 (31%)] Loss: 0.046494, 1 batch cost time 0.51
Train Epoch: 9 [100352/319902 (31%)] Loss: 0.021635, 1 batch cost time 0.51
Train Epoch: 9 [100864/319902 (32%)] Loss: 0.029281, 1 batch cost time 0.51
Train Epoch: 9 [101376/319902 (32%)] Loss: 0.021659, 1 batch cost time 0.51
Train Epoch: 9 [101888/319902 (32%)] Loss: 0.015497, 1 batch cost time 0.51
Train Epoch: 9 [102400/319902 (32%)] Loss: 0.025367, 1 batch cost time 0.51
Train Epoch: 9 [102912/319902 (32%)] Loss: 0.035741, 1 batch cost time 0.51
Train Epoch: 9 [103424/319902 (32%)] Loss: 0.014728, 1 batch cost time 0.51
Train Epoch: 9 [103936/319902 (32%)] Loss: 0.026239, 1 batch cost time 0.51
Train Epoch: 9 [104448/319902 (33%)] Loss: 0.020577, 1 batch cost time 0.51
Train Epoch: 9 [104960/319902 (33%)] Loss: 0.051199, 1 batch cost time 0.51
Train Epoch: 9 [105472/319902 (33%)] Loss: 0.027307, 1 batch cost time 0.51
Train Epoch: 9 [105984/319902 (33%)] Loss: 0.035433, 1 batch cost time 0.51
Train Epoch: 9 [106496/319902 (33%)] Loss: 0.015903, 1 batch cost time 0.51
Train Epoch: 9 [107008/319902 (33%)] Loss: 0.022466, 1 batch cost time 0.51
Train Epoch: 9 [107520/319902 (34%)] Loss: 0.006576, 1 batch cost time 0.51
Train Epoch: 9 [108032/319902 (34%)] Loss: 0.012446, 1 batch cost time 0.51
Train Epoch: 9 [108544/319902 (34%)] Loss: 0.036897, 1 batch cost time 0.51
Train Epoch: 9 [109056/319902 (34%)] Loss: 0.026333, 1 batch cost time 0.51
Train Epoch: 9 [109568/319902 (34%)] Loss: 0.035644, 1 batch cost time 0.51
Train Epoch: 9 [110080/319902 (34%)] Loss: 0.010825, 1 batch cost time 0.51
Train Epoch: 9 [110592/319902 (35%)] Loss: 0.023112, 1 batch cost time 0.51
Train Epoch: 9 [111104/319902 (35%)] Loss: 0.031345, 1 batch cost time 0.51
Train Epoch: 9 [111616/319902 (35%)] Loss: 0.020424, 1 batch cost time 0.51
Train Epoch: 9 [112128/319902 (35%)] Loss: 0.025775, 1 batch cost time 0.51
Train Epoch: 9 [112640/319902 (35%)] Loss: 0.030101, 1 batch cost time 0.51
Train Epoch: 9 [113152/319902 (35%)] Loss: 0.014884, 1 batch cost time 0.51
Train Epoch: 9 [113664/319902 (36%)] Loss: 0.009742, 1 batch cost time 0.51
Train Epoch: 9 [114176/319902 (36%)] Loss: 0.035553, 1 batch cost time 0.51
Train Epoch: 9 [114688/319902 (36%)] Loss: 0.017806, 1 batch cost time 0.51
Train Epoch: 9 [115200/319902 (36%)] Loss: 0.013854, 1 batch cost time 0.51
Train Epoch: 9 [115712/319902 (36%)] Loss: 0.028401, 1 batch cost time 0.51
Train Epoch: 9 [116224/319902 (36%)] Loss: 0.017428, 1 batch cost time 0.51
Train Epoch: 9 [116736/319902 (36%)] Loss: 0.047227, 1 batch cost time 0.51
Train Epoch: 9 [117248/319902 (37%)] Loss: 0.017983, 1 batch cost time 0.51
Train Epoch: 9 [117760/319902 (37%)] Loss: 0.061727, 1 batch cost time 0.51
Train Epoch: 9 [118272/319902 (37%)] Loss: 0.034596, 1 batch cost time 0.51
Train Epoch: 9 [118784/319902 (37%)] Loss: 0.019241, 1 batch cost time 0.51
Train Epoch: 9 [119296/319902 (37%)] Loss: 0.025785, 1 batch cost time 0.51
Train Epoch: 9 [119808/319902 (37%)] Loss: 0.044656, 1 batch cost time 0.51
Train Epoch: 9 [120320/319902 (38%)] Loss: 0.027183, 1 batch cost time 0.51
Train Epoch: 9 [120832/319902 (38%)] Loss: 0.023876, 1 batch cost time 0.51
Train Epoch: 9 [121344/319902 (38%)] Loss: 0.014423, 1 batch cost time 0.51
Train Epoch: 9 [121856/319902 (38%)] Loss: 0.023409, 1 batch cost time 0.51
Train Epoch: 9 [122368/319902 (38%)] Loss: 0.031630, 1 batch cost time 0.51
Train Epoch: 9 [122880/319902 (38%)] Loss: 0.020563, 1 batch cost time 0.51
Train Epoch: 9 [123392/319902 (39%)] Loss: 0.031437, 1 batch cost time 0.51
Train Epoch: 9 [123904/319902 (39%)] Loss: 0.030620, 1 batch cost time 0.51
Train Epoch: 9 [124416/319902 (39%)] Loss: 0.013908, 1 batch cost time 0.51
Train Epoch: 9 [124928/319902 (39%)] Loss: 0.015290, 1 batch cost time 0.51
Train Epoch: 9 [125440/319902 (39%)] Loss: 0.029626, 1 batch cost time 0.51
Train Epoch: 9 [125952/319902 (39%)] Loss: 0.022612, 1 batch cost time 0.51
Train Epoch: 9 [126464/319902 (40%)] Loss: 0.062069, 1 batch cost time 0.51
Train Epoch: 9 [126976/319902 (40%)] Loss: 0.019883, 1 batch cost time 0.51
Train Epoch: 9 [127488/319902 (40%)] Loss: 0.059192, 1 batch cost time 0.51
Train Epoch: 9 [128000/319902 (40%)] Loss: 0.012198, 1 batch cost time 0.51
Train Epoch: 9 [128512/319902 (40%)] Loss: 0.042385, 1 batch cost time 0.51
Train Epoch: 9 [129024/319902 (40%)] Loss: 0.020275, 1 batch cost time 0.51
Train Epoch: 9 [129536/319902 (40%)] Loss: 0.022819, 1 batch cost time 0.51
Train Epoch: 9 [130048/319902 (41%)] Loss: 0.034228, 1 batch cost time 0.51
Train Epoch: 9 [130560/319902 (41%)] Loss: 0.044257, 1 batch cost time 0.51
Train Epoch: 9 [131072/319902 (41%)] Loss: 0.041177, 1 batch cost time 0.51
Train Epoch: 9 [131584/319902 (41%)] Loss: 0.014816, 1 batch cost time 0.51
Train Epoch: 9 [132096/319902 (41%)] Loss: 0.048185, 1 batch cost time 0.51
Train Epoch: 9 [132608/319902 (41%)] Loss: 0.038062, 1 batch cost time 0.51
Train Epoch: 9 [133120/319902 (42%)] Loss: 0.021897, 1 batch cost time 0.51
Train Epoch: 9 [133632/319902 (42%)] Loss: 0.031359, 1 batch cost time 0.51
Train Epoch: 9 [134144/319902 (42%)] Loss: 0.052292, 1 batch cost time 0.51
Train Epoch: 9 [134656/319902 (42%)] Loss: 0.026112, 1 batch cost time 0.51
Train Epoch: 9 [135168/319902 (42%)] Loss: 0.012529, 1 batch cost time 0.51
Train Epoch: 9 [135680/319902 (42%)] Loss: 0.040885, 1 batch cost time 0.51
Train Epoch: 9 [136192/319902 (43%)] Loss: 0.061353, 1 batch cost time 0.51
Train Epoch: 9 [136704/319902 (43%)] Loss: 0.036783, 1 batch cost time 0.51
Train Epoch: 9 [137216/319902 (43%)] Loss: 0.023992, 1 batch cost time 0.51
Train Epoch: 9 [137728/319902 (43%)] Loss: 0.023203, 1 batch cost time 0.51
Train Epoch: 9 [138240/319902 (43%)] Loss: 0.022646, 1 batch cost time 0.51
Train Epoch: 9 [138752/319902 (43%)] Loss: 0.034125, 1 batch cost time 0.51
Train Epoch: 9 [139264/319902 (44%)] Loss: 0.072633, 1 batch cost time 0.51
Train Epoch: 9 [139776/319902 (44%)] Loss: 0.043412, 1 batch cost time 0.51
Train Epoch: 9 [140288/319902 (44%)] Loss: 0.029683, 1 batch cost time 0.51
Train Epoch: 9 [140800/319902 (44%)] Loss: 0.027558, 1 batch cost time 0.51
Train Epoch: 9 [141312/319902 (44%)] Loss: 0.020193, 1 batch cost time 0.51
Train Epoch: 9 [141824/319902 (44%)] Loss: 0.030067, 1 batch cost time 0.51
Train Epoch: 9 [142336/319902 (44%)] Loss: 0.013425, 1 batch cost time 0.51
Train Epoch: 9 [142848/319902 (45%)] Loss: 0.016382, 1 batch cost time 0.51
Train Epoch: 9 [143360/319902 (45%)] Loss: 0.043458, 1 batch cost time 0.51
Train Epoch: 9 [143872/319902 (45%)] Loss: 0.018151, 1 batch cost time 0.51
Train Epoch: 9 [144384/319902 (45%)] Loss: 0.030878, 1 batch cost time 0.51
Train Epoch: 9 [144896/319902 (45%)] Loss: 0.023906, 1 batch cost time 0.51
Train Epoch: 9 [145408/319902 (45%)] Loss: 0.008053, 1 batch cost time 0.51
Train Epoch: 9 [145920/319902 (46%)] Loss: 0.041526, 1 batch cost time 0.51
Train Epoch: 9 [146432/319902 (46%)] Loss: 0.020298, 1 batch cost time 0.51
Train Epoch: 9 [146944/319902 (46%)] Loss: 0.026892, 1 batch cost time 0.51
Train Epoch: 9 [147456/319902 (46%)] Loss: 0.028806, 1 batch cost time 0.51
Train Epoch: 9 [147968/319902 (46%)] Loss: 0.021601, 1 batch cost time 0.51
Train Epoch: 9 [148480/319902 (46%)] Loss: 0.031182, 1 batch cost time 0.51
Train Epoch: 9 [148992/319902 (47%)] Loss: 0.025796, 1 batch cost time 0.51
Train Epoch: 9 [149504/319902 (47%)] Loss: 0.041762, 1 batch cost time 0.51
Train Epoch: 9 [150016/319902 (47%)] Loss: 0.018927, 1 batch cost time 0.51
Train Epoch: 9 [150528/319902 (47%)] Loss: 0.020730, 1 batch cost time 0.51
Train Epoch: 9 [151040/319902 (47%)] Loss: 0.025843, 1 batch cost time 0.51
Train Epoch: 9 [151552/319902 (47%)] Loss: 0.055536, 1 batch cost time 0.51
Train Epoch: 9 [152064/319902 (48%)] Loss: 0.054194, 1 batch cost time 0.51
Train Epoch: 9 [152576/319902 (48%)] Loss: 0.020587, 1 batch cost time 0.51
Train Epoch: 9 [153088/319902 (48%)] Loss: 0.051410, 1 batch cost time 0.51
Train Epoch: 9 [153600/319902 (48%)] Loss: 0.033663, 1 batch cost time 0.51
Train Epoch: 9 [154112/319902 (48%)] Loss: 0.030796, 1 batch cost time 0.51
Train Epoch: 9 [154624/319902 (48%)] Loss: 0.049533, 1 batch cost time 0.51
Train Epoch: 9 [155136/319902 (48%)] Loss: 0.024110, 1 batch cost time 0.51
Train Epoch: 9 [155648/319902 (49%)] Loss: 0.013649, 1 batch cost time 0.51
Train Epoch: 9 [156160/319902 (49%)] Loss: 0.020816, 1 batch cost time 0.51
Train Epoch: 9 [156672/319902 (49%)] Loss: 0.023054, 1 batch cost time 0.51
Train Epoch: 9 [157184/319902 (49%)] Loss: 0.014086, 1 batch cost time 0.51
Train Epoch: 9 [157696/319902 (49%)] Loss: 0.050848, 1 batch cost time 0.51
Train Epoch: 9 [158208/319902 (49%)] Loss: 0.054051, 1 batch cost time 0.51
Train Epoch: 9 [158720/319902 (50%)] Loss: 0.024769, 1 batch cost time 0.51
Train Epoch: 9 [159232/319902 (50%)] Loss: 0.021704, 1 batch cost time 0.51
Train Epoch: 9 [159744/319902 (50%)] Loss: 0.033047, 1 batch cost time 0.51
Train Epoch: 9 [160256/319902 (50%)] Loss: 0.016300, 1 batch cost time 0.51
Train Epoch: 9 [160768/319902 (50%)] Loss: 0.034680, 1 batch cost time 0.51
Train Epoch: 9 [161280/319902 (50%)] Loss: 0.048711, 1 batch cost time 0.51
Train Epoch: 9 [161792/319902 (51%)] Loss: 0.037244, 1 batch cost time 0.51
Train Epoch: 9 [162304/319902 (51%)] Loss: 0.055015, 1 batch cost time 0.51
Train Epoch: 9 [162816/319902 (51%)] Loss: 0.026147, 1 batch cost time 0.51
Train Epoch: 9 [163328/319902 (51%)] Loss: 0.046788, 1 batch cost time 0.51
Train Epoch: 9 [163840/319902 (51%)] Loss: 0.011396, 1 batch cost time 0.51
Train Epoch: 9 [164352/319902 (51%)] Loss: 0.028418, 1 batch cost time 0.51
Train Epoch: 9 [164864/319902 (52%)] Loss: 0.016682, 1 batch cost time 0.51
Train Epoch: 9 [165376/319902 (52%)] Loss: 0.035266, 1 batch cost time 0.51
Train Epoch: 9 [165888/319902 (52%)] Loss: 0.009168, 1 batch cost time 0.51
Train Epoch: 9 [166400/319902 (52%)] Loss: 0.024738, 1 batch cost time 0.51
Train Epoch: 9 [166912/319902 (52%)] Loss: 0.028479, 1 batch cost time 0.51
Train Epoch: 9 [167424/319902 (52%)] Loss: 0.027524, 1 batch cost time 0.51
Train Epoch: 9 [167936/319902 (52%)] Loss: 0.022529, 1 batch cost time 0.51
Train Epoch: 9 [168448/319902 (53%)] Loss: 0.058424, 1 batch cost time 0.51
Train Epoch: 9 [168960/319902 (53%)] Loss: 0.044919, 1 batch cost time 0.51
Train Epoch: 9 [169472/319902 (53%)] Loss: 0.030859, 1 batch cost time 0.51
Train Epoch: 9 [169984/319902 (53%)] Loss: 0.019250, 1 batch cost time 0.51
Train Epoch: 9 [170496/319902 (53%)] Loss: 0.023364, 1 batch cost time 0.51
Train Epoch: 9 [171008/319902 (53%)] Loss: 0.034428, 1 batch cost time 0.51
Train Epoch: 9 [171520/319902 (54%)] Loss: 0.043557, 1 batch cost time 0.51
Train Epoch: 9 [172032/319902 (54%)] Loss: 0.020285, 1 batch cost time 0.51
Train Epoch: 9 [172544/319902 (54%)] Loss: 0.032675, 1 batch cost time 0.51
Train Epoch: 9 [173056/319902 (54%)] Loss: 0.030397, 1 batch cost time 0.51
Train Epoch: 9 [173568/319902 (54%)] Loss: 0.027304, 1 batch cost time 0.51
Train Epoch: 9 [174080/319902 (54%)] Loss: 0.064851, 1 batch cost time 0.51
Train Epoch: 9 [174592/319902 (55%)] Loss: 0.038716, 1 batch cost time 0.51
Train Epoch: 9 [175104/319902 (55%)] Loss: 0.022530, 1 batch cost time 0.51
Train Epoch: 9 [175616/319902 (55%)] Loss: 0.018989, 1 batch cost time 0.51
Train Epoch: 9 [176128/319902 (55%)] Loss: 0.036999, 1 batch cost time 0.51
Train Epoch: 9 [176640/319902 (55%)] Loss: 0.041457, 1 batch cost time 0.51
Train Epoch: 9 [177152/319902 (55%)] Loss: 0.017520, 1 batch cost time 0.51
Train Epoch: 9 [177664/319902 (56%)] Loss: 0.016353, 1 batch cost time 0.51
Train Epoch: 9 [178176/319902 (56%)] Loss: 0.028076, 1 batch cost time 0.51
Train Epoch: 9 [178688/319902 (56%)] Loss: 0.013171, 1 batch cost time 0.51
Train Epoch: 9 [179200/319902 (56%)] Loss: 0.046571, 1 batch cost time 0.51
Train Epoch: 9 [179712/319902 (56%)] Loss: 0.031027, 1 batch cost time 0.51
Train Epoch: 9 [180224/319902 (56%)] Loss: 0.012025, 1 batch cost time 0.51
Train Epoch: 9 [180736/319902 (56%)] Loss: 0.039093, 1 batch cost time 0.51
Train Epoch: 9 [181248/319902 (57%)] Loss: 0.043091, 1 batch cost time 0.51
Train Epoch: 9 [181760/319902 (57%)] Loss: 0.044438, 1 batch cost time 0.51
Train Epoch: 9 [182272/319902 (57%)] Loss: 0.013849, 1 batch cost time 0.51
Train Epoch: 9 [182784/319902 (57%)] Loss: 0.024082, 1 batch cost time 0.51
Train Epoch: 9 [183296/319902 (57%)] Loss: 0.016589, 1 batch cost time 0.51
Train Epoch: 9 [183808/319902 (57%)] Loss: 0.012915, 1 batch cost time 0.51
Train Epoch: 9 [184320/319902 (58%)] Loss: 0.026671, 1 batch cost time 0.51
Train Epoch: 9 [184832/319902 (58%)] Loss: 0.054903, 1 batch cost time 0.51
Train Epoch: 9 [185344/319902 (58%)] Loss: 0.039762, 1 batch cost time 0.51
Train Epoch: 9 [185856/319902 (58%)] Loss: 0.032880, 1 batch cost time 0.51
Train Epoch: 9 [186368/319902 (58%)] Loss: 0.022529, 1 batch cost time 0.51
Train Epoch: 9 [186880/319902 (58%)] Loss: 0.017275, 1 batch cost time 0.51
Train Epoch: 9 [187392/319902 (59%)] Loss: 0.025772, 1 batch cost time 0.51
Train Epoch: 9 [187904/319902 (59%)] Loss: 0.014359, 1 batch cost time 0.51
Train Epoch: 9 [188416/319902 (59%)] Loss: 0.026299, 1 batch cost time 0.51
Train Epoch: 9 [188928/319902 (59%)] Loss: 0.043495, 1 batch cost time 0.51
Train Epoch: 9 [189440/319902 (59%)] Loss: 0.031346, 1 batch cost time 0.51
Train Epoch: 9 [189952/319902 (59%)] Loss: 0.022291, 1 batch cost time 0.51
Train Epoch: 9 [190464/319902 (60%)] Loss: 0.057524, 1 batch cost time 0.51
Train Epoch: 9 [190976/319902 (60%)] Loss: 0.053656, 1 batch cost time 0.51
Train Epoch: 9 [191488/319902 (60%)] Loss: 0.064972, 1 batch cost time 0.51
Train Epoch: 9 [192000/319902 (60%)] Loss: 0.030253, 1 batch cost time 0.51
Train Epoch: 9 [192512/319902 (60%)] Loss: 0.022170, 1 batch cost time 0.51
Train Epoch: 9 [193024/319902 (60%)] Loss: 0.026970, 1 batch cost time 0.51
Train Epoch: 9 [193536/319902 (60%)] Loss: 0.021390, 1 batch cost time 0.51
Train Epoch: 9 [194048/319902 (61%)] Loss: 0.040964, 1 batch cost time 0.51
Train Epoch: 9 [194560/319902 (61%)] Loss: 0.014312, 1 batch cost time 0.51
Train Epoch: 9 [195072/319902 (61%)] Loss: 0.033570, 1 batch cost time 0.51
Train Epoch: 9 [195584/319902 (61%)] Loss: 0.028991, 1 batch cost time 0.51
Train Epoch: 9 [196096/319902 (61%)] Loss: 0.032138, 1 batch cost time 0.51
Train Epoch: 9 [196608/319902 (61%)] Loss: 0.023574, 1 batch cost time 0.51
Train Epoch: 9 [197120/319902 (62%)] Loss: 0.053191, 1 batch cost time 0.51
Train Epoch: 9 [197632/319902 (62%)] Loss: 0.027825, 1 batch cost time 0.51
Train Epoch: 9 [198144/319902 (62%)] Loss: 0.047298, 1 batch cost time 0.51
Train Epoch: 9 [198656/319902 (62%)] Loss: 0.042917, 1 batch cost time 0.51
Train Epoch: 9 [199168/319902 (62%)] Loss: 0.028177, 1 batch cost time 0.51
Train Epoch: 9 [199680/319902 (62%)] Loss: 0.031534, 1 batch cost time 0.51
Train Epoch: 9 [200192/319902 (63%)] Loss: 0.013300, 1 batch cost time 0.51
Train Epoch: 9 [200704/319902 (63%)] Loss: 0.026827, 1 batch cost time 0.51
Train Epoch: 9 [201216/319902 (63%)] Loss: 0.017357, 1 batch cost time 0.51
Train Epoch: 9 [201728/319902 (63%)] Loss: 0.043855, 1 batch cost time 0.51
Train Epoch: 9 [202240/319902 (63%)] Loss: 0.034003, 1 batch cost time 0.51
Train Epoch: 9 [202752/319902 (63%)] Loss: 0.016162, 1 batch cost time 0.51
Train Epoch: 9 [203264/319902 (64%)] Loss: 0.030794, 1 batch cost time 0.51
Train Epoch: 9 [203776/319902 (64%)] Loss: 0.021192, 1 batch cost time 0.51
Train Epoch: 9 [204288/319902 (64%)] Loss: 0.027073, 1 batch cost time 0.51
Train Epoch: 9 [204800/319902 (64%)] Loss: 0.031210, 1 batch cost time 0.51
Train Epoch: 9 [205312/319902 (64%)] Loss: 0.021605, 1 batch cost time 0.51
Train Epoch: 9 [205824/319902 (64%)] Loss: 0.036085, 1 batch cost time 0.51
Train Epoch: 9 [206336/319902 (64%)] Loss: 0.030022, 1 batch cost time 0.51
Train Epoch: 9 [206848/319902 (65%)] Loss: 0.026982, 1 batch cost time 0.51
Train Epoch: 9 [207360/319902 (65%)] Loss: 0.028212, 1 batch cost time 0.51
Train Epoch: 9 [207872/319902 (65%)] Loss: 0.048095, 1 batch cost time 0.51
Train Epoch: 9 [208384/319902 (65%)] Loss: 0.041976, 1 batch cost time 0.51
Train Epoch: 9 [208896/319902 (65%)] Loss: 0.028177, 1 batch cost time 0.51
Train Epoch: 9 [209408/319902 (65%)] Loss: 0.030299, 1 batch cost time 0.51
Train Epoch: 9 [209920/319902 (66%)] Loss: 0.044569, 1 batch cost time 0.51
Train Epoch: 9 [210432/319902 (66%)] Loss: 0.026863, 1 batch cost time 0.51
Train Epoch: 9 [210944/319902 (66%)] Loss: 0.062114, 1 batch cost time 0.51
Train Epoch: 9 [211456/319902 (66%)] Loss: 0.022945, 1 batch cost time 0.51
Train Epoch: 9 [211968/319902 (66%)] Loss: 0.036244, 1 batch cost time 0.51
Train Epoch: 9 [212480/319902 (66%)] Loss: 0.024532, 1 batch cost time 0.51
Train Epoch: 9 [212992/319902 (67%)] Loss: 0.030206, 1 batch cost time 0.51
Train Epoch: 9 [213504/319902 (67%)] Loss: 0.020536, 1 batch cost time 0.51
Train Epoch: 9 [214016/319902 (67%)] Loss: 0.038603, 1 batch cost time 0.51
Train Epoch: 9 [214528/319902 (67%)] Loss: 0.025195, 1 batch cost time 0.51
Train Epoch: 9 [215040/319902 (67%)] Loss: 0.032028, 1 batch cost time 0.51
Train Epoch: 9 [215552/319902 (67%)] Loss: 0.021089, 1 batch cost time 0.51
Train Epoch: 9 [216064/319902 (68%)] Loss: 0.048573, 1 batch cost time 0.51
Train Epoch: 9 [216576/319902 (68%)] Loss: 0.022877, 1 batch cost time 0.51
Train Epoch: 9 [217088/319902 (68%)] Loss: 0.015389, 1 batch cost time 0.51
Train Epoch: 9 [217600/319902 (68%)] Loss: 0.020941, 1 batch cost time 0.51
Train Epoch: 9 [218112/319902 (68%)] Loss: 0.022674, 1 batch cost time 0.51
Train Epoch: 9 [218624/319902 (68%)] Loss: 0.013949, 1 batch cost time 0.51
Train Epoch: 9 [219136/319902 (69%)] Loss: 0.029684, 1 batch cost time 0.51
Train Epoch: 9 [219648/319902 (69%)] Loss: 0.034662, 1 batch cost time 0.51
Train Epoch: 9 [220160/319902 (69%)] Loss: 0.021965, 1 batch cost time 0.51
Train Epoch: 9 [220672/319902 (69%)] Loss: 0.055738, 1 batch cost time 0.51
Train Epoch: 9 [221184/319902 (69%)] Loss: 0.025946, 1 batch cost time 0.51
Train Epoch: 9 [221696/319902 (69%)] Loss: 0.042005, 1 batch cost time 0.51
Train Epoch: 9 [222208/319902 (69%)] Loss: 0.021439, 1 batch cost time 0.51
Train Epoch: 9 [222720/319902 (70%)] Loss: 0.044561, 1 batch cost time 0.51
Train Epoch: 9 [223232/319902 (70%)] Loss: 0.045141, 1 batch cost time 0.51
Train Epoch: 9 [223744/319902 (70%)] Loss: 0.037774, 1 batch cost time 0.51
Train Epoch: 9 [224256/319902 (70%)] Loss: 0.031421, 1 batch cost time 0.51
Train Epoch: 9 [224768/319902 (70%)] Loss: 0.022611, 1 batch cost time 0.51
Train Epoch: 9 [225280/319902 (70%)] Loss: 0.055758, 1 batch cost time 0.51
Train Epoch: 9 [225792/319902 (71%)] Loss: 0.039907, 1 batch cost time 0.51
Train Epoch: 9 [226304/319902 (71%)] Loss: 0.017452, 1 batch cost time 0.51
Train Epoch: 9 [226816/319902 (71%)] Loss: 0.017577, 1 batch cost time 0.51
Train Epoch: 9 [227328/319902 (71%)] Loss: 0.036660, 1 batch cost time 0.51
Train Epoch: 9 [227840/319902 (71%)] Loss: 0.034586, 1 batch cost time 0.51
Train Epoch: 9 [228352/319902 (71%)] Loss: 0.010406, 1 batch cost time 0.51
Train Epoch: 9 [228864/319902 (72%)] Loss: 0.025226, 1 batch cost time 0.51
Train Epoch: 9 [229376/319902 (72%)] Loss: 0.019196, 1 batch cost time 0.51
Train Epoch: 9 [229888/319902 (72%)] Loss: 0.030339, 1 batch cost time 0.51
Train Epoch: 9 [230400/319902 (72%)] Loss: 0.039906, 1 batch cost time 0.51
Train Epoch: 9 [230912/319902 (72%)] Loss: 0.033090, 1 batch cost time 0.51
Train Epoch: 9 [231424/319902 (72%)] Loss: 0.037915, 1 batch cost time 0.51
Train Epoch: 9 [231936/319902 (73%)] Loss: 0.036748, 1 batch cost time 0.51
Train Epoch: 9 [232448/319902 (73%)] Loss: 0.043921, 1 batch cost time 0.51
Train Epoch: 9 [232960/319902 (73%)] Loss: 0.018910, 1 batch cost time 0.51
Train Epoch: 9 [233472/319902 (73%)] Loss: 0.023182, 1 batch cost time 0.51
Train Epoch: 9 [233984/319902 (73%)] Loss: 0.019808, 1 batch cost time 0.51
Train Epoch: 9 [234496/319902 (73%)] Loss: 0.018049, 1 batch cost time 0.51
Train Epoch: 9 [235008/319902 (73%)] Loss: 0.021669, 1 batch cost time 0.51
Train Epoch: 9 [235520/319902 (74%)] Loss: 0.017892, 1 batch cost time 0.51
Train Epoch: 9 [236032/319902 (74%)] Loss: 0.029388, 1 batch cost time 0.51
Train Epoch: 9 [236544/319902 (74%)] Loss: 0.016651, 1 batch cost time 0.51
Train Epoch: 9 [237056/319902 (74%)] Loss: 0.007672, 1 batch cost time 0.51
Train Epoch: 9 [237568/319902 (74%)] Loss: 0.020456, 1 batch cost time 0.51
Train Epoch: 9 [238080/319902 (74%)] Loss: 0.022757, 1 batch cost time 0.51
Train Epoch: 9 [238592/319902 (75%)] Loss: 0.027919, 1 batch cost time 0.51
Train Epoch: 9 [239104/319902 (75%)] Loss: 0.016141, 1 batch cost time 0.51
Train Epoch: 9 [239616/319902 (75%)] Loss: 0.070139, 1 batch cost time 0.51
Train Epoch: 9 [240128/319902 (75%)] Loss: 0.026775, 1 batch cost time 0.51
Train Epoch: 9 [240640/319902 (75%)] Loss: 0.018383, 1 batch cost time 0.51
Train Epoch: 9 [241152/319902 (75%)] Loss: 0.016751, 1 batch cost time 0.51
Train Epoch: 9 [241664/319902 (76%)] Loss: 0.036327, 1 batch cost time 0.51
Train Epoch: 9 [242176/319902 (76%)] Loss: 0.025986, 1 batch cost time 0.51
Train Epoch: 9 [242688/319902 (76%)] Loss: 0.025977, 1 batch cost time 0.51
Train Epoch: 9 [243200/319902 (76%)] Loss: 0.019093, 1 batch cost time 0.51
Train Epoch: 9 [243712/319902 (76%)] Loss: 0.014125, 1 batch cost time 0.51
Train Epoch: 9 [244224/319902 (76%)] Loss: 0.037914, 1 batch cost time 0.51
Train Epoch: 9 [244736/319902 (77%)] Loss: 0.013570, 1 batch cost time 0.51
Train Epoch: 9 [245248/319902 (77%)] Loss: 0.019257, 1 batch cost time 0.51
Train Epoch: 9 [245760/319902 (77%)] Loss: 0.029838, 1 batch cost time 0.51
Train Epoch: 9 [246272/319902 (77%)] Loss: 0.026550, 1 batch cost time 0.51
Train Epoch: 9 [246784/319902 (77%)] Loss: 0.024094, 1 batch cost time 0.51
Train Epoch: 9 [247296/319902 (77%)] Loss: 0.073363, 1 batch cost time 0.51
Train Epoch: 9 [247808/319902 (77%)] Loss: 0.017350, 1 batch cost time 0.51
Train Epoch: 9 [248320/319902 (78%)] Loss: 0.037505, 1 batch cost time 0.51
Train Epoch: 9 [248832/319902 (78%)] Loss: 0.048068, 1 batch cost time 0.51
Train Epoch: 9 [249344/319902 (78%)] Loss: 0.051050, 1 batch cost time 0.51
Train Epoch: 9 [249856/319902 (78%)] Loss: 0.024549, 1 batch cost time 0.51
Train Epoch: 9 [250368/319902 (78%)] Loss: 0.018653, 1 batch cost time 0.51
Train Epoch: 9 [250880/319902 (78%)] Loss: 0.052126, 1 batch cost time 0.51
Train Epoch: 9 [251392/319902 (79%)] Loss: 0.013041, 1 batch cost time 0.51
Train Epoch: 9 [251904/319902 (79%)] Loss: 0.050552, 1 batch cost time 0.51
Train Epoch: 9 [252416/319902 (79%)] Loss: 0.011348, 1 batch cost time 0.51
Train Epoch: 9 [252928/319902 (79%)] Loss: 0.044514, 1 batch cost time 0.51
Train Epoch: 9 [253440/319902 (79%)] Loss: 0.018193, 1 batch cost time 0.51
Train Epoch: 9 [253952/319902 (79%)] Loss: 0.016748, 1 batch cost time 0.51
Train Epoch: 9 [254464/319902 (80%)] Loss: 0.019338, 1 batch cost time 0.51
Train Epoch: 9 [254976/319902 (80%)] Loss: 0.061421, 1 batch cost time 0.51
Train Epoch: 9 [255488/319902 (80%)] Loss: 0.023402, 1 batch cost time 0.51
Train Epoch: 9 [256000/319902 (80%)] Loss: 0.019473, 1 batch cost time 0.51
Train Epoch: 9 [256512/319902 (80%)] Loss: 0.020923, 1 batch cost time 0.51
Train Epoch: 9 [257024/319902 (80%)] Loss: 0.024971, 1 batch cost time 0.51
Train Epoch: 9 [257536/319902 (81%)] Loss: 0.044478, 1 batch cost time 0.51
Train Epoch: 9 [258048/319902 (81%)] Loss: 0.027902, 1 batch cost time 0.51
Train Epoch: 9 [258560/319902 (81%)] Loss: 0.028685, 1 batch cost time 0.51
Train Epoch: 9 [259072/319902 (81%)] Loss: 0.041632, 1 batch cost time 0.51
Train Epoch: 9 [259584/319902 (81%)] Loss: 0.029715, 1 batch cost time 0.51
Train Epoch: 9 [260096/319902 (81%)] Loss: 0.030338, 1 batch cost time 0.51
Train Epoch: 9 [260608/319902 (81%)] Loss: 0.050103, 1 batch cost time 0.51
Train Epoch: 9 [261120/319902 (82%)] Loss: 0.012724, 1 batch cost time 0.51
Train Epoch: 9 [261632/319902 (82%)] Loss: 0.028136, 1 batch cost time 0.51
Train Epoch: 9 [262144/319902 (82%)] Loss: 0.038400, 1 batch cost time 0.51
Train Epoch: 9 [262656/319902 (82%)] Loss: 0.016087, 1 batch cost time 0.51
Train Epoch: 9 [263168/319902 (82%)] Loss: 0.022091, 1 batch cost time 0.51
Train Epoch: 9 [263680/319902 (82%)] Loss: 0.035737, 1 batch cost time 0.51
Train Epoch: 9 [264192/319902 (83%)] Loss: 0.032381, 1 batch cost time 0.51
Train Epoch: 9 [264704/319902 (83%)] Loss: 0.024701, 1 batch cost time 0.51
Train Epoch: 9 [265216/319902 (83%)] Loss: 0.027196, 1 batch cost time 0.51
Train Epoch: 9 [265728/319902 (83%)] Loss: 0.009350, 1 batch cost time 0.51
Train Epoch: 9 [266240/319902 (83%)] Loss: 0.039700, 1 batch cost time 0.51
Train Epoch: 9 [266752/319902 (83%)] Loss: 0.023918, 1 batch cost time 0.51
Train Epoch: 9 [267264/319902 (84%)] Loss: 0.017316, 1 batch cost time 0.51
Train Epoch: 9 [267776/319902 (84%)] Loss: 0.037840, 1 batch cost time 0.51
Train Epoch: 9 [268288/319902 (84%)] Loss: 0.038790, 1 batch cost time 0.51
Train Epoch: 9 [268800/319902 (84%)] Loss: 0.015310, 1 batch cost time 0.51
Train Epoch: 9 [269312/319902 (84%)] Loss: 0.030478, 1 batch cost time 0.51
Train Epoch: 9 [269824/319902 (84%)] Loss: 0.053809, 1 batch cost time 0.51
Train Epoch: 9 [270336/319902 (85%)] Loss: 0.022175, 1 batch cost time 0.51
Train Epoch: 9 [270848/319902 (85%)] Loss: 0.014529, 1 batch cost time 0.51
Train Epoch: 9 [271360/319902 (85%)] Loss: 0.033845, 1 batch cost time 0.51
Train Epoch: 9 [271872/319902 (85%)] Loss: 0.036191, 1 batch cost time 0.51
Train Epoch: 9 [272384/319902 (85%)] Loss: 0.028544, 1 batch cost time 0.51
Train Epoch: 9 [272896/319902 (85%)] Loss: 0.027338, 1 batch cost time 0.51
Train Epoch: 9 [273408/319902 (85%)] Loss: 0.039152, 1 batch cost time 0.51
Train Epoch: 9 [273920/319902 (86%)] Loss: 0.020461, 1 batch cost time 0.51
Train Epoch: 9 [274432/319902 (86%)] Loss: 0.019488, 1 batch cost time 0.51
Train Epoch: 9 [274944/319902 (86%)] Loss: 0.029946, 1 batch cost time 0.51
Train Epoch: 9 [275456/319902 (86%)] Loss: 0.014943, 1 batch cost time 0.51
Train Epoch: 9 [275968/319902 (86%)] Loss: 0.027041, 1 batch cost time 0.51
Train Epoch: 9 [276480/319902 (86%)] Loss: 0.049944, 1 batch cost time 0.51
Train Epoch: 9 [276992/319902 (87%)] Loss: 0.031102, 1 batch cost time 0.51
Train Epoch: 9 [277504/319902 (87%)] Loss: 0.015950, 1 batch cost time 0.51
Train Epoch: 9 [278016/319902 (87%)] Loss: 0.033145, 1 batch cost time 0.51
Train Epoch: 9 [278528/319902 (87%)] Loss: 0.034593, 1 batch cost time 0.51
Train Epoch: 9 [279040/319902 (87%)] Loss: 0.021039, 1 batch cost time 0.51
Train Epoch: 9 [279552/319902 (87%)] Loss: 0.025956, 1 batch cost time 0.51
Train Epoch: 9 [280064/319902 (88%)] Loss: 0.029131, 1 batch cost time 0.51
Train Epoch: 9 [280576/319902 (88%)] Loss: 0.036296, 1 batch cost time 0.51
Train Epoch: 9 [281088/319902 (88%)] Loss: 0.022289, 1 batch cost time 0.51
Train Epoch: 9 [281600/319902 (88%)] Loss: 0.014898, 1 batch cost time 0.51
Train Epoch: 9 [282112/319902 (88%)] Loss: 0.040106, 1 batch cost time 0.51
Train Epoch: 9 [282624/319902 (88%)] Loss: 0.033247, 1 batch cost time 0.51
Train Epoch: 9 [283136/319902 (89%)] Loss: 0.017901, 1 batch cost time 0.51
Train Epoch: 9 [283648/319902 (89%)] Loss: 0.054916, 1 batch cost time 0.51
Train Epoch: 9 [284160/319902 (89%)] Loss: 0.025770, 1 batch cost time 0.51
Train Epoch: 9 [284672/319902 (89%)] Loss: 0.023604, 1 batch cost time 0.51
Train Epoch: 9 [285184/319902 (89%)] Loss: 0.005061, 1 batch cost time 0.51
Train Epoch: 9 [285696/319902 (89%)] Loss: 0.026385, 1 batch cost time 0.51
Train Epoch: 9 [286208/319902 (89%)] Loss: 0.017544, 1 batch cost time 0.51
Train Epoch: 9 [286720/319902 (90%)] Loss: 0.031957, 1 batch cost time 0.51
Train Epoch: 9 [287232/319902 (90%)] Loss: 0.048904, 1 batch cost time 0.51
Train Epoch: 9 [287744/319902 (90%)] Loss: 0.030640, 1 batch cost time 0.51
Train Epoch: 9 [288256/319902 (90%)] Loss: 0.022563, 1 batch cost time 0.51
Train Epoch: 9 [288768/319902 (90%)] Loss: 0.049660, 1 batch cost time 0.51
Train Epoch: 9 [289280/319902 (90%)] Loss: 0.028643, 1 batch cost time 0.51
Train Epoch: 9 [289792/319902 (91%)] Loss: 0.011490, 1 batch cost time 0.51
Train Epoch: 9 [290304/319902 (91%)] Loss: 0.039457, 1 batch cost time 0.51
Train Epoch: 9 [290816/319902 (91%)] Loss: 0.031006, 1 batch cost time 0.51
Train Epoch: 9 [291328/319902 (91%)] Loss: 0.032626, 1 batch cost time 0.51
Train Epoch: 9 [291840/319902 (91%)] Loss: 0.029381, 1 batch cost time 0.51
Train Epoch: 9 [292352/319902 (91%)] Loss: 0.014713, 1 batch cost time 0.51
Train Epoch: 9 [292864/319902 (92%)] Loss: 0.017019, 1 batch cost time 0.51
Train Epoch: 9 [293376/319902 (92%)] Loss: 0.031658, 1 batch cost time 0.51
Train Epoch: 9 [293888/319902 (92%)] Loss: 0.046434, 1 batch cost time 0.51
Train Epoch: 9 [294400/319902 (92%)] Loss: 0.036647, 1 batch cost time 0.51
Train Epoch: 9 [294912/319902 (92%)] Loss: 0.030671, 1 batch cost time 0.51
Train Epoch: 9 [295424/319902 (92%)] Loss: 0.049941, 1 batch cost time 0.51
Train Epoch: 9 [295936/319902 (93%)] Loss: 0.035713, 1 batch cost time 0.51
Train Epoch: 9 [296448/319902 (93%)] Loss: 0.032297, 1 batch cost time 0.51
Train Epoch: 9 [296960/319902 (93%)] Loss: 0.020353, 1 batch cost time 0.51
Train Epoch: 9 [297472/319902 (93%)] Loss: 0.036096, 1 batch cost time 0.51
Train Epoch: 9 [297984/319902 (93%)] Loss: 0.025463, 1 batch cost time 0.51
Train Epoch: 9 [298496/319902 (93%)] Loss: 0.044184, 1 batch cost time 0.51
Train Epoch: 9 [299008/319902 (93%)] Loss: 0.021930, 1 batch cost time 0.51
Train Epoch: 9 [299520/319902 (94%)] Loss: 0.037784, 1 batch cost time 0.51
Train Epoch: 9 [300032/319902 (94%)] Loss: 0.022397, 1 batch cost time 0.51
Train Epoch: 9 [300544/319902 (94%)] Loss: 0.037501, 1 batch cost time 0.51
Train Epoch: 9 [301056/319902 (94%)] Loss: 0.040881, 1 batch cost time 0.51
Train Epoch: 9 [301568/319902 (94%)] Loss: 0.022984, 1 batch cost time 0.51
Train Epoch: 9 [302080/319902 (94%)] Loss: 0.044405, 1 batch cost time 0.51
Train Epoch: 9 [302592/319902 (95%)] Loss: 0.042600, 1 batch cost time 0.51
Train Epoch: 9 [303104/319902 (95%)] Loss: 0.041298, 1 batch cost time 0.51
Train Epoch: 9 [303616/319902 (95%)] Loss: 0.042767, 1 batch cost time 0.51
Train Epoch: 9 [304128/319902 (95%)] Loss: 0.007613, 1 batch cost time 0.51
Train Epoch: 9 [304640/319902 (95%)] Loss: 0.031132, 1 batch cost time 0.52
Train Epoch: 9 [305152/319902 (95%)] Loss: 0.034172, 1 batch cost time 0.51
Train Epoch: 9 [305664/319902 (96%)] Loss: 0.044375, 1 batch cost time 0.51
Train Epoch: 9 [306176/319902 (96%)] Loss: 0.047049, 1 batch cost time 0.52
Train Epoch: 9 [306688/319902 (96%)] Loss: 0.037505, 1 batch cost time 0.52
Train Epoch: 9 [307200/319902 (96%)] Loss: 0.017290, 1 batch cost time 0.51
Train Epoch: 9 [307712/319902 (96%)] Loss: 0.046301, 1 batch cost time 0.51
Train Epoch: 9 [308224/319902 (96%)] Loss: 0.029520, 1 batch cost time 0.51
Train Epoch: 9 [308736/319902 (97%)] Loss: 0.018431, 1 batch cost time 0.51
Train Epoch: 9 [309248/319902 (97%)] Loss: 0.027163, 1 batch cost time 0.52
Train Epoch: 9 [309760/319902 (97%)] Loss: 0.020961, 1 batch cost time 0.52
Train Epoch: 9 [310272/319902 (97%)] Loss: 0.051913, 1 batch cost time 0.51
Train Epoch: 9 [310784/319902 (97%)] Loss: 0.019353, 1 batch cost time 0.51
Train Epoch: 9 [311296/319902 (97%)] Loss: 0.010083, 1 batch cost time 0.51
Train Epoch: 9 [311808/319902 (97%)] Loss: 0.017947, 1 batch cost time 0.51
Train Epoch: 9 [312320/319902 (98%)] Loss: 0.013175, 1 batch cost time 0.51
Train Epoch: 9 [312832/319902 (98%)] Loss: 0.032759, 1 batch cost time 0.52
Train Epoch: 9 [313344/319902 (98%)] Loss: 0.031427, 1 batch cost time 0.51
Train Epoch: 9 [313856/319902 (98%)] Loss: 0.032444, 1 batch cost time 0.51
Train Epoch: 9 [314368/319902 (98%)] Loss: 0.016350, 1 batch cost time 0.52
Train Epoch: 9 [314880/319902 (98%)] Loss: 0.052023, 1 batch cost time 0.51
Train Epoch: 9 [315392/319902 (99%)] Loss: 0.053590, 1 batch cost time 0.51
Train Epoch: 9 [315904/319902 (99%)] Loss: 0.024014, 1 batch cost time 0.51
Train Epoch: 9 [316416/319902 (99%)] Loss: 0.026552, 1 batch cost time 0.51
Train Epoch: 9 [316928/319902 (99%)] Loss: 0.038918, 1 batch cost time 0.51
Train Epoch: 9 [317440/319902 (99%)] Loss: 0.030053, 1 batch cost time 0.51
Train Epoch: 9 [317952/319902 (99%)] Loss: 0.034493, 1 batch cost time 0.51
Train Epoch: 9 [318464/319902 (100%)] Loss: 0.032020, 1 batch cost time 0.51
Train Epoch: 9 [318976/319902 (100%)] Loss: 0.046735, 1 batch cost time 0.51
Train Epoch: 9 [319488/319902 (100%)] Loss: 0.012871, 1 batch cost time 0.51
training epoch cost 8191.831938266754 seconds
    epoch          : 9
    lr             : 0.0001
    loss           : 0.030332928812526326
    accuracy       : 0.9330200830332133
    f_measure      : 0.5630239577423449
    val_loss       : 0.024737450449417036
    val_accuracy   : 0.94482421875
    val_f_measure  : 0.5736895555254932
Saving current best: model_best.pth ...
Train Epoch: 10 [0/319902 (0%)] Loss: 0.025105, 1 batch cost time 0.52
Train Epoch: 10 [512/319902 (0%)] Loss: 0.028142, 1 batch cost time 0.51
Train Epoch: 10 [1024/319902 (0%)] Loss: 0.016034, 1 batch cost time 0.51
Train Epoch: 10 [1536/319902 (0%)] Loss: 0.041155, 1 batch cost time 0.51
Train Epoch: 10 [2048/319902 (1%)] Loss: 0.040665, 1 batch cost time 0.51
Train Epoch: 10 [2560/319902 (1%)] Loss: 0.020182, 1 batch cost time 0.51
Train Epoch: 10 [3072/319902 (1%)] Loss: 0.021091, 1 batch cost time 0.51
Train Epoch: 10 [3584/319902 (1%)] Loss: 0.045088, 1 batch cost time 0.51
Train Epoch: 10 [4096/319902 (1%)] Loss: 0.028215, 1 batch cost time 0.51
Train Epoch: 10 [4608/319902 (1%)] Loss: 0.036239, 1 batch cost time 0.51
Train Epoch: 10 [5120/319902 (2%)] Loss: 0.053315, 1 batch cost time 0.51
Train Epoch: 10 [5632/319902 (2%)] Loss: 0.020761, 1 batch cost time 0.51
Train Epoch: 10 [6144/319902 (2%)] Loss: 0.046207, 1 batch cost time 0.51
Train Epoch: 10 [6656/319902 (2%)] Loss: 0.036896, 1 batch cost time 0.51
Train Epoch: 10 [7168/319902 (2%)] Loss: 0.052270, 1 batch cost time 0.51
Train Epoch: 10 [7680/319902 (2%)] Loss: 0.014057, 1 batch cost time 0.51
Train Epoch: 10 [8192/319902 (3%)] Loss: 0.034494, 1 batch cost time 0.51
Train Epoch: 10 [8704/319902 (3%)] Loss: 0.036607, 1 batch cost time 0.51
Train Epoch: 10 [9216/319902 (3%)] Loss: 0.028024, 1 batch cost time 0.51
Train Epoch: 10 [9728/319902 (3%)] Loss: 0.027409, 1 batch cost time 0.51
Train Epoch: 10 [10240/319902 (3%)] Loss: 0.023342, 1 batch cost time 0.51
Train Epoch: 10 [10752/319902 (3%)] Loss: 0.018715, 1 batch cost time 0.51
Train Epoch: 10 [11264/319902 (4%)] Loss: 0.036999, 1 batch cost time 0.51
Train Epoch: 10 [11776/319902 (4%)] Loss: 0.027965, 1 batch cost time 0.51
Train Epoch: 10 [12288/319902 (4%)] Loss: 0.035872, 1 batch cost time 0.51
Train Epoch: 10 [12800/319902 (4%)] Loss: 0.034528, 1 batch cost time 0.51
Train Epoch: 10 [13312/319902 (4%)] Loss: 0.015630, 1 batch cost time 0.51
Train Epoch: 10 [13824/319902 (4%)] Loss: 0.039472, 1 batch cost time 0.51
Train Epoch: 10 [14336/319902 (4%)] Loss: 0.053404, 1 batch cost time 0.51
Train Epoch: 10 [14848/319902 (5%)] Loss: 0.048733, 1 batch cost time 0.51
Train Epoch: 10 [15360/319902 (5%)] Loss: 0.032908, 1 batch cost time 0.51
Train Epoch: 10 [15872/319902 (5%)] Loss: 0.031523, 1 batch cost time 0.51
Train Epoch: 10 [16384/319902 (5%)] Loss: 0.016131, 1 batch cost time 0.51
Train Epoch: 10 [16896/319902 (5%)] Loss: 0.011090, 1 batch cost time 0.51
Train Epoch: 10 [17408/319902 (5%)] Loss: 0.028362, 1 batch cost time 0.51
Train Epoch: 10 [17920/319902 (6%)] Loss: 0.041768, 1 batch cost time 0.51
Train Epoch: 10 [18432/319902 (6%)] Loss: 0.016584, 1 batch cost time 0.51
Train Epoch: 10 [18944/319902 (6%)] Loss: 0.044424, 1 batch cost time 0.51
Train Epoch: 10 [19456/319902 (6%)] Loss: 0.079929, 1 batch cost time 0.51
Train Epoch: 10 [19968/319902 (6%)] Loss: 0.017329, 1 batch cost time 0.51
Train Epoch: 10 [20480/319902 (6%)] Loss: 0.019609, 1 batch cost time 0.51
Train Epoch: 10 [20992/319902 (7%)] Loss: 0.015065, 1 batch cost time 0.51
Train Epoch: 10 [21504/319902 (7%)] Loss: 0.029765, 1 batch cost time 0.51
Train Epoch: 10 [22016/319902 (7%)] Loss: 0.065707, 1 batch cost time 0.51
Train Epoch: 10 [22528/319902 (7%)] Loss: 0.017162, 1 batch cost time 0.51
Train Epoch: 10 [23040/319902 (7%)] Loss: 0.031586, 1 batch cost time 0.51
Train Epoch: 10 [23552/319902 (7%)] Loss: 0.030451, 1 batch cost time 0.51
Train Epoch: 10 [24064/319902 (8%)] Loss: 0.041782, 1 batch cost time 0.51
Train Epoch: 10 [24576/319902 (8%)] Loss: 0.031693, 1 batch cost time 0.51
Train Epoch: 10 [25088/319902 (8%)] Loss: 0.022118, 1 batch cost time 0.51
Train Epoch: 10 [25600/319902 (8%)] Loss: 0.027943, 1 batch cost time 0.51
Train Epoch: 10 [26112/319902 (8%)] Loss: 0.024154, 1 batch cost time 0.51
Train Epoch: 10 [26624/319902 (8%)] Loss: 0.025133, 1 batch cost time 0.51
Train Epoch: 10 [27136/319902 (8%)] Loss: 0.019650, 1 batch cost time 0.51
Train Epoch: 10 [27648/319902 (9%)] Loss: 0.010299, 1 batch cost time 0.51
Train Epoch: 10 [28160/319902 (9%)] Loss: 0.021438, 1 batch cost time 0.51
Train Epoch: 10 [28672/319902 (9%)] Loss: 0.040297, 1 batch cost time 0.51
Train Epoch: 10 [29184/319902 (9%)] Loss: 0.012962, 1 batch cost time 0.51
Train Epoch: 10 [29696/319902 (9%)] Loss: 0.046817, 1 batch cost time 0.51
Train Epoch: 10 [30208/319902 (9%)] Loss: 0.025626, 1 batch cost time 0.51
Train Epoch: 10 [30720/319902 (10%)] Loss: 0.038867, 1 batch cost time 0.51
Train Epoch: 10 [31232/319902 (10%)] Loss: 0.021517, 1 batch cost time 0.51
Train Epoch: 10 [31744/319902 (10%)] Loss: 0.022683, 1 batch cost time 0.51
Train Epoch: 10 [32256/319902 (10%)] Loss: 0.038576, 1 batch cost time 0.51
Train Epoch: 10 [32768/319902 (10%)] Loss: 0.037275, 1 batch cost time 0.51
Train Epoch: 10 [33280/319902 (10%)] Loss: 0.011892, 1 batch cost time 0.51
Train Epoch: 10 [33792/319902 (11%)] Loss: 0.063578, 1 batch cost time 0.51
Train Epoch: 10 [34304/319902 (11%)] Loss: 0.037554, 1 batch cost time 0.51
Train Epoch: 10 [34816/319902 (11%)] Loss: 0.018264, 1 batch cost time 0.51
Train Epoch: 10 [35328/319902 (11%)] Loss: 0.020946, 1 batch cost time 0.51
Train Epoch: 10 [35840/319902 (11%)] Loss: 0.043624, 1 batch cost time 0.51
Train Epoch: 10 [36352/319902 (11%)] Loss: 0.062484, 1 batch cost time 0.51
Train Epoch: 10 [36864/319902 (12%)] Loss: 0.050180, 1 batch cost time 0.51
Train Epoch: 10 [37376/319902 (12%)] Loss: 0.046290, 1 batch cost time 0.51
Train Epoch: 10 [37888/319902 (12%)] Loss: 0.018792, 1 batch cost time 0.51
Train Epoch: 10 [38400/319902 (12%)] Loss: 0.034736, 1 batch cost time 0.51
Train Epoch: 10 [38912/319902 (12%)] Loss: 0.027821, 1 batch cost time 0.51
Train Epoch: 10 [39424/319902 (12%)] Loss: 0.035934, 1 batch cost time 0.51
Train Epoch: 10 [39936/319902 (12%)] Loss: 0.031287, 1 batch cost time 0.51
Train Epoch: 10 [40448/319902 (13%)] Loss: 0.013017, 1 batch cost time 0.51
Train Epoch: 10 [40960/319902 (13%)] Loss: 0.034826, 1 batch cost time 0.51
Train Epoch: 10 [41472/319902 (13%)] Loss: 0.030300, 1 batch cost time 0.51
Train Epoch: 10 [41984/319902 (13%)] Loss: 0.033771, 1 batch cost time 0.51
Train Epoch: 10 [42496/319902 (13%)] Loss: 0.020558, 1 batch cost time 0.51
Train Epoch: 10 [43008/319902 (13%)] Loss: 0.028109, 1 batch cost time 0.51
Train Epoch: 10 [43520/319902 (14%)] Loss: 0.050165, 1 batch cost time 0.51
Train Epoch: 10 [44032/319902 (14%)] Loss: 0.033347, 1 batch cost time 0.51
Train Epoch: 10 [44544/319902 (14%)] Loss: 0.015436, 1 batch cost time 0.51
Train Epoch: 10 [45056/319902 (14%)] Loss: 0.022575, 1 batch cost time 0.51
Train Epoch: 10 [45568/319902 (14%)] Loss: 0.038191, 1 batch cost time 0.51
Train Epoch: 10 [46080/319902 (14%)] Loss: 0.054642, 1 batch cost time 0.51
Train Epoch: 10 [46592/319902 (15%)] Loss: 0.028034, 1 batch cost time 0.51
Train Epoch: 10 [47104/319902 (15%)] Loss: 0.020260, 1 batch cost time 0.51
Train Epoch: 10 [47616/319902 (15%)] Loss: 0.028642, 1 batch cost time 0.51
Train Epoch: 10 [48128/319902 (15%)] Loss: 0.035241, 1 batch cost time 0.51
Train Epoch: 10 [48640/319902 (15%)] Loss: 0.012974, 1 batch cost time 0.51
Train Epoch: 10 [49152/319902 (15%)] Loss: 0.012899, 1 batch cost time 0.51
Train Epoch: 10 [49664/319902 (16%)] Loss: 0.038173, 1 batch cost time 0.51
Train Epoch: 10 [50176/319902 (16%)] Loss: 0.048139, 1 batch cost time 0.51
Train Epoch: 10 [50688/319902 (16%)] Loss: 0.033471, 1 batch cost time 0.51
Train Epoch: 10 [51200/319902 (16%)] Loss: 0.023444, 1 batch cost time 0.51
Train Epoch: 10 [51712/319902 (16%)] Loss: 0.050538, 1 batch cost time 0.51
Train Epoch: 10 [52224/319902 (16%)] Loss: 0.019872, 1 batch cost time 0.51
Train Epoch: 10 [52736/319902 (16%)] Loss: 0.019591, 1 batch cost time 0.51
Train Epoch: 10 [53248/319902 (17%)] Loss: 0.018429, 1 batch cost time 0.51
Train Epoch: 10 [53760/319902 (17%)] Loss: 0.019667, 1 batch cost time 0.51
Train Epoch: 10 [54272/319902 (17%)] Loss: 0.018430, 1 batch cost time 0.51
Train Epoch: 10 [54784/319902 (17%)] Loss: 0.044472, 1 batch cost time 0.51
Train Epoch: 10 [55296/319902 (17%)] Loss: 0.040160, 1 batch cost time 0.51
Train Epoch: 10 [55808/319902 (17%)] Loss: 0.045708, 1 batch cost time 0.51
Train Epoch: 10 [56320/319902 (18%)] Loss: 0.044495, 1 batch cost time 0.51
Train Epoch: 10 [56832/319902 (18%)] Loss: 0.027896, 1 batch cost time 0.51
Train Epoch: 10 [57344/319902 (18%)] Loss: 0.044617, 1 batch cost time 0.51
Train Epoch: 10 [57856/319902 (18%)] Loss: 0.024124, 1 batch cost time 0.51
Train Epoch: 10 [58368/319902 (18%)] Loss: 0.032045, 1 batch cost time 0.51
Train Epoch: 10 [58880/319902 (18%)] Loss: 0.030311, 1 batch cost time 0.51
Train Epoch: 10 [59392/319902 (19%)] Loss: 0.037605, 1 batch cost time 0.51
Train Epoch: 10 [59904/319902 (19%)] Loss: 0.028482, 1 batch cost time 0.51
Train Epoch: 10 [60416/319902 (19%)] Loss: 0.030093, 1 batch cost time 0.51
Train Epoch: 10 [60928/319902 (19%)] Loss: 0.053407, 1 batch cost time 0.51
Train Epoch: 10 [61440/319902 (19%)] Loss: 0.011967, 1 batch cost time 0.51
Train Epoch: 10 [61952/319902 (19%)] Loss: 0.046758, 1 batch cost time 0.51
Train Epoch: 10 [62464/319902 (20%)] Loss: 0.033392, 1 batch cost time 0.51
Train Epoch: 10 [62976/319902 (20%)] Loss: 0.025626, 1 batch cost time 0.51
Train Epoch: 10 [63488/319902 (20%)] Loss: 0.024369, 1 batch cost time 0.51
Train Epoch: 10 [64000/319902 (20%)] Loss: 0.020540, 1 batch cost time 0.51
Train Epoch: 10 [64512/319902 (20%)] Loss: 0.039603, 1 batch cost time 0.51
Train Epoch: 10 [65024/319902 (20%)] Loss: 0.011530, 1 batch cost time 0.51
Train Epoch: 10 [65536/319902 (20%)] Loss: 0.027610, 1 batch cost time 0.51
Train Epoch: 10 [66048/319902 (21%)] Loss: 0.017016, 1 batch cost time 0.51
Train Epoch: 10 [66560/319902 (21%)] Loss: 0.026554, 1 batch cost time 0.51
Train Epoch: 10 [67072/319902 (21%)] Loss: 0.038654, 1 batch cost time 0.51
Train Epoch: 10 [67584/319902 (21%)] Loss: 0.017644, 1 batch cost time 0.51
Train Epoch: 10 [68096/319902 (21%)] Loss: 0.035719, 1 batch cost time 0.51
Train Epoch: 10 [68608/319902 (21%)] Loss: 0.044732, 1 batch cost time 0.51
Train Epoch: 10 [69120/319902 (22%)] Loss: 0.015846, 1 batch cost time 0.51
Train Epoch: 10 [69632/319902 (22%)] Loss: 0.031703, 1 batch cost time 0.51
Train Epoch: 10 [70144/319902 (22%)] Loss: 0.019949, 1 batch cost time 0.51
Train Epoch: 10 [70656/319902 (22%)] Loss: 0.018440, 1 batch cost time 0.51
Train Epoch: 10 [71168/319902 (22%)] Loss: 0.026042, 1 batch cost time 0.51
Train Epoch: 10 [71680/319902 (22%)] Loss: 0.041616, 1 batch cost time 0.51
Train Epoch: 10 [72192/319902 (23%)] Loss: 0.019097, 1 batch cost time 0.51
Train Epoch: 10 [72704/319902 (23%)] Loss: 0.036973, 1 batch cost time 0.51
Train Epoch: 10 [73216/319902 (23%)] Loss: 0.020664, 1 batch cost time 0.51
Train Epoch: 10 [73728/319902 (23%)] Loss: 0.050036, 1 batch cost time 0.51
Train Epoch: 10 [74240/319902 (23%)] Loss: 0.011426, 1 batch cost time 0.51
Train Epoch: 10 [74752/319902 (23%)] Loss: 0.044749, 1 batch cost time 0.51
Train Epoch: 10 [75264/319902 (24%)] Loss: 0.017277, 1 batch cost time 0.51
Train Epoch: 10 [75776/319902 (24%)] Loss: 0.044719, 1 batch cost time 0.51
Train Epoch: 10 [76288/319902 (24%)] Loss: 0.015785, 1 batch cost time 0.51
Train Epoch: 10 [76800/319902 (24%)] Loss: 0.016714, 1 batch cost time 0.51
Train Epoch: 10 [77312/319902 (24%)] Loss: 0.027872, 1 batch cost time 0.51
Train Epoch: 10 [77824/319902 (24%)] Loss: 0.035456, 1 batch cost time 0.51
Train Epoch: 10 [78336/319902 (24%)] Loss: 0.042866, 1 batch cost time 0.51
Train Epoch: 10 [78848/319902 (25%)] Loss: 0.033554, 1 batch cost time 0.51
Train Epoch: 10 [79360/319902 (25%)] Loss: 0.029946, 1 batch cost time 0.51
Train Epoch: 10 [79872/319902 (25%)] Loss: 0.021389, 1 batch cost time 0.51
Train Epoch: 10 [80384/319902 (25%)] Loss: 0.009510, 1 batch cost time 0.51
Train Epoch: 10 [80896/319902 (25%)] Loss: 0.047663, 1 batch cost time 0.51
Train Epoch: 10 [81408/319902 (25%)] Loss: 0.040227, 1 batch cost time 0.51
Train Epoch: 10 [81920/319902 (26%)] Loss: 0.027096, 1 batch cost time 0.51
Train Epoch: 10 [82432/319902 (26%)] Loss: 0.027221, 1 batch cost time 0.51
Train Epoch: 10 [82944/319902 (26%)] Loss: 0.022663, 1 batch cost time 0.51
Train Epoch: 10 [83456/319902 (26%)] Loss: 0.012314, 1 batch cost time 0.51
Train Epoch: 10 [83968/319902 (26%)] Loss: 0.026310, 1 batch cost time 0.51
Train Epoch: 10 [84480/319902 (26%)] Loss: 0.024291, 1 batch cost time 0.51
Train Epoch: 10 [84992/319902 (27%)] Loss: 0.021396, 1 batch cost time 0.51
Train Epoch: 10 [85504/319902 (27%)] Loss: 0.039632, 1 batch cost time 0.51
Train Epoch: 10 [86016/319902 (27%)] Loss: 0.026637, 1 batch cost time 0.51
Train Epoch: 10 [86528/319902 (27%)] Loss: 0.038361, 1 batch cost time 0.51
Train Epoch: 10 [87040/319902 (27%)] Loss: 0.023115, 1 batch cost time 0.51
Train Epoch: 10 [87552/319902 (27%)] Loss: 0.038704, 1 batch cost time 0.51
Train Epoch: 10 [88064/319902 (28%)] Loss: 0.027566, 1 batch cost time 0.51
Train Epoch: 10 [88576/319902 (28%)] Loss: 0.024234, 1 batch cost time 0.51
Train Epoch: 10 [89088/319902 (28%)] Loss: 0.039549, 1 batch cost time 0.51
Train Epoch: 10 [89600/319902 (28%)] Loss: 0.011062, 1 batch cost time 0.51
Train Epoch: 10 [90112/319902 (28%)] Loss: 0.011308, 1 batch cost time 0.51
Train Epoch: 10 [90624/319902 (28%)] Loss: 0.026490, 1 batch cost time 0.51
Train Epoch: 10 [91136/319902 (28%)] Loss: 0.022397, 1 batch cost time 0.51
Train Epoch: 10 [91648/319902 (29%)] Loss: 0.018949, 1 batch cost time 0.51
Train Epoch: 10 [92160/319902 (29%)] Loss: 0.031132, 1 batch cost time 0.51
Train Epoch: 10 [92672/319902 (29%)] Loss: 0.026908, 1 batch cost time 0.51
Train Epoch: 10 [93184/319902 (29%)] Loss: 0.030113, 1 batch cost time 0.51
Train Epoch: 10 [93696/319902 (29%)] Loss: 0.026528, 1 batch cost time 0.51
Train Epoch: 10 [94208/319902 (29%)] Loss: 0.030422, 1 batch cost time 0.51
Train Epoch: 10 [94720/319902 (30%)] Loss: 0.039483, 1 batch cost time 0.51
Train Epoch: 10 [95232/319902 (30%)] Loss: 0.043720, 1 batch cost time 0.51
Train Epoch: 10 [95744/319902 (30%)] Loss: 0.036980, 1 batch cost time 0.51
Train Epoch: 10 [96256/319902 (30%)] Loss: 0.023640, 1 batch cost time 0.51
Train Epoch: 10 [96768/319902 (30%)] Loss: 0.015920, 1 batch cost time 0.51
Train Epoch: 10 [97280/319902 (30%)] Loss: 0.030836, 1 batch cost time 0.51
Train Epoch: 10 [97792/319902 (31%)] Loss: 0.006372, 1 batch cost time 0.51
Train Epoch: 10 [98304/319902 (31%)] Loss: 0.022636, 1 batch cost time 0.51
Train Epoch: 10 [98816/319902 (31%)] Loss: 0.024018, 1 batch cost time 0.51
Train Epoch: 10 [99328/319902 (31%)] Loss: 0.038122, 1 batch cost time 0.51
Train Epoch: 10 [99840/319902 (31%)] Loss: 0.033384, 1 batch cost time 0.51
Train Epoch: 10 [100352/319902 (31%)] Loss: 0.046377, 1 batch cost time 0.51
Train Epoch: 10 [100864/319902 (32%)] Loss: 0.036865, 1 batch cost time 0.51
Train Epoch: 10 [101376/319902 (32%)] Loss: 0.057387, 1 batch cost time 0.51
Train Epoch: 10 [101888/319902 (32%)] Loss: 0.038549, 1 batch cost time 0.51
Train Epoch: 10 [102400/319902 (32%)] Loss: 0.027499, 1 batch cost time 0.51
Train Epoch: 10 [102912/319902 (32%)] Loss: 0.022030, 1 batch cost time 0.51
Train Epoch: 10 [103424/319902 (32%)] Loss: 0.036692, 1 batch cost time 0.51
Train Epoch: 10 [103936/319902 (32%)] Loss: 0.048446, 1 batch cost time 0.51
Train Epoch: 10 [104448/319902 (33%)] Loss: 0.021678, 1 batch cost time 0.51
Train Epoch: 10 [104960/319902 (33%)] Loss: 0.038036, 1 batch cost time 0.51
Train Epoch: 10 [105472/319902 (33%)] Loss: 0.022182, 1 batch cost time 0.51
Train Epoch: 10 [105984/319902 (33%)] Loss: 0.022150, 1 batch cost time 0.51
Train Epoch: 10 [106496/319902 (33%)] Loss: 0.056460, 1 batch cost time 0.51
Train Epoch: 10 [107008/319902 (33%)] Loss: 0.044549, 1 batch cost time 0.51
Train Epoch: 10 [107520/319902 (34%)] Loss: 0.013934, 1 batch cost time 0.51
Train Epoch: 10 [108032/319902 (34%)] Loss: 0.029576, 1 batch cost time 0.51
Train Epoch: 10 [108544/319902 (34%)] Loss: 0.013216, 1 batch cost time 0.51
Train Epoch: 10 [109056/319902 (34%)] Loss: 0.015504, 1 batch cost time 0.51
Train Epoch: 10 [109568/319902 (34%)] Loss: 0.056000, 1 batch cost time 0.51
Train Epoch: 10 [110080/319902 (34%)] Loss: 0.015959, 1 batch cost time 0.51
Train Epoch: 10 [110592/319902 (35%)] Loss: 0.030193, 1 batch cost time 0.51
Train Epoch: 10 [111104/319902 (35%)] Loss: 0.049459, 1 batch cost time 0.51
Train Epoch: 10 [111616/319902 (35%)] Loss: 0.025635, 1 batch cost time 0.51
Train Epoch: 10 [112128/319902 (35%)] Loss: 0.030380, 1 batch cost time 0.51
Train Epoch: 10 [112640/319902 (35%)] Loss: 0.018864, 1 batch cost time 0.51
Train Epoch: 10 [113152/319902 (35%)] Loss: 0.037487, 1 batch cost time 0.51
Train Epoch: 10 [113664/319902 (36%)] Loss: 0.050005, 1 batch cost time 0.51
Train Epoch: 10 [114176/319902 (36%)] Loss: 0.043692, 1 batch cost time 0.51
Train Epoch: 10 [114688/319902 (36%)] Loss: 0.033168, 1 batch cost time 0.51
Train Epoch: 10 [115200/319902 (36%)] Loss: 0.027341, 1 batch cost time 0.51
Train Epoch: 10 [115712/319902 (36%)] Loss: 0.016677, 1 batch cost time 0.51
Train Epoch: 10 [116224/319902 (36%)] Loss: 0.045231, 1 batch cost time 0.51
Train Epoch: 10 [116736/319902 (36%)] Loss: 0.022583, 1 batch cost time 0.51
Train Epoch: 10 [117248/319902 (37%)] Loss: 0.018790, 1 batch cost time 0.51
Train Epoch: 10 [117760/319902 (37%)] Loss: 0.021813, 1 batch cost time 0.51
Train Epoch: 10 [118272/319902 (37%)] Loss: 0.020695, 1 batch cost time 0.51
Train Epoch: 10 [118784/319902 (37%)] Loss: 0.031682, 1 batch cost time 0.51
Train Epoch: 10 [119296/319902 (37%)] Loss: 0.038557, 1 batch cost time 0.51
Train Epoch: 10 [119808/319902 (37%)] Loss: 0.035433, 1 batch cost time 0.51
Train Epoch: 10 [120320/319902 (38%)] Loss: 0.033545, 1 batch cost time 0.51
Train Epoch: 10 [120832/319902 (38%)] Loss: 0.017063, 1 batch cost time 0.51
Train Epoch: 10 [121344/319902 (38%)] Loss: 0.052914, 1 batch cost time 0.51
Train Epoch: 10 [121856/319902 (38%)] Loss: 0.019214, 1 batch cost time 0.51
Train Epoch: 10 [122368/319902 (38%)] Loss: 0.018644, 1 batch cost time 0.51
Train Epoch: 10 [122880/319902 (38%)] Loss: 0.056513, 1 batch cost time 0.51
Train Epoch: 10 [123392/319902 (39%)] Loss: 0.014755, 1 batch cost time 0.51
Train Epoch: 10 [123904/319902 (39%)] Loss: 0.019077, 1 batch cost time 0.51
Train Epoch: 10 [124416/319902 (39%)] Loss: 0.014938, 1 batch cost time 0.51
Train Epoch: 10 [124928/319902 (39%)] Loss: 0.026503, 1 batch cost time 0.51
Train Epoch: 10 [125440/319902 (39%)] Loss: 0.049044, 1 batch cost time 0.51
Train Epoch: 10 [125952/319902 (39%)] Loss: 0.041028, 1 batch cost time 0.51
Train Epoch: 10 [126464/319902 (40%)] Loss: 0.019882, 1 batch cost time 0.51
Train Epoch: 10 [126976/319902 (40%)] Loss: 0.026088, 1 batch cost time 0.51
Train Epoch: 10 [127488/319902 (40%)] Loss: 0.028142, 1 batch cost time 0.51
Train Epoch: 10 [128000/319902 (40%)] Loss: 0.053954, 1 batch cost time 0.51
Train Epoch: 10 [128512/319902 (40%)] Loss: 0.024883, 1 batch cost time 0.51
Train Epoch: 10 [129024/319902 (40%)] Loss: 0.026495, 1 batch cost time 0.51
Train Epoch: 10 [129536/319902 (40%)] Loss: 0.020008, 1 batch cost time 0.51
Train Epoch: 10 [130048/319902 (41%)] Loss: 0.068610, 1 batch cost time 0.51
Train Epoch: 10 [130560/319902 (41%)] Loss: 0.022809, 1 batch cost time 0.51
Train Epoch: 10 [131072/319902 (41%)] Loss: 0.033271, 1 batch cost time 0.51
Train Epoch: 10 [131584/319902 (41%)] Loss: 0.076238, 1 batch cost time 0.51
Train Epoch: 10 [132096/319902 (41%)] Loss: 0.042187, 1 batch cost time 0.51
Train Epoch: 10 [132608/319902 (41%)] Loss: 0.037608, 1 batch cost time 0.51
Train Epoch: 10 [133120/319902 (42%)] Loss: 0.022010, 1 batch cost time 0.51
Train Epoch: 10 [133632/319902 (42%)] Loss: 0.020968, 1 batch cost time 0.51
Train Epoch: 10 [134144/319902 (42%)] Loss: 0.020263, 1 batch cost time 0.51
Train Epoch: 10 [134656/319902 (42%)] Loss: 0.022993, 1 batch cost time 0.51
Train Epoch: 10 [135168/319902 (42%)] Loss: 0.037940, 1 batch cost time 0.51
Train Epoch: 10 [135680/319902 (42%)] Loss: 0.015395, 1 batch cost time 0.51
Train Epoch: 10 [136192/319902 (43%)] Loss: 0.013352, 1 batch cost time 0.51
Train Epoch: 10 [136704/319902 (43%)] Loss: 0.032981, 1 batch cost time 0.51
Train Epoch: 10 [137216/319902 (43%)] Loss: 0.019563, 1 batch cost time 0.51
Train Epoch: 10 [137728/319902 (43%)] Loss: 0.027851, 1 batch cost time 0.51
Train Epoch: 10 [138240/319902 (43%)] Loss: 0.034538, 1 batch cost time 0.51
Train Epoch: 10 [138752/319902 (43%)] Loss: 0.052193, 1 batch cost time 0.51
Train Epoch: 10 [139264/319902 (44%)] Loss: 0.031736, 1 batch cost time 0.51
Train Epoch: 10 [139776/319902 (44%)] Loss: 0.014004, 1 batch cost time 0.51
Train Epoch: 10 [140288/319902 (44%)] Loss: 0.013231, 1 batch cost time 0.51
Train Epoch: 10 [140800/319902 (44%)] Loss: 0.026733, 1 batch cost time 0.51
Train Epoch: 10 [141312/319902 (44%)] Loss: 0.034971, 1 batch cost time 0.51
Train Epoch: 10 [141824/319902 (44%)] Loss: 0.031109, 1 batch cost time 0.51
Train Epoch: 10 [142336/319902 (44%)] Loss: 0.030324, 1 batch cost time 0.51
Train Epoch: 10 [142848/319902 (45%)] Loss: 0.030393, 1 batch cost time 0.51
Train Epoch: 10 [143360/319902 (45%)] Loss: 0.030878, 1 batch cost time 0.51
Train Epoch: 10 [143872/319902 (45%)] Loss: 0.027323, 1 batch cost time 0.51
Train Epoch: 10 [144384/319902 (45%)] Loss: 0.017331, 1 batch cost time 0.51
Train Epoch: 10 [144896/319902 (45%)] Loss: 0.018632, 1 batch cost time 0.51
Train Epoch: 10 [145408/319902 (45%)] Loss: 0.016214, 1 batch cost time 0.51
Train Epoch: 10 [145920/319902 (46%)] Loss: 0.036279, 1 batch cost time 0.51
Train Epoch: 10 [146432/319902 (46%)] Loss: 0.023719, 1 batch cost time 0.51
Train Epoch: 10 [146944/319902 (46%)] Loss: 0.029634, 1 batch cost time 0.51
Train Epoch: 10 [147456/319902 (46%)] Loss: 0.017296, 1 batch cost time 0.51
Train Epoch: 10 [147968/319902 (46%)] Loss: 0.039824, 1 batch cost time 0.51
Train Epoch: 10 [148480/319902 (46%)] Loss: 0.034452, 1 batch cost time 0.51
Train Epoch: 10 [148992/319902 (47%)] Loss: 0.018375, 1 batch cost time 0.51
Train Epoch: 10 [149504/319902 (47%)] Loss: 0.040371, 1 batch cost time 0.51
Train Epoch: 10 [150016/319902 (47%)] Loss: 0.018558, 1 batch cost time 0.51
Train Epoch: 10 [150528/319902 (47%)] Loss: 0.032874, 1 batch cost time 0.51
Train Epoch: 10 [151040/319902 (47%)] Loss: 0.022869, 1 batch cost time 0.51
Train Epoch: 10 [151552/319902 (47%)] Loss: 0.060852, 1 batch cost time 0.51
Train Epoch: 10 [152064/319902 (48%)] Loss: 0.021801, 1 batch cost time 0.51
Train Epoch: 10 [152576/319902 (48%)] Loss: 0.045401, 1 batch cost time 0.51
Train Epoch: 10 [153088/319902 (48%)] Loss: 0.030494, 1 batch cost time 0.51
Train Epoch: 10 [153600/319902 (48%)] Loss: 0.028447, 1 batch cost time 0.51
Train Epoch: 10 [154112/319902 (48%)] Loss: 0.025458, 1 batch cost time 0.51
Train Epoch: 10 [154624/319902 (48%)] Loss: 0.021920, 1 batch cost time 0.51
Train Epoch: 10 [155136/319902 (48%)] Loss: 0.040345, 1 batch cost time 0.51
Train Epoch: 10 [155648/319902 (49%)] Loss: 0.044603, 1 batch cost time 0.51
Train Epoch: 10 [156160/319902 (49%)] Loss: 0.018100, 1 batch cost time 0.51
Train Epoch: 10 [156672/319902 (49%)] Loss: 0.024605, 1 batch cost time 0.51
Train Epoch: 10 [157184/319902 (49%)] Loss: 0.020340, 1 batch cost time 0.51
Train Epoch: 10 [157696/319902 (49%)] Loss: 0.036218, 1 batch cost time 0.51
Train Epoch: 10 [158208/319902 (49%)] Loss: 0.013793, 1 batch cost time 0.51
Train Epoch: 10 [158720/319902 (50%)] Loss: 0.022489, 1 batch cost time 0.51
Train Epoch: 10 [159232/319902 (50%)] Loss: 0.025680, 1 batch cost time 0.51
Train Epoch: 10 [159744/319902 (50%)] Loss: 0.044323, 1 batch cost time 0.51
Train Epoch: 10 [160256/319902 (50%)] Loss: 0.015117, 1 batch cost time 0.51
Train Epoch: 10 [160768/319902 (50%)] Loss: 0.012685, 1 batch cost time 0.51
Train Epoch: 10 [161280/319902 (50%)] Loss: 0.031297, 1 batch cost time 0.51
Train Epoch: 10 [161792/319902 (51%)] Loss: 0.048101, 1 batch cost time 0.51
Train Epoch: 10 [162304/319902 (51%)] Loss: 0.026661, 1 batch cost time 0.51
Train Epoch: 10 [162816/319902 (51%)] Loss: 0.046413, 1 batch cost time 0.51
Train Epoch: 10 [163328/319902 (51%)] Loss: 0.007347, 1 batch cost time 0.51
Train Epoch: 10 [163840/319902 (51%)] Loss: 0.023548, 1 batch cost time 0.51
Train Epoch: 10 [164352/319902 (51%)] Loss: 0.025519, 1 batch cost time 0.51
Train Epoch: 10 [164864/319902 (52%)] Loss: 0.030958, 1 batch cost time 0.51
Train Epoch: 10 [165376/319902 (52%)] Loss: 0.059314, 1 batch cost time 0.51
Train Epoch: 10 [165888/319902 (52%)] Loss: 0.024801, 1 batch cost time 0.51
Train Epoch: 10 [166400/319902 (52%)] Loss: 0.026883, 1 batch cost time 0.51
Train Epoch: 10 [166912/319902 (52%)] Loss: 0.011375, 1 batch cost time 0.51
Train Epoch: 10 [167424/319902 (52%)] Loss: 0.022089, 1 batch cost time 0.51
Train Epoch: 10 [167936/319902 (52%)] Loss: 0.009131, 1 batch cost time 0.51
Train Epoch: 10 [168448/319902 (53%)] Loss: 0.032650, 1 batch cost time 0.51
Train Epoch: 10 [168960/319902 (53%)] Loss: 0.037000, 1 batch cost time 0.51
Train Epoch: 10 [169472/319902 (53%)] Loss: 0.029837, 1 batch cost time 0.51
Train Epoch: 10 [169984/319902 (53%)] Loss: 0.029356, 1 batch cost time 0.51
Train Epoch: 10 [170496/319902 (53%)] Loss: 0.018193, 1 batch cost time 0.51
Train Epoch: 10 [171008/319902 (53%)] Loss: 0.045710, 1 batch cost time 0.51
Train Epoch: 10 [171520/319902 (54%)] Loss: 0.045143, 1 batch cost time 0.51
Train Epoch: 10 [172032/319902 (54%)] Loss: 0.022661, 1 batch cost time 0.51
Train Epoch: 10 [172544/319902 (54%)] Loss: 0.038526, 1 batch cost time 0.51
Train Epoch: 10 [173056/319902 (54%)] Loss: 0.044756, 1 batch cost time 0.51
Train Epoch: 10 [173568/319902 (54%)] Loss: 0.019649, 1 batch cost time 0.51
Train Epoch: 10 [174080/319902 (54%)] Loss: 0.021896, 1 batch cost time 0.51
Train Epoch: 10 [174592/319902 (55%)] Loss: 0.037044, 1 batch cost time 0.51
Train Epoch: 10 [175104/319902 (55%)] Loss: 0.015700, 1 batch cost time 0.51
Train Epoch: 10 [175616/319902 (55%)] Loss: 0.030573, 1 batch cost time 0.51
Train Epoch: 10 [176128/319902 (55%)] Loss: 0.037077, 1 batch cost time 0.51
Train Epoch: 10 [176640/319902 (55%)] Loss: 0.040265, 1 batch cost time 0.51
Train Epoch: 10 [177152/319902 (55%)] Loss: 0.012609, 1 batch cost time 0.51
Train Epoch: 10 [177664/319902 (56%)] Loss: 0.044095, 1 batch cost time 0.51
Train Epoch: 10 [178176/319902 (56%)] Loss: 0.018698, 1 batch cost time 0.51
Train Epoch: 10 [178688/319902 (56%)] Loss: 0.018551, 1 batch cost time 0.51
Train Epoch: 10 [179200/319902 (56%)] Loss: 0.039753, 1 batch cost time 0.51
Train Epoch: 10 [179712/319902 (56%)] Loss: 0.028935, 1 batch cost time 0.51
Train Epoch: 10 [180224/319902 (56%)] Loss: 0.029785, 1 batch cost time 0.51
Train Epoch: 10 [180736/319902 (56%)] Loss: 0.057351, 1 batch cost time 0.51
Train Epoch: 10 [181248/319902 (57%)] Loss: 0.028885, 1 batch cost time 0.51
Train Epoch: 10 [181760/319902 (57%)] Loss: 0.026576, 1 batch cost time 0.51
Train Epoch: 10 [182272/319902 (57%)] Loss: 0.011878, 1 batch cost time 0.51
Train Epoch: 10 [182784/319902 (57%)] Loss: 0.023604, 1 batch cost time 0.51
Train Epoch: 10 [183296/319902 (57%)] Loss: 0.030362, 1 batch cost time 0.51
Train Epoch: 10 [183808/319902 (57%)] Loss: 0.036880, 1 batch cost time 0.51
Train Epoch: 10 [184320/319902 (58%)] Loss: 0.016982, 1 batch cost time 0.51
Train Epoch: 10 [184832/319902 (58%)] Loss: 0.024784, 1 batch cost time 0.51
Train Epoch: 10 [185344/319902 (58%)] Loss: 0.028834, 1 batch cost time 0.51
Train Epoch: 10 [185856/319902 (58%)] Loss: 0.048813, 1 batch cost time 0.51
Train Epoch: 10 [186368/319902 (58%)] Loss: 0.026459, 1 batch cost time 0.51
Train Epoch: 10 [186880/319902 (58%)] Loss: 0.029095, 1 batch cost time 0.51
Train Epoch: 10 [187392/319902 (59%)] Loss: 0.038229, 1 batch cost time 0.51
Train Epoch: 10 [187904/319902 (59%)] Loss: 0.051455, 1 batch cost time 0.51
Train Epoch: 10 [188416/319902 (59%)] Loss: 0.028922, 1 batch cost time 0.51
Train Epoch: 10 [188928/319902 (59%)] Loss: 0.018425, 1 batch cost time 0.51
Train Epoch: 10 [189440/319902 (59%)] Loss: 0.045104, 1 batch cost time 0.51
Train Epoch: 10 [189952/319902 (59%)] Loss: 0.030132, 1 batch cost time 0.51
Train Epoch: 10 [190464/319902 (60%)] Loss: 0.029150, 1 batch cost time 0.51
Train Epoch: 10 [190976/319902 (60%)] Loss: 0.033374, 1 batch cost time 0.51
Train Epoch: 10 [191488/319902 (60%)] Loss: 0.030417, 1 batch cost time 0.51
Train Epoch: 10 [192000/319902 (60%)] Loss: 0.007859, 1 batch cost time 0.51
Train Epoch: 10 [192512/319902 (60%)] Loss: 0.030386, 1 batch cost time 0.51
Train Epoch: 10 [193024/319902 (60%)] Loss: 0.038719, 1 batch cost time 0.51
Train Epoch: 10 [193536/319902 (60%)] Loss: 0.027131, 1 batch cost time 0.51
Train Epoch: 10 [194048/319902 (61%)] Loss: 0.044198, 1 batch cost time 0.51
Train Epoch: 10 [194560/319902 (61%)] Loss: 0.034001, 1 batch cost time 0.51
Train Epoch: 10 [195072/319902 (61%)] Loss: 0.021024, 1 batch cost time 0.51
Train Epoch: 10 [195584/319902 (61%)] Loss: 0.016054, 1 batch cost time 0.51
Train Epoch: 10 [196096/319902 (61%)] Loss: 0.033110, 1 batch cost time 0.51
Train Epoch: 10 [196608/319902 (61%)] Loss: 0.038877, 1 batch cost time 0.51
Train Epoch: 10 [197120/319902 (62%)] Loss: 0.024231, 1 batch cost time 0.51
Train Epoch: 10 [197632/319902 (62%)] Loss: 0.036903, 1 batch cost time 0.51
Train Epoch: 10 [198144/319902 (62%)] Loss: 0.011397, 1 batch cost time 0.51
Train Epoch: 10 [198656/319902 (62%)] Loss: 0.051381, 1 batch cost time 0.51
Train Epoch: 10 [199168/319902 (62%)] Loss: 0.021491, 1 batch cost time 0.51
Train Epoch: 10 [199680/319902 (62%)] Loss: 0.038397, 1 batch cost time 0.51
Train Epoch: 10 [200192/319902 (63%)] Loss: 0.035772, 1 batch cost time 0.51
Train Epoch: 10 [200704/319902 (63%)] Loss: 0.015383, 1 batch cost time 0.51
Train Epoch: 10 [201216/319902 (63%)] Loss: 0.041301, 1 batch cost time 0.51
Train Epoch: 10 [201728/319902 (63%)] Loss: 0.028645, 1 batch cost time 0.51
Train Epoch: 10 [202240/319902 (63%)] Loss: 0.017529, 1 batch cost time 0.51
Train Epoch: 10 [202752/319902 (63%)] Loss: 0.025176, 1 batch cost time 0.51
Train Epoch: 10 [203264/319902 (64%)] Loss: 0.037482, 1 batch cost time 0.51
Train Epoch: 10 [203776/319902 (64%)] Loss: 0.032644, 1 batch cost time 0.51
Train Epoch: 10 [204288/319902 (64%)] Loss: 0.047840, 1 batch cost time 0.51
Train Epoch: 10 [204800/319902 (64%)] Loss: 0.023276, 1 batch cost time 0.51
Train Epoch: 10 [205312/319902 (64%)] Loss: 0.016139, 1 batch cost time 0.51
Train Epoch: 10 [205824/319902 (64%)] Loss: 0.046000, 1 batch cost time 0.51
Train Epoch: 10 [206336/319902 (64%)] Loss: 0.014904, 1 batch cost time 0.51
Train Epoch: 10 [206848/319902 (65%)] Loss: 0.018034, 1 batch cost time 0.51
Train Epoch: 10 [207360/319902 (65%)] Loss: 0.036245, 1 batch cost time 0.51
Train Epoch: 10 [207872/319902 (65%)] Loss: 0.046104, 1 batch cost time 0.51
Train Epoch: 10 [208384/319902 (65%)] Loss: 0.027801, 1 batch cost time 0.51
Train Epoch: 10 [208896/319902 (65%)] Loss: 0.021380, 1 batch cost time 0.51
Train Epoch: 10 [209408/319902 (65%)] Loss: 0.012120, 1 batch cost time 0.51
Train Epoch: 10 [209920/319902 (66%)] Loss: 0.025380, 1 batch cost time 0.51
Train Epoch: 10 [210432/319902 (66%)] Loss: 0.041175, 1 batch cost time 0.51
Train Epoch: 10 [210944/319902 (66%)] Loss: 0.015080, 1 batch cost time 0.51
Train Epoch: 10 [211456/319902 (66%)] Loss: 0.028128, 1 batch cost time 0.51
Train Epoch: 10 [211968/319902 (66%)] Loss: 0.024709, 1 batch cost time 0.51
Train Epoch: 10 [212480/319902 (66%)] Loss: 0.028829, 1 batch cost time 0.51
Train Epoch: 10 [212992/319902 (67%)] Loss: 0.026249, 1 batch cost time 0.51
Train Epoch: 10 [213504/319902 (67%)] Loss: 0.037592, 1 batch cost time 0.51
Train Epoch: 10 [214016/319902 (67%)] Loss: 0.041313, 1 batch cost time 0.51
Train Epoch: 10 [214528/319902 (67%)] Loss: 0.014886, 1 batch cost time 0.51
Train Epoch: 10 [215040/319902 (67%)] Loss: 0.039504, 1 batch cost time 0.51
Train Epoch: 10 [215552/319902 (67%)] Loss: 0.011036, 1 batch cost time 0.51
Train Epoch: 10 [216064/319902 (68%)] Loss: 0.026624, 1 batch cost time 0.51
Train Epoch: 10 [216576/319902 (68%)] Loss: 0.084196, 1 batch cost time 0.51
Train Epoch: 10 [217088/319902 (68%)] Loss: 0.014262, 1 batch cost time 0.51
Train Epoch: 10 [217600/319902 (68%)] Loss: 0.027653, 1 batch cost time 0.51
Train Epoch: 10 [218112/319902 (68%)] Loss: 0.033306, 1 batch cost time 0.51
Train Epoch: 10 [218624/319902 (68%)] Loss: 0.019261, 1 batch cost time 0.51
Train Epoch: 10 [219136/319902 (69%)] Loss: 0.028095, 1 batch cost time 0.51
Train Epoch: 10 [219648/319902 (69%)] Loss: 0.023220, 1 batch cost time 0.51
Train Epoch: 10 [220160/319902 (69%)] Loss: 0.017643, 1 batch cost time 0.51
Train Epoch: 10 [220672/319902 (69%)] Loss: 0.014453, 1 batch cost time 0.51
Train Epoch: 10 [221184/319902 (69%)] Loss: 0.026753, 1 batch cost time 0.51
Train Epoch: 10 [221696/319902 (69%)] Loss: 0.008870, 1 batch cost time 0.51
Train Epoch: 10 [222208/319902 (69%)] Loss: 0.020699, 1 batch cost time 0.51
Train Epoch: 10 [222720/319902 (70%)] Loss: 0.079223, 1 batch cost time 0.51
Train Epoch: 10 [223232/319902 (70%)] Loss: 0.020043, 1 batch cost time 0.51
Train Epoch: 10 [223744/319902 (70%)] Loss: 0.076863, 1 batch cost time 0.51
Train Epoch: 10 [224256/319902 (70%)] Loss: 0.028477, 1 batch cost time 0.51
Train Epoch: 10 [224768/319902 (70%)] Loss: 0.041208, 1 batch cost time 0.51
Train Epoch: 10 [225280/319902 (70%)] Loss: 0.057047, 1 batch cost time 0.51
Train Epoch: 10 [225792/319902 (71%)] Loss: 0.039036, 1 batch cost time 0.51
Train Epoch: 10 [226304/319902 (71%)] Loss: 0.020916, 1 batch cost time 0.51
Train Epoch: 10 [226816/319902 (71%)] Loss: 0.032326, 1 batch cost time 0.51
Train Epoch: 10 [227328/319902 (71%)] Loss: 0.022978, 1 batch cost time 0.51
Train Epoch: 10 [227840/319902 (71%)] Loss: 0.038410, 1 batch cost time 0.51
Train Epoch: 10 [228352/319902 (71%)] Loss: 0.033907, 1 batch cost time 0.51
Train Epoch: 10 [228864/319902 (72%)] Loss: 0.014953, 1 batch cost time 0.51
Train Epoch: 10 [229376/319902 (72%)] Loss: 0.016698, 1 batch cost time 0.51
Train Epoch: 10 [229888/319902 (72%)] Loss: 0.022066, 1 batch cost time 0.51
Train Epoch: 10 [230400/319902 (72%)] Loss: 0.025696, 1 batch cost time 0.51
Train Epoch: 10 [230912/319902 (72%)] Loss: 0.013076, 1 batch cost time 0.51
Train Epoch: 10 [231424/319902 (72%)] Loss: 0.034930, 1 batch cost time 0.51
Train Epoch: 10 [231936/319902 (73%)] Loss: 0.019106, 1 batch cost time 0.51
Train Epoch: 10 [232448/319902 (73%)] Loss: 0.009684, 1 batch cost time 0.51
Train Epoch: 10 [232960/319902 (73%)] Loss: 0.044250, 1 batch cost time 0.51
Train Epoch: 10 [233472/319902 (73%)] Loss: 0.022976, 1 batch cost time 0.53
Train Epoch: 10 [233984/319902 (73%)] Loss: 0.022302, 1 batch cost time 0.51
Train Epoch: 10 [234496/319902 (73%)] Loss: 0.030115, 1 batch cost time 0.51
Train Epoch: 10 [235008/319902 (73%)] Loss: 0.022969, 1 batch cost time 0.51
Train Epoch: 10 [235520/319902 (74%)] Loss: 0.032473, 1 batch cost time 0.51
Train Epoch: 10 [236032/319902 (74%)] Loss: 0.011383, 1 batch cost time 0.51
Train Epoch: 10 [236544/319902 (74%)] Loss: 0.046930, 1 batch cost time 0.51
Train Epoch: 10 [237056/319902 (74%)] Loss: 0.019610, 1 batch cost time 0.51
Train Epoch: 10 [237568/319902 (74%)] Loss: 0.035687, 1 batch cost time 0.51
Train Epoch: 10 [238080/319902 (74%)] Loss: 0.044889, 1 batch cost time 0.51
Train Epoch: 10 [238592/319902 (75%)] Loss: 0.055476, 1 batch cost time 0.51
Train Epoch: 10 [239104/319902 (75%)] Loss: 0.043828, 1 batch cost time 0.51
Train Epoch: 10 [239616/319902 (75%)] Loss: 0.023684, 1 batch cost time 0.51
Train Epoch: 10 [240128/319902 (75%)] Loss: 0.029914, 1 batch cost time 0.51
Train Epoch: 10 [240640/319902 (75%)] Loss: 0.027310, 1 batch cost time 0.51
Train Epoch: 10 [241152/319902 (75%)] Loss: 0.024974, 1 batch cost time 0.51
Train Epoch: 10 [241664/319902 (76%)] Loss: 0.040511, 1 batch cost time 0.51
Train Epoch: 10 [242176/319902 (76%)] Loss: 0.045588, 1 batch cost time 0.51
Train Epoch: 10 [242688/319902 (76%)] Loss: 0.023704, 1 batch cost time 0.51
Train Epoch: 10 [243200/319902 (76%)] Loss: 0.027043, 1 batch cost time 0.51
Train Epoch: 10 [243712/319902 (76%)] Loss: 0.012138, 1 batch cost time 0.51
Train Epoch: 10 [244224/319902 (76%)] Loss: 0.024168, 1 batch cost time 0.51
Train Epoch: 10 [244736/319902 (77%)] Loss: 0.021803, 1 batch cost time 0.51
Train Epoch: 10 [245248/319902 (77%)] Loss: 0.028687, 1 batch cost time 0.51
Train Epoch: 10 [245760/319902 (77%)] Loss: 0.017744, 1 batch cost time 0.51
Train Epoch: 10 [246272/319902 (77%)] Loss: 0.017494, 1 batch cost time 0.51
Train Epoch: 10 [246784/319902 (77%)] Loss: 0.034978, 1 batch cost time 0.51
Train Epoch: 10 [247296/319902 (77%)] Loss: 0.027156, 1 batch cost time 0.51
Train Epoch: 10 [247808/319902 (77%)] Loss: 0.037757, 1 batch cost time 0.51
Train Epoch: 10 [248320/319902 (78%)] Loss: 0.024747, 1 batch cost time 0.51
Train Epoch: 10 [248832/319902 (78%)] Loss: 0.037287, 1 batch cost time 0.51
Train Epoch: 10 [249344/319902 (78%)] Loss: 0.020388, 1 batch cost time 0.51
Train Epoch: 10 [249856/319902 (78%)] Loss: 0.032562, 1 batch cost time 0.51
Train Epoch: 10 [250368/319902 (78%)] Loss: 0.041092, 1 batch cost time 0.51
Train Epoch: 10 [250880/319902 (78%)] Loss: 0.033539, 1 batch cost time 0.51
Train Epoch: 10 [251392/319902 (79%)] Loss: 0.031039, 1 batch cost time 0.51
Train Epoch: 10 [251904/319902 (79%)] Loss: 0.035063, 1 batch cost time 0.51
Train Epoch: 10 [252416/319902 (79%)] Loss: 0.026919, 1 batch cost time 0.51
Train Epoch: 10 [252928/319902 (79%)] Loss: 0.045929, 1 batch cost time 0.51
Train Epoch: 10 [253440/319902 (79%)] Loss: 0.022077, 1 batch cost time 0.51
Train Epoch: 10 [253952/319902 (79%)] Loss: 0.016644, 1 batch cost time 0.51
Train Epoch: 10 [254464/319902 (80%)] Loss: 0.061134, 1 batch cost time 0.51
Train Epoch: 10 [254976/319902 (80%)] Loss: 0.030565, 1 batch cost time 0.51
Train Epoch: 10 [255488/319902 (80%)] Loss: 0.024034, 1 batch cost time 0.51
Train Epoch: 10 [256000/319902 (80%)] Loss: 0.019407, 1 batch cost time 0.51
Train Epoch: 10 [256512/319902 (80%)] Loss: 0.043546, 1 batch cost time 0.51
Train Epoch: 10 [257024/319902 (80%)] Loss: 0.025121, 1 batch cost time 0.51
Train Epoch: 10 [257536/319902 (81%)] Loss: 0.021668, 1 batch cost time 0.51
Train Epoch: 10 [258048/319902 (81%)] Loss: 0.006086, 1 batch cost time 0.51
Train Epoch: 10 [258560/319902 (81%)] Loss: 0.015766, 1 batch cost time 0.51
Train Epoch: 10 [259072/319902 (81%)] Loss: 0.034519, 1 batch cost time 0.51
Train Epoch: 10 [259584/319902 (81%)] Loss: 0.048956, 1 batch cost time 0.51
Train Epoch: 10 [260096/319902 (81%)] Loss: 0.033803, 1 batch cost time 0.51
Train Epoch: 10 [260608/319902 (81%)] Loss: 0.019505, 1 batch cost time 0.51
Train Epoch: 10 [261120/319902 (82%)] Loss: 0.033852, 1 batch cost time 0.51
Train Epoch: 10 [261632/319902 (82%)] Loss: 0.048783, 1 batch cost time 0.51
Train Epoch: 10 [262144/319902 (82%)] Loss: 0.023099, 1 batch cost time 0.51
Train Epoch: 10 [262656/319902 (82%)] Loss: 0.016455, 1 batch cost time 0.51
Train Epoch: 10 [263168/319902 (82%)] Loss: 0.017821, 1 batch cost time 0.51
Train Epoch: 10 [263680/319902 (82%)] Loss: 0.054972, 1 batch cost time 0.51
Train Epoch: 10 [264192/319902 (83%)] Loss: 0.022593, 1 batch cost time 0.51
Train Epoch: 10 [264704/319902 (83%)] Loss: 0.033543, 1 batch cost time 0.51
Train Epoch: 10 [265216/319902 (83%)] Loss: 0.022758, 1 batch cost time 0.51
Train Epoch: 10 [265728/319902 (83%)] Loss: 0.023204, 1 batch cost time 0.51
Train Epoch: 10 [266240/319902 (83%)] Loss: 0.033126, 1 batch cost time 0.51
Train Epoch: 10 [266752/319902 (83%)] Loss: 0.029645, 1 batch cost time 0.51
Train Epoch: 10 [267264/319902 (84%)] Loss: 0.039454, 1 batch cost time 0.51
Train Epoch: 10 [267776/319902 (84%)] Loss: 0.042567, 1 batch cost time 0.51
Train Epoch: 10 [268288/319902 (84%)] Loss: 0.024733, 1 batch cost time 0.51
Train Epoch: 10 [268800/319902 (84%)] Loss: 0.022999, 1 batch cost time 0.51
Train Epoch: 10 [269312/319902 (84%)] Loss: 0.038119, 1 batch cost time 0.51
Train Epoch: 10 [269824/319902 (84%)] Loss: 0.043937, 1 batch cost time 0.51
Train Epoch: 10 [270336/319902 (85%)] Loss: 0.019637, 1 batch cost time 0.51
Train Epoch: 10 [270848/319902 (85%)] Loss: 0.004613, 1 batch cost time 0.51
Train Epoch: 10 [271360/319902 (85%)] Loss: 0.014388, 1 batch cost time 0.51
Train Epoch: 10 [271872/319902 (85%)] Loss: 0.026524, 1 batch cost time 0.51
Train Epoch: 10 [272384/319902 (85%)] Loss: 0.035903, 1 batch cost time 0.51
Train Epoch: 10 [272896/319902 (85%)] Loss: 0.028827, 1 batch cost time 0.51
Train Epoch: 10 [273408/319902 (85%)] Loss: 0.019250, 1 batch cost time 0.51
Train Epoch: 10 [273920/319902 (86%)] Loss: 0.037926, 1 batch cost time 0.51
Train Epoch: 10 [274432/319902 (86%)] Loss: 0.019124, 1 batch cost time 0.51
Train Epoch: 10 [274944/319902 (86%)] Loss: 0.041418, 1 batch cost time 0.51
Train Epoch: 10 [275456/319902 (86%)] Loss: 0.025934, 1 batch cost time 0.51
Train Epoch: 10 [275968/319902 (86%)] Loss: 0.051327, 1 batch cost time 0.51
Train Epoch: 10 [276480/319902 (86%)] Loss: 0.017472, 1 batch cost time 0.51
Train Epoch: 10 [276992/319902 (87%)] Loss: 0.035864, 1 batch cost time 0.51
Train Epoch: 10 [277504/319902 (87%)] Loss: 0.006882, 1 batch cost time 0.51
Train Epoch: 10 [278016/319902 (87%)] Loss: 0.021979, 1 batch cost time 0.51
Train Epoch: 10 [278528/319902 (87%)] Loss: 0.015634, 1 batch cost time 0.51
Train Epoch: 10 [279040/319902 (87%)] Loss: 0.035938, 1 batch cost time 0.51
Train Epoch: 10 [279552/319902 (87%)] Loss: 0.037409, 1 batch cost time 0.51
Train Epoch: 10 [280064/319902 (88%)] Loss: 0.031136, 1 batch cost time 0.51
Train Epoch: 10 [280576/319902 (88%)] Loss: 0.030667, 1 batch cost time 0.51
Train Epoch: 10 [281088/319902 (88%)] Loss: 0.008799, 1 batch cost time 0.51
Train Epoch: 10 [281600/319902 (88%)] Loss: 0.019328, 1 batch cost time 0.51
Train Epoch: 10 [282112/319902 (88%)] Loss: 0.032913, 1 batch cost time 0.51
Train Epoch: 10 [282624/319902 (88%)] Loss: 0.034937, 1 batch cost time 0.51
Train Epoch: 10 [283136/319902 (89%)] Loss: 0.029276, 1 batch cost time 0.51
Train Epoch: 10 [283648/319902 (89%)] Loss: 0.014616, 1 batch cost time 0.51
Train Epoch: 10 [284160/319902 (89%)] Loss: 0.038052, 1 batch cost time 0.51
Train Epoch: 10 [284672/319902 (89%)] Loss: 0.026217, 1 batch cost time 0.51
Train Epoch: 10 [285184/319902 (89%)] Loss: 0.033621, 1 batch cost time 0.51
Train Epoch: 10 [285696/319902 (89%)] Loss: 0.031840, 1 batch cost time 0.51
Train Epoch: 10 [286208/319902 (89%)] Loss: 0.027288, 1 batch cost time 0.51
Train Epoch: 10 [286720/319902 (90%)] Loss: 0.060488, 1 batch cost time 0.51
Train Epoch: 10 [287232/319902 (90%)] Loss: 0.011330, 1 batch cost time 0.51
Train Epoch: 10 [287744/319902 (90%)] Loss: 0.036505, 1 batch cost time 0.51
Train Epoch: 10 [288256/319902 (90%)] Loss: 0.034945, 1 batch cost time 0.51
Train Epoch: 10 [288768/319902 (90%)] Loss: 0.020575, 1 batch cost time 0.51
Train Epoch: 10 [289280/319902 (90%)] Loss: 0.024473, 1 batch cost time 0.51
Train Epoch: 10 [289792/319902 (91%)] Loss: 0.022180, 1 batch cost time 0.51
Train Epoch: 10 [290304/319902 (91%)] Loss: 0.025845, 1 batch cost time 0.51
Train Epoch: 10 [290816/319902 (91%)] Loss: 0.073294, 1 batch cost time 0.51
Train Epoch: 10 [291328/319902 (91%)] Loss: 0.030779, 1 batch cost time 0.51
Train Epoch: 10 [291840/319902 (91%)] Loss: 0.014581, 1 batch cost time 0.51
Train Epoch: 10 [292352/319902 (91%)] Loss: 0.033729, 1 batch cost time 0.51
Train Epoch: 10 [292864/319902 (92%)] Loss: 0.047914, 1 batch cost time 0.51
Train Epoch: 10 [293376/319902 (92%)] Loss: 0.042342, 1 batch cost time 0.51
Train Epoch: 10 [293888/319902 (92%)] Loss: 0.034169, 1 batch cost time 0.51
Train Epoch: 10 [294400/319902 (92%)] Loss: 0.057317, 1 batch cost time 0.51
Train Epoch: 10 [294912/319902 (92%)] Loss: 0.041272, 1 batch cost time 0.51
Train Epoch: 10 [295424/319902 (92%)] Loss: 0.023483, 1 batch cost time 0.51
Train Epoch: 10 [295936/319902 (93%)] Loss: 0.027199, 1 batch cost time 0.51
Train Epoch: 10 [296448/319902 (93%)] Loss: 0.050362, 1 batch cost time 0.51
Train Epoch: 10 [296960/319902 (93%)] Loss: 0.036899, 1 batch cost time 0.51
Train Epoch: 10 [297472/319902 (93%)] Loss: 0.033391, 1 batch cost time 0.51
Train Epoch: 10 [297984/319902 (93%)] Loss: 0.015465, 1 batch cost time 0.51
Train Epoch: 10 [298496/319902 (93%)] Loss: 0.051315, 1 batch cost time 0.51
Train Epoch: 10 [299008/319902 (93%)] Loss: 0.031201, 1 batch cost time 0.51
Train Epoch: 10 [299520/319902 (94%)] Loss: 0.028858, 1 batch cost time 0.51
Train Epoch: 10 [300032/319902 (94%)] Loss: 0.036009, 1 batch cost time 0.51
Train Epoch: 10 [300544/319902 (94%)] Loss: 0.042996, 1 batch cost time 0.51
Train Epoch: 10 [301056/319902 (94%)] Loss: 0.034721, 1 batch cost time 0.51
Train Epoch: 10 [301568/319902 (94%)] Loss: 0.033056, 1 batch cost time 0.51
Train Epoch: 10 [302080/319902 (94%)] Loss: 0.051131, 1 batch cost time 0.51
Train Epoch: 10 [302592/319902 (95%)] Loss: 0.008224, 1 batch cost time 0.51
Train Epoch: 10 [303104/319902 (95%)] Loss: 0.024657, 1 batch cost time 0.51
Train Epoch: 10 [303616/319902 (95%)] Loss: 0.026869, 1 batch cost time 0.51
Train Epoch: 10 [304128/319902 (95%)] Loss: 0.042857, 1 batch cost time 0.51
Train Epoch: 10 [304640/319902 (95%)] Loss: 0.038799, 1 batch cost time 0.51
Train Epoch: 10 [305152/319902 (95%)] Loss: 0.025928, 1 batch cost time 0.51
Train Epoch: 10 [305664/319902 (96%)] Loss: 0.011365, 1 batch cost time 0.51
Train Epoch: 10 [306176/319902 (96%)] Loss: 0.016341, 1 batch cost time 0.51
Train Epoch: 10 [306688/319902 (96%)] Loss: 0.029059, 1 batch cost time 0.51
Train Epoch: 10 [307200/319902 (96%)] Loss: 0.021233, 1 batch cost time 0.51
Train Epoch: 10 [307712/319902 (96%)] Loss: 0.015601, 1 batch cost time 0.51
Train Epoch: 10 [308224/319902 (96%)] Loss: 0.038631, 1 batch cost time 0.51
Train Epoch: 10 [308736/319902 (97%)] Loss: 0.043721, 1 batch cost time 0.51
Train Epoch: 10 [309248/319902 (97%)] Loss: 0.041200, 1 batch cost time 0.51
Train Epoch: 10 [309760/319902 (97%)] Loss: 0.028297, 1 batch cost time 0.51
Train Epoch: 10 [310272/319902 (97%)] Loss: 0.046990, 1 batch cost time 0.51
Train Epoch: 10 [310784/319902 (97%)] Loss: 0.023916, 1 batch cost time 0.51
Train Epoch: 10 [311296/319902 (97%)] Loss: 0.020784, 1 batch cost time 0.51
Train Epoch: 10 [311808/319902 (97%)] Loss: 0.027608, 1 batch cost time 0.51
Train Epoch: 10 [312320/319902 (98%)] Loss: 0.020383, 1 batch cost time 0.51
Train Epoch: 10 [312832/319902 (98%)] Loss: 0.036195, 1 batch cost time 0.51
Train Epoch: 10 [313344/319902 (98%)] Loss: 0.045530, 1 batch cost time 0.51
Train Epoch: 10 [313856/319902 (98%)] Loss: 0.033550, 1 batch cost time 0.51
Train Epoch: 10 [314368/319902 (98%)] Loss: 0.030972, 1 batch cost time 0.51
Train Epoch: 10 [314880/319902 (98%)] Loss: 0.043115, 1 batch cost time 0.51
Train Epoch: 10 [315392/319902 (99%)] Loss: 0.012180, 1 batch cost time 0.51
Train Epoch: 10 [315904/319902 (99%)] Loss: 0.020837, 1 batch cost time 0.51
Train Epoch: 10 [316416/319902 (99%)] Loss: 0.028907, 1 batch cost time 0.51
Train Epoch: 10 [316928/319902 (99%)] Loss: 0.016541, 1 batch cost time 0.51
Train Epoch: 10 [317440/319902 (99%)] Loss: 0.023654, 1 batch cost time 0.51
Train Epoch: 10 [317952/319902 (99%)] Loss: 0.030394, 1 batch cost time 0.51
Train Epoch: 10 [318464/319902 (100%)] Loss: 0.026472, 1 batch cost time 0.51
Train Epoch: 10 [318976/319902 (100%)] Loss: 0.046443, 1 batch cost time 0.51
Train Epoch: 10 [319488/319902 (100%)] Loss: 0.016663, 1 batch cost time 0.51
training epoch cost 7994.554598331451 seconds
    epoch          : 10
    lr             : 0.0001
    loss           : 0.029819407704367893
    accuracy       : 0.9339016856742697
    f_measure      : 0.5665931198764314
    val_loss       : 0.02579269074097586
    val_accuracy   : 0.9443359375
    val_f_measure  : 0.5504835933742183
Saving current best: model_best.pth ...
Loading checkpoint: output/saved/models/beat_aligned_swin_transformer_CODE/0803_100409/model_best.pth ...
Checkpoint loaded from epoch 11
/home/josegfer/li2021bat/model/metric.py:460: RuntimeWarning: Mean of empty slice
  macro_f_measure = np.nanmean(f_measure)
0it [00:00, ?it/s]1it [00:00,  4.01it/s]2it [00:00,  4.27it/s]3it [00:00,  4.47it/s]4it [00:00,  4.63it/s]5it [00:01,  4.76it/s]6it [00:01,  4.85it/s]7it [00:01,  4.74it/s]8it [00:02,  1.91it/s]9it [00:02,  2.35it/s]10it [00:03,  2.80it/s]11it [00:03,  3.24it/s]12it [00:03,  3.63it/s]13it [00:03,  3.97it/s]14it [00:03,  4.08it/s]15it [00:04,  4.34it/s]16it [00:04,  4.53it/s]17it [00:04,  4.62it/s]18it [00:04,  3.79it/s]19it [00:05,  4.10it/s]20it [00:05,  3.42it/s]21it [00:05,  3.80it/s]22it [00:05,  3.94it/s]23it [00:06,  4.22it/s]24it [00:06,  4.45it/s]25it [00:06,  4.62it/s]26it [00:06,  4.74it/s]27it [00:06,  4.83it/s]28it [00:07,  4.90it/s]29it [00:07,  4.94it/s]30it [00:07,  4.98it/s]31it [00:07,  5.01it/s]32it [00:08,  4.30it/s]33it [00:08,  4.50it/s]34it [00:08,  4.65it/s]35it [00:08,  4.78it/s]36it [00:09,  3.34it/s]37it [00:09,  3.72it/s]38it [00:09,  4.04it/s]39it [00:09,  4.31it/s]40it [00:09,  4.51it/s]41it [00:10,  4.67it/s]42it [00:10,  4.79it/s]43it [00:10,  4.86it/s]44it [00:10,  4.92it/s]45it [00:11,  3.85it/s]46it [00:11,  3.85it/s]47it [00:11,  4.15it/s]48it [00:11,  3.93it/s]49it [00:12,  4.20it/s]50it [00:12,  4.43it/s]51it [00:12,  4.61it/s]52it [00:12,  4.74it/s]53it [00:12,  4.83it/s]54it [00:13,  4.91it/s]55it [00:13,  4.95it/s]56it [00:13,  3.79it/s]57it [00:14,  2.80it/s]58it [00:14,  3.18it/s]59it [00:14,  3.59it/s]60it [00:14,  3.93it/s]61it [00:15,  4.22it/s]62it [00:15,  4.44it/s]63it [00:15,  4.62it/s]64it [00:15,  4.73it/s]65it [00:15,  4.82it/s]66it [00:15,  4.90it/s]67it [00:16,  4.95it/s]68it [00:16,  4.99it/s]69it [00:16,  4.50it/s]70it [00:16,  4.66it/s]71it [00:17,  4.77it/s]72it [00:17,  3.92it/s]73it [00:17,  4.20it/s]74it [00:17,  3.55it/s]75it [00:18,  3.86it/s]76it [00:18,  4.10it/s]77it [00:18,  4.36it/s]78it [00:18,  4.56it/s]79it [00:18,  4.71it/s]80it [00:19,  4.82it/s]81it [00:19,  4.89it/s]82it [00:20,  2.52it/s]83it [00:20,  2.96it/s]84it [00:20,  3.38it/s]85it [00:20,  3.75it/s]86it [00:21,  4.07it/s]87it [00:21,  4.33it/s]88it [00:21,  4.53it/s]89it [00:21,  4.68it/s]90it [00:21,  4.79it/s]91it [00:22,  4.88it/s]92it [00:22,  4.94it/s]93it [00:22,  4.98it/s]94it [00:22,  4.98it/s]95it [00:22,  5.00it/s]96it [00:23,  5.02it/s]97it [00:23,  5.04it/s]98it [00:23,  5.05it/s]99it [00:23,  5.06it/s]100it [00:23,  5.06it/s]101it [00:24,  4.21it/s]102it [00:24,  4.43it/s]103it [00:24,  4.60it/s]104it [00:24,  4.74it/s]105it [00:24,  4.49it/s]106it [00:25,  3.56it/s]107it [00:25,  3.80it/s]108it [00:25,  3.90it/s]109it [00:26,  4.19it/s]110it [00:26,  4.42it/s]111it [00:26,  4.60it/s]112it [00:26,  4.73it/s]113it [00:26,  4.83it/s]114it [00:27,  4.90it/s]115it [00:27,  4.17it/s]116it [00:27,  4.41it/s]117it [00:27,  4.59it/s]118it [00:27,  4.72it/s]119it [00:28,  4.82it/s]120it [00:28,  4.86it/s]121it [00:28,  4.92it/s]122it [00:28,  4.26it/s]123it [00:29,  4.47it/s]124it [00:29,  4.64it/s]125it [00:29,  4.76it/s]126it [00:29,  4.85it/s]127it [00:29,  4.92it/s]128it [00:30,  4.47it/s]129it [00:30,  4.64it/s]130it [00:30,  4.76it/s]131it [00:30,  4.85it/s]132it [00:30,  4.92it/s]133it [00:31,  4.46it/s]134it [00:31,  4.63it/s]135it [00:31,  4.75it/s]136it [00:31,  4.81it/s]137it [00:31,  4.88it/s]138it [00:32,  4.94it/s]139it [00:32,  4.98it/s]140it [00:32,  5.01it/s]141it [00:32,  5.03it/s]142it [00:32,  5.05it/s]143it [00:33,  5.06it/s]144it [00:33,  5.06it/s]145it [00:33,  5.07it/s]146it [00:33,  4.29it/s]147it [00:34,  4.50it/s]148it [00:34,  4.66it/s]149it [00:34,  4.78it/s]150it [00:34,  4.87it/s]151it [00:34,  4.93it/s]152it [00:35,  4.98it/s]153it [00:35,  5.01it/s]154it [00:35,  4.98it/s]155it [00:35,  5.00it/s]156it [00:35,  5.02it/s]157it [00:36,  5.04it/s]158it [00:36,  5.05it/s]159it [00:36,  5.06it/s]160it [00:36,  5.06it/s]161it [00:36,  5.06it/s]162it [00:37,  5.03it/s]163it [00:37,  5.05it/s]164it [00:37,  4.93it/s]165it [00:37,  4.86it/s]166it [00:37,  4.92it/s]167it [00:38,  4.86it/s]168it [00:38,  4.93it/s]169it [00:38,  4.97it/s]170it [00:38,  5.01it/s]171it [00:38,  5.03it/s]172it [00:39,  5.04it/s]173it [00:39,  5.05it/s]174it [00:39,  5.00it/s]175it [00:39,  5.01it/s]176it [00:39,  5.03it/s]177it [00:40,  5.04it/s]178it [00:40,  5.05it/s]179it [00:40,  5.06it/s]180it [00:40,  5.07it/s]181it [00:40,  5.07it/s]182it [00:41,  5.08it/s]183it [00:41,  5.08it/s]184it [00:41,  5.08it/s]185it [00:41,  5.08it/s]186it [00:41,  5.07it/s]187it [00:42,  3.08it/s]188it [00:42,  3.47it/s]189it [00:42,  3.83it/s]190it [00:43,  4.14it/s]191it [00:43,  4.38it/s]192it [00:43,  4.57it/s]192it [00:43,  4.42it/s]
0it [00:00, ?it/s]1it [00:01,  1.29s/it]2it [00:01,  1.02it/s]3it [00:01,  1.29it/s]4it [00:02,  1.55it/s]5it [00:02,  1.87it/s]6it [00:02,  2.17it/s]7it [00:03,  2.43it/s]8it [00:03,  2.65it/s]9it [00:03,  2.89it/s]10it [00:03,  2.99it/s]11it [00:04,  3.01it/s]12it [00:04,  3.13it/s]13it [00:04,  3.01it/s]14it [00:05,  3.11it/s]15it [00:05,  3.05it/s]16it [00:05,  3.18it/s]17it [00:06,  3.29it/s]18it [00:06,  3.34it/s]19it [00:06,  3.31it/s]20it [00:07,  3.26it/s]21it [00:07,  3.31it/s]22it [00:07,  3.33it/s]23it [00:07,  3.27it/s]24it [00:08,  3.25it/s]25it [00:08,  3.28it/s]26it [00:08,  3.17it/s]27it [00:09,  3.21it/s]28it [00:09,  3.20it/s]29it [00:09,  3.32it/s]30it [00:10,  3.25it/s]31it [00:10,  3.21it/s]32it [00:10,  3.25it/s]33it [00:11,  3.12it/s]34it [00:11,  3.18it/s]35it [00:11,  3.25it/s]36it [00:11,  3.20it/s]37it [00:12,  3.10it/s]38it [00:12,  2.99it/s]39it [00:13,  2.85it/s]40it [00:13,  2.82it/s]41it [00:13,  2.88it/s]42it [00:14,  2.81it/s]43it [00:14,  2.80it/s]44it [00:14,  2.76it/s]45it [00:15,  2.90it/s]46it [00:15,  2.84it/s]47it [00:15,  2.77it/s]48it [00:16,  2.70it/s]49it [00:16,  2.78it/s]50it [00:16,  2.95it/s]51it [00:17,  3.11it/s]52it [00:17,  3.22it/s]53it [00:17,  3.23it/s]54it [00:18,  3.36it/s]55it [00:18,  3.43it/s]56it [00:18,  3.42it/s]57it [00:18,  3.47it/s]58it [00:19,  3.35it/s]59it [00:19,  3.29it/s]60it [00:19,  3.11it/s]61it [00:20,  3.04it/s]62it [00:20,  3.05it/s]63it [00:20,  2.94it/s]64it [00:21,  2.87it/s]65it [00:21,  2.85it/s]66it [00:22,  2.66it/s]67it [00:22,  2.70it/s]68it [00:22,  2.56it/s]69it [00:23,  2.61it/s]70it [00:23,  2.66it/s]71it [00:24,  2.73it/s]72it [00:24,  2.82it/s]73it [00:24,  2.83it/s]74it [00:25,  2.94it/s]75it [00:25,  2.96it/s]76it [00:25,  2.98it/s]77it [00:26,  2.93it/s]78it [00:26,  2.94it/s]79it [00:26,  2.86it/s]80it [00:27,  2.87it/s]81it [00:27,  2.85it/s]82it [00:27,  2.63it/s]83it [00:28,  2.60it/s]84it [00:28,  2.63it/s]85it [00:29,  2.68it/s]86it [00:29,  2.62it/s]87it [00:29,  2.74it/s]88it [00:30,  2.72it/s]89it [00:30,  2.75it/s]90it [00:30,  2.86it/s]91it [00:31,  2.93it/s]92it [00:31,  2.90it/s]93it [00:31,  2.81it/s]94it [00:32,  2.79it/s]95it [00:32,  2.77it/s]96it [00:32,  2.78it/s]97it [00:33,  2.58it/s]98it [00:33,  2.48it/s]99it [00:34,  2.66it/s]100it [00:34,  2.72it/s]101it [00:34,  2.82it/s]102it [00:35,  2.85it/s]103it [00:35,  2.75it/s]104it [00:35,  2.75it/s]105it [00:36,  2.78it/s]106it [00:36,  2.77it/s]107it [00:37,  2.65it/s]108it [00:37,  2.77it/s]109it [00:37,  2.75it/s]110it [00:38,  2.80it/s]111it [00:38,  2.77it/s]112it [00:38,  2.66it/s]113it [00:39,  2.64it/s]114it [00:39,  2.66it/s]115it [00:39,  2.68it/s]116it [00:40,  2.66it/s]117it [00:40,  2.65it/s]118it [00:41,  2.66it/s]119it [00:41,  2.70it/s]120it [00:41,  2.67it/s]121it [00:42,  2.64it/s]122it [00:42,  2.59it/s]123it [00:43,  2.61it/s]124it [00:43,  2.69it/s]125it [00:43,  2.72it/s]126it [00:44,  2.76it/s]127it [00:44,  2.57it/s]128it [00:44,  2.65it/s]129it [00:45,  2.66it/s]130it [00:45,  2.65it/s]131it [00:45,  2.82it/s]132it [00:46,  2.89it/s]133it [00:46,  2.89it/s]134it [00:46,  2.84it/s]135it [00:47,  3.00it/s]136it [00:47,  2.80it/s]137it [00:48,  2.74it/s]138it [00:48,  2.79it/s]139it [00:48,  2.71it/s]140it [00:49,  2.74it/s]141it [00:49,  2.74it/s]142it [00:49,  2.76it/s]143it [00:50,  2.62it/s]144it [00:50,  2.61it/s]145it [00:51,  2.68it/s]146it [00:51,  2.58it/s]147it [00:51,  2.54it/s]148it [00:52,  2.54it/s]149it [00:52,  2.61it/s]150it [00:52,  2.71it/s]151it [00:53,  2.63it/s]152it [00:53,  2.54it/s]153it [00:54,  2.59it/s]154it [00:54,  2.58it/s]155it [00:54,  2.60it/s]156it [00:55,  2.56it/s]157it [00:55,  2.47it/s]158it [00:56,  2.54it/s]159it [00:56,  2.65it/s]160it [00:56,  2.79it/s]161it [00:57,  2.91it/s]162it [00:57,  2.83it/s]163it [00:57,  2.79it/s]164it [00:58,  2.87it/s]165it [00:58,  2.81it/s]166it [00:58,  2.80it/s]167it [00:59,  2.76it/s]168it [00:59,  2.86it/s]169it [00:59,  2.87it/s]170it [01:00,  2.93it/s]171it [01:00,  2.75it/s]172it [01:01,  2.76it/s]173it [01:01,  2.60it/s]174it [01:01,  2.70it/s]175it [01:02,  2.70it/s]176it [01:02,  2.74it/s]177it [01:02,  2.91it/s]178it [01:03,  2.92it/s]179it [01:03,  2.82it/s]180it [01:03,  2.68it/s]181it [01:04,  2.70it/s]182it [01:04,  2.66it/s]183it [01:05,  2.55it/s]184it [01:05,  2.50it/s]185it [01:05,  2.54it/s]185it [01:05,  2.81it/s]
程序运行时间：82424秒
32370.24user 7542.72system 22:54:02elapsed 48%CPU (0avgtext+0avgdata 2799808maxresident)k
1210142920inputs+28430288outputs (4983major+6969924minor)pagefaults 0swaps
